it O
is O
based O
on O
the O
assumption O
that O
more O
frequent O
words O
are O
supposed O
to O
be O
easier O
to O
understand O
. O

in O
our O
scenario O
, O
it O
is O
desirable O
that O
the O
system O
can O
take O
into O
account O
the O
frequency O
level O
of O
words O
rather O
purely O
focusing O
on O
their O
meanings O
. O

though O
they O
are O
useful O
since O
topics O
are O
good O
indications O
of O
whether O
a O
document O
is O
difﬁcult O
to O
comprehend O
, O
word O
embeddings O
do O
not O
directly O
reﬂect O
the O
frequency O
levels O
of O
words O
. O

the O
pre O
- O
trained O
word O
embeddings O
are O
generally O
designed O
in O
a O
way O
that O
they O
can O
capture O
word O
meaning O
and O
topics O
. O

these O
models O
often O
use O
pre O
- O
trained O
word O
embeddings O
for O
nlp O
tasks O
and O
have O
been O
proven O
to O
achieve O
good O
results O
on O
multiple O
benchmarks O
( O
mikolov O
et O
al O
. O
, O

2011 O
) O
typically O
do O
not O
have O
to O
be O
supplied O
with O
hand O
- O
crafted O
features O
. O

our O
aim O
is O
to O
develop O
a O
universal O
method O
that O
can O
be O
used O
in O
a O
multilingual O
setting O
, O
which O
involve O
little O
effort O
when O
extending O
to O
other O
languages O
. O

these O
approaches O
, O
however O
, O
rely O
on O
hand O
- O
crafted O
features O
that O
depend O
heavily O
on O
the O
languages O
and O
require O
adjustment O
when O
applying O
to O
a O
new O
language O
. O

1975 O
; O
chall O
and O
dale O
, O
1995 O
; O
si O
and O
callan O
, O
2001 O
; O
heilman O
et O
al O
. O
, O

it O
is O
useful O
in O
many O
applications O
such O
as O
selecting O
learning O
material O
for O
children O
of O
different O
grade O
levels O
, O
for O
language O
learners O
, O
for O
comprehension O
tests O
, O
skills O
training O
, O
text O
summarisation O
, O
simpliﬁcation O
systems O
and O
so O
on O
. O

1 O
introduction O
readability B-TaskName
assessment I-TaskName
is O
the O
task O
of O
determining O
how O
difﬁcult O
a O
given O
document O
is O
to O
understand O
. O

the O
experimental O
results O
testing O
on O
both O
english O
and O
chinese O
datasets O
show O
that O
the O
proposed O
models O
improve O
the O
results O
notably O
when O
comparing O
to O
those O
using O
only O
traditional O
word O
embeddings O
. O

the O
proposed O
models O
show O
how O
frequency O
information O
can O
be O
integrated O
to O
improve O
the O
readability B-TaskName
assessment I-TaskName
. O

the O
task O
is O
to O
determine O
the O
difﬁculty O
level O
of O
a O
given O
document O
, O
i.e. O
, O
how O
hard O
it O
is O
for O
a O
reader O
to O
fully O
comprehend O
the O
text O
. O

acknowledgments O
this O
study O
was O
supported O
by O
the O
dfg O
grant O
oceanic O
exchanges O
( O
ko O
5362/2 O
- O
1 O
) O
and O
the O
creta O
center O
funded O
by O
the O
german O
ministry O
for O
education O
and O
research O
( O
bmbf O
) O
. O

in O
future O
work O
, O
we O
will O
extend O
the O
bilstm B-MethodName
to O
other O
languages O
using O
cross O
- O
lingual O
embeddings O
( O
ruder O
et O
al O
. O
, O

in O
sum O
, O
modern O
rnns B-MethodName
consistently O
yield O
the O
best O
performance O
. O

even O
though O
rnns B-MethodName
struggle O
with O
small O
datasets O
, O
transfer O
learning O
is O
a O
simple O
and O
effective O
remedy O
to O
achieve O
state O
- O
of O
- O
the O
- O
art O
performance O
even O
for O
such O
datasets O
. O

we O
found O
that O
combining O
bilstm B-MethodName
with O
a O
crf B-MethodName
as O
top O
layer O
, O
outperform O
crfs B-MethodName
with O
hand O
- O
coded O
features O
consistently O
when O
enough O
data O
is O
available O
. O

we O
have O
investigated O
the O
relative O
performance O
of O
an O
bilstm B-MethodName
method O
and O
traditional B-MethodName
crfs I-MethodName
on O
german O
ner B-TaskName
in O
big- O
and O
small O
- O
data O
situations O
, O
asking O
whether O
it O
makes O
sense O
to O
consider O
different O
model O
types O
for O
different O
setups O
. O

9 O
conclusion O
our O
study O
ﬁlls O
an O
empirical O
gap O
by O
considering O
historical O
datasets O
and O
performing O
careful O
comparisons O
of O
multiple O
models O
under O
exactly O
the O
same O
conditions O
. O

most O
related O
to O
our O
paper O
is O
the O
work O
by O
ghaddar O
and O
langlais O
( O
2017 O
) O
which O
demonstrates O
the O
impact O
of O
transfer O
learning O
of O
the O
english O
conll B-DatasetName
2003 I-DatasetName
dataset O
with O
wikipedia O
annotations O
. O

2017 O
) O
yield O
improvements O
up O
to O
0.8 B-MetricValue
% I-MetricValue
for O
ner B-TaskName
in O
the O
medical O
domain O
. O

with O
different O
labels O
and O
show O
that O
only O
60 B-HyperparameterValue
% I-HyperparameterValue
of O
the O
data O
of O
the O
target O
domain O
is O
required O
to O
achieve O
good O
results O
. O

sutton O
and O
mccallum O
( O
2005 O
) O
showed O
the O
capability O
of O
crfs B-MethodName
for O
transfer O
learning O
by O
joint O
decoding O
two O
separately O
trained O
sequence O
models O
. O

2016 O
; O
reimers O
and O
gurevych O
, O
2017 O
) O
and B-DatasetName
germeval I-DatasetName
( O
reimers O
et O
al O
. O
, O

however O
, O
only O
few O
systems O
reported O
results O
for O
german O
ner B-TaskName
, O
and O
restrict O
themselves O
to O
the O
“ O
big O
- O
data O
” O
scenarios O
of O
the O
conll B-DatasetName
2003 I-DatasetName
( O
lample O
et O
al O
. O
, O

2016 O
; O
reimers O
and O
gurevych O
, O
2017 O
; O
lin O
et O
al O
. O
, O

8 O
related O
work B-MethodName
bilstms I-MethodName
that O
combine O
neural O
network O
architectures O
with O
crf B-MethodName
- O
based O
superstructures O
yield O
the O
highest O
results O
on O
english O
ner B-TaskName
datasets O
in O
a O
number O
of O
studies O
( O
ma O
and O
hovy O
, O
2016 O
; O
lample O
et O
al O
. O
, O

czechoslovakian O
press O
) O
is O
detected O
as O
organization O
by O
all O
classiﬁers O
but O
is O
not O
manually O
annotated O
. O

for O
example O
, O
the O
typo O
“ O
sterreichischen O
außenministerlum O
” O
( O
should O
be O
“ O
außenministerium O
” O
, O
austrian O
foreign O
ministry O
) O
is O
manually O
annotated O
in O
the O
data O
but O
not O
detected O
by O
any O
of O
the O
models O
. O

often O
, O
the O
annotations O
for O
the O
organization O
category O
are O
not O
entirely O
clear O
. O

evaluating O
on O
the O
onb B-DatasetName
dataset O
, O
we O
obtain O
an O
f1 B-MetricName
score O
for O
that O
label O
of O
50.22 B-MetricValue
using O
germaner B-MethodName
, O
48.63 B-MetricValue
for O
the O
bilstm B-MethodName
using O
europeana B-MethodName
embeddings I-MethodName
and O
61.48 B-MetricValue
using O
transfer O
learning O
. O

the O
lowest O
f1 B-MetricName
scores O
are O
achieved O
for O
the O
label O
organization O
. O

7 O
data O
analysis O
besides O
ocr B-MetricName
errors O
, O
the O
lower B-MetricName
f1 I-MetricName
scores O
for O
the O
historic O
data O
are O
largely O
due O
to O
hyphens O
used O
to O
divide O
words O
for O
line O
breaks O
. O

we O
applied O
the O
same O
procedure O
to O
the O
crfs B-MethodName
, O
but O
did O
not O
obtain O
improvements O
for O
the O
“ O
target O
” O
data O
. O

we O
conclude O
that O
transfer O
learning O
is O
beneﬁcial O
for O
bilstms B-MethodName
, O
especially O
when O
training O
data O
for O
the O
target O
domain O
is O
scarce O
. O

the O
germeval B-DatasetName
corpus O
is O
more O
appropriate O
as O
a O
source O
corpus O
, O
presumably O
because O
it O
is O
both O
larger O
and O
drawn O
from O
encyclopaedic O
text O
, O
more O
varied O
than O
newswire O
. O

theresults O
in O
table O
5 O
show O
signiﬁcant O
improvements O
for O
the O
conll B-DatasetName
dataset O
but O
performance O
drops O
for O
germeval B-DatasetName
. O

performance O
on B-DatasetName
lft I-DatasetName
increases O
from O
69.62 B-MetricValue
to O
74.33 B-MetricValue
and O
on O
onb B-DatasetName
from O
73.31 B-MetricValue
to O
78.56 B-MetricValue
. O

combining O
contemporary O
sources O
with O
historic O
target O
corpora O
yields O
to O
consistent O
beneﬁts O
. O

in O
our O
scenario O
, O
we O
start O
by O
training O
on O
large O
contemporary O
“ O
source O
” O
corpora O
until O
convergence O
and O
then O
train O
additional O
15 B-HyperparameterValue
epochs B-HyperparameterName
on O
the O
“ O
target O
” O
corpus O
from O
the O
domain O
on O
which O
we O
evaluate O
. O

2017 O
): O
we O
simply O
start O
training O
on O
one O
corpus O
and O
at O
some O
point O
switch O
to O
another O
corpus O
. O

a O
simple O
way O
of O
doing O
this O
is O
transfer O
learning O
( O
lee O
et O
al O
. O
, O

6 O
experiment O
3 O
: O
transfer O
learning O
if O
the O
problems O
of O
bilstm B-MethodName
from O
the O
last O
section O
are O
in O
fact O
due O
to O
lack O
of O
data O
, O
we O
might O
be O
able O
to O
obtain O
an O
improvement O
by O
combining O
them O
. O

in O
sum O
, O
we O
conclude O
that O
bilstm B-MethodName
models O
run O
into O
trouble O
when O
faced O
with O
very O
small O
training O
datasets O
, O
while O
crf B-MethodName
- O
based O
methods O
are O
more O
robust O
( O
cotterell O
and O
duh O
, O
2017 O
) O
. O

the O
type O
of O
embeddings O
used O
by O
bilstm B-MethodName
plays O
a O
minor O
role O
for O
the O
historical O
corpora O
( O
for O
contemporary O
corpora O
, O
wikipedia O
is O
clearly O
better O
) O
. O

interestingly O
, O
these O
beneﬁts O
also O
extend O
to O
the O
historical O
datasets O
for O
which O
the O
crf B-MethodName
features O
were O
presumably O
not O
optimized O
: O
overall O
f1 B-MetricName
- O
scores O
are O
only O
a O
few O
points O
lower O
than O
for O
the O
contemporary O
corpora O
, O
and O
the O
crfs B-MethodName
signiﬁcantly O
outperform O
the O
bilstm B-MethodName
models O
on O
onb B-DatasetName
and O
performs O
comparable O
on O
the O
larger O
lft B-DatasetName
dataset O
. O

germaner B-MethodName
consistently O
outperforms O
stanfordner B-MethodName
again O
, O
highlighting O
the O
beneﬁts O
of O
knowledge O
engineering O
when O
using O
crfs B-MethodName
. O

unsurprisingly O
, O
the O
best O
results O
are O
gained O
when O
testing O
on O
the O
same O
dataset O
as O
the O
training O
has O
been O
performed O
. O

experiment O
2 O
evaluates O
how O
well O
the O
models O
do O
when O
trained O
on O
one O
corpus O
and O
tested O
on O
another O
one O
, O
including O
historical O
corpora O
. O

5 O
experiment O
2 O
: O
cross O
- O
corpus O
performance O
a O
potential O
downside O
of O
bilstms B-MethodName
is O
that O
learned O
models O
may O
be O
more O
text O
type O
speciﬁc O
, O
due O
to O
the O
high O
capacity O
of O
the O
models O
. O

in O
sum O
, O
we O
ﬁnd O
that O
bilstm B-MethodName
models O
can O
outperform O
crf B-MethodName
models O
when O
there O
is O
sufﬁcient O
training O
data O
to O
proﬁt O
from O
distributed O
representations O
. O

again O
, O
lower O
f1 B-MetricName
scores O
are O
achieved O
using O
the O
europeana B-MethodName
embeddings O
. O

the O
bilstm B-MethodName
again O
yields O
the O
signiﬁcantly O
best O
performance O
, O
matching O
its O
high O
precision B-MetricName
while O
substantially O
improving O
recall B-MetricName
. O

on O
the B-DatasetName
conll I-DatasetName
dataset O
( O
see O
table O
3 O
) O
germaner B-MethodName
outperforms O
the O
currently O
best O
- O
performing O
rnnbased B-MethodName
system O
( O
lample O
et O
al O
. O
, O

using O
europeana B-MethodName
embeddings I-MethodName
, O
the O
performance O
drops O
to O
an O
f1 B-MetricName
score O
of O
73.03 B-MetricValue
– O
due O
to O
the O
difference O
in O
vocabulary O
. O

our O
bilstm B-MethodName
with O
wikipedia B-MethodName
word I-MethodName
embeddings I-MethodName
, O
scores O
highest O
( O
79.99 B-MetricValue
) O
and O
outperforms O
the O
shared O
7we O
cleaned O
the O
corpora O
by O
correcting O
named O
entity O
labels O
and O
tokenization O
. O

germaner B-MethodName
achieves O
high O
precision B-MetricName
, O
but O
can O
not O
compete O
in O
terms O
of O
recall B-MetricName
. O

2015 O
) O
ensemble O
classiﬁer O
achieved O
the O
best O
result O
with O
an O
f1 B-MetricName
score O
of O
76.38 B-MetricValue
, O
followed O
by O
the O
rnn B-MethodName
- O
based O
method O
from O
ukp B-MethodName
( O
reimers O
et O
al O
. O
, O

first O
, O
we O
use O
pre O
- O
trained O
embeddings O
computed O
on O
wikipedia O
with O
300 O
dimensions O
and O
standard O
parameters O
( O
wikiemb)8 B-MethodName
, O
which O
are O
presumably O
more O
appropriate O
for O
contemporary O
texts O
. O

second O
, O
we O
compute O
embeddings O
with O
the O
same O
parameters O
from O
1.5 O
billion O
tokens O
of O
historic O
german O
texts O
from O
europeana B-MethodName
( O
euroemb B-MethodName
) O
. O

for O
bilstm B-MethodName
, O
we O
experiment O
with O
two O
options O
for O
word O
embeddings O
. O

4 O
experiment O
1 O
: O
contemporary O
german O
in O
our O
ﬁrst O
experiment O
, O
we O
compare O
the O
ner B-TaskName
performances O
on O
the O
two O
contemporary O
, O
large O
datasets O
. O

these O
corpora O
give O
rise O
to O
a O
number O
of O
challenges O
: O
they O
are O
considerably O
smaller O
than O
the O
contemporary O
corpora O
from O
above O
, O
contain O
a O
different O
language O
variety O
( O
19th O
century O
austrian O
german O
) O
, O
and O
include O
a O
high O
rate O
of O
ocr O
errors O
since O
they O
were O
originally O
printed O
in O
gothic O
typeface.7we O
use O
80 B-HyperparameterValue
% I-HyperparameterValue
of O
the O
data O
for O
training O
and O
each O
10 B-HyperparameterValue
% I-HyperparameterValue
for O
development O
and O
testing O
. O

our O
second O
corpus O
is O
a O
collection O
of O
austrian B-DatasetName
newspaper I-DatasetName
texts I-DatasetName
from I-DatasetName
the I-DatasetName
austrian I-DatasetName
national I-DatasetName
library I-DatasetName
( O
onb B-DatasetName
) O
, O
covering O
some O
35k O
tokens O
between O
1710 O
and O
1873 O
. O

we O
further O
consider O
two O
datasets O
based O
on O
historical O
texts O
( O
neudecker O
, O
2016)5 O
, O
extracted O
from O
the O
europeana O
collection O
of O
historical O
newspapers6 O
, O
a O
standard O
resource O
for O
historical O
digital O
humanities O
. O

to O
be O
more O
conform O
with O
the O
tagsets O
of O
the O
conll B-DatasetName
task O
, O
we O
focus O
on O
outer O
spans O
and O
remove O
the O
ﬁne O
- O
grained O
tags O
in O
the O
follow O
- O
up O
experiments O
( O
see O
section O
5 O
and O
6 O
) O
. O

as O
there O
are O
only O
few O
inner O
span O
annotations O
, O
we O
additionally O
report O
results O
based O
on O
the O
outer O
spans O
. O

to O
compare O
to O
previous O
state O
- O
of O
- O
the O
- O
art O
methods O
, O
we O
show O
results O
on O
the O
ofﬁcial O
metric O
( O
a O
combination O
of O
the O
outer O
and O
inner O
spans O
) O
in O
section O
4 O
. O

in O
addition O
to O
the O
standard O
tagsets O
also O
used O
in O
the O
conll B-DatasetName
dataset O
, O
ﬁne O
grained O
versions O
of O
these O
entities O
are O
marked O
with O
sufﬁxes O
: O
-deriv O
marks O
derivations O
of O
the O
named O
entities O
( O
e.g. O
german O
actor O
– O
german O
is O
a O
derived O
location O
) O
and O
-part O
marks O
compounds O
including O
a O
named O
entity O
( O
e.g. O
in O
the O
word O
rhineshore O
the O
compound O
rhine O
is O
location O
) O
. O

the O
nested O
term O
chicago O
is O
annotated O
as O
location O
in O
the O
inner O
span O
annotation O
. O

for O
example O
, O
the O
term O
chicago O
bulls O
is O
tagged O
as O
organization O
in O
the O
outer O
span O
annotation O
. O

2014 O
) O
) O
, O
consisting O
of O
some O
450k O
tokens O
( O
for O
training O
) O
of O
wikipedia O
articles.4this O
dataset O
has O
two O
levels O
of O
annotations O
: O
outer O
and O
inner O
span O
named O
entities O
. O

the O
second O
dataset O
is O
the O
germeval B-DatasetName
2014 I-DatasetName
shared O
task O
dataset O
( O
germeval O
, O
benikova O
et O
al O
. O
( O

the O
tagset O
handles O
locations O
( O
loc O
) O
, O
organizations O
( O
org O
) O
, O
persons O
( O
per O
) O
and O
the O
remaining O
entities O
as O
miscellaneous O
( O
misc O
) O
. O

it O
consists O
of O
about O
220k O
tokens O
( O
for O
training O
) O
of O
annotated O
newspaper O
documents O
. O

the O
ﬁrst O
large O
- O
scale O
german O
ner B-TaskName
dataset O
was O
published O
as O
part O
of O
the O
conll B-DatasetName
2003 I-DatasetName
shared O
task O
( O
conll O
, O
tjong O
kim O
sang O
and O
de O
meulder O
, O
2003 O
) O
. O

to O
alleviate O
issues O
with O
out O
- O
of O
- O
vocabulary O
( O
oov O
) O
words O
, O
we O
use O
both O
character- O
and O
subwordbased O
word O
embeddings O
computed O
with O
fasttext O
( O
bojanowski O
et O
al O
. O
, O

we O
train O
the O
character O
embeddings O
while O
training O
the O
model O
but O
use O
pre O
- O
trained O
word O
embeddings O
. O

in O
this O
work O
, O
we O
use O
an O
implementation O
that O
solely O
uses O
word O
and O
character O
embeddings O
. O

among O
the O
various O
deep O
learning O
architectures O
applied O
for O
ner O
, O
the O
best O
results O
have O
been O
achieved O
with O
bidirectional B-MethodName
lstm I-MethodName
methods O
combined O
with O
a O
top O
- O
level O
crf B-MethodName
model O
( O
ma O
and O
hovy O
, O
2016 O
; O
lample O
et O
al O
. O
, O

it O
was O
optimized O
for O
the O
germeval B-DatasetName
2014 I-DatasetName
ner B-TaskName
challenge O
and O
also O
uses O
a O
set O
of O
standard O
features O
( O
word O
and O
character O
n O
- O
grams O
, O
pos O
) O
supplemented O
by O
a O
number O
of O
speciﬁc O
information O
sources O
( O
unsupervised O
parts O
of O
speech O
( O
biemann O
, O
2009 O
) O
, O
distributional O
semantics O
and O
topic O
cluster O
information O
, O
gazetteer O
lists O
) O
. O

2015 O
) O
developed O
germa B-MethodName
ner2 I-MethodName
, O
another O
crf B-MethodName
- O
based O
ner B-TaskName
system O
. O

the O
ready O
- O
to O
- O
run O
model O
is O
pre O
- O
trained O
on O
the O
german B-DatasetName
conll I-DatasetName
2003 I-DatasetName
data O
( O
tjong O
kim O
sang O
and O
de O
meulder O
, O
2003 O
) O
. O

for O
german O
, O
these O
features O
are O
complemented O
by O
distributional O
clusters O
computed O
on O
a O
large O
german O
web O
corpus O
( O
faruqui O
and O
pad O
´ O
o O
, O
2010 O
) O
. O

it O
uses O
a O
set O
of O
language O
- O
independent O
features O
, O
including O
word O
and O
character O
n O
- O
grams O
, O
word O
shapes O
, O
surrounding O
pos O
and O
lemmas O
. O

they O
form O
the O
basis O
of O
two O
widely O
used O
named O
entity O
recognizers O
. O

linear O
- O
chain O
crfs B-MethodName
form O
a O
family O
of O
models O
that O
are O
well O
established O
in O
sequence O
classiﬁcation O
. O

our O
study O
focuses O
on O
crfs B-MethodName
and O
bilstms B-MethodName
, O
the O
two O
most O
widely O
used O
choices O
. O

the O
ﬁnal O
bilstm B-MethodName
models O
form O
a O
new O
state O
of O
the O
art O
for O
german O
ner B-TaskName
and O
are O
freely O
available.1212 O
model O
families O
for O
ner B-TaskName
as O
mentioned O
above O
, O
contemporary O
research O
on O
ner B-TaskName
almost O
exclusively O
uses O
sequence O
classiﬁcation O
models O
. O

due O
to O
these O
experiments O
, O
we O
get O
the O
following O
results O
: O
( O
a O
) O
, O
the O
bilstm B-MethodName
system O
indeed O
performs O
best O
on O
contemporary O
corpora O
, O
both O
within O
and O
across O
domains O
; O
( O
b O
) O
, O
the O
bilstm O
system O
performs O
worse O
than O
the O
crf B-MethodName
systems O
for O
the O
smallest O
historical O
corpus O
due O
to O
lack O
of O
data O
; O
( O
c O
) O
, O
by O
applying O
transfer O
learning O
to O
adduce O
more O
training O
data O
, O
the O
rnn B-MethodName
outperform O
crfs B-MethodName
substantially O
for O
all O
corpora O
. O

we O
pit O
linear O
- O
chain O
crf- B-MethodName
and O
bilstm B-MethodName
- O
based O
systems O
against O
each O
other O
and O
compare O
to O
state O
- O
ofthe O
- O
art O
models O
, O
performing O
three O
experiments O
. O

this O
paper O
investigates O
this O
question O
empirically O
on O
a O
set O
of O
german O
corpora O
including O
two O
large O
, O
contemporary O
corpora O
and O
two O
small O
historical O
corpora O
. O

thus O
, O
it O
is O
an O
open O
question O
, O
whether O
it O
is O
generally O
a O
better O
idea O
to O
choose O
different O
model O
families O
for O
different O
settings O
, O
or O
whether O
one O
model O
family O
can O
be O
optimized O
to O
perform O
well O
across O
settings O
. O

this O
consideration O
becomes O
particularly O
pressing O
when O
moving O
to O
“ O
small O
- O
data O
” O
settings O
such O
as O
low O
- O
resource O
languages O
, O
speciﬁc O
domains O
, O
or O
historical O
corpora O
. O

to O
perform O
representation O
learning O
, O
bilstms B-MethodName
require O
considerably O
annotated O
data O
to O
learn O
proper O
representations O
( O
see O
, O
e.g. O
, O
the O
impact O
of O
training O
size O
by O
dernoncourt O
et O
al O
. O
, O

another O
one O
is O
the O
amount O
of O
training O
data O
: O
linearchain O
crfs B-MethodName
require O
only O
moderate O
amounts O
of O
training O
data O
compared O
to O
bilstm B-MethodName
. O

when O
developing O
ner B-TaskName
tools O
for O
new O
types O
of O
text O
, O
one O
requirement O
is O
the O
availability O
of O
different O
resources O
to O
inform O
features O
and/or O
embeddings O
. O

there O
are O
two O
families O
of O
sequence O
models O
that O
constitute O
promising O
candidates O
. O

the O
two O
best O
- O
performing O
model O
families O
are O
pitted O
against O
each O
other O
( O
linear O
- O
chain O
crfs B-MethodName
and O
bilstm B-MethodName
) O
to O
observe O
the O
trade O
- O
off O
between O
expressiveness O
and O
data O
requirements O
. O

bilstms B-MethodName
proﬁt O
substantially O
from O
transfer O
learning O
, O
which O
enables O
them O
to O
be O
trained O
on O
multiple O
corpora O
, O
resulting O
in O
a O
new O
state O
- O
of O
- O
theart O
model O
for O
german O
ner B-TaskName
on O
two O
contemporary O
german O
corpora O
( O
conll B-DatasetName
2003 I-DatasetName
and O
germeval B-DatasetName
2014 I-DatasetName
) O
and O
two O
historic O
corpora O
. O

on O
the O
one O
hand O
, O
linearchain O
crfs B-MethodName
, O
which O
form O
the O
basis O
for O
many O
widely O
used O
systems O
( O
e.g. O
, O
finkel O
et O
al O
. O
, O

on O
the O
other O
hand O
, O
bidirectional B-MethodName
lstmss B-MethodName
( O
bilstms B-MethodName
, O
e.g. O
, O
reimers O
and O
gurevych O
, O
2017 O
) O
identifyinformative O
features O
directly O
from O
the O
data O
, O
presented O
as O
word O
and/or O
character O
embeddings O
( O
e.g. O
, O
mikolov O
et O
al O
. O
, O

2015 O
) O
, O
proﬁt O
from O
hand O
- O
crafted O
features O
and O
can O
easily O
incorporate O
language- O
and O
domainspeciﬁc O
knowledge O
from O
dictionaries O
or O
gazetteers O
. O

since O
the O
goal O
of O
ner B-TaskName
is O
to O
recognize O
instances O
of O
named O
entities O
in O
running O
text O
, O
it O
is O
established O
practice O
to O
treat O
ner B-TaskName
as O
a O
“ O
word O
- O
by O
- O
word O
sequence O
labeling O
task O
” O
( O
jurafsky O
and O
martin O
, O
2009 O
) O
. O

high O
- O
quality O
ner B-TaskName
is O
crucial O
for O
applications O
like O
information O
extraction O
, O
question O
answering O
, O
or O
entity O
linking O
. O

1 O
introduction O
named B-TaskName
entity I-TaskName
recognition I-TaskName
and B-TaskName
classiﬁcation I-TaskName
( O
ner B-TaskName
) O
is O
a O
central O
component O
in O
many O
natural O
language O
processing O
pipelines O
. O

bilstm B-MethodName
outperforms O
the O
crf B-MethodName
when O
large O
datasets O
are O
available O
and O
performs O
inferior O
for O
the O
smallest O
dataset O
. O

top O
3 O
by O
both O
one O
or O
two O
of O
the O
tradespeople O
even O
darted O
out O
of O
their O
shops O
, O
and O
went O
a O
little O
way O
down O
the O
street O
before O
me O
, O
that O
they O
might O
turn O
, O
as O
if O
they O
had O
forgotten O
something O
, O
and O
pass O
me O
face O
to O
face O
– O
on O
which O
occa O
- O
sions O
i O
do O
n't O
know O
whether O
they O
or O
i O
made O
the O
worse O
pretence O
; O
they O
of O
doing O
it O
, O
or O
i O
of O
not O
seeing O
it O
. O

many O
of O
the O
decreases O
are O
statistically O
insignificant O
such O
as O
the O
decrease O
in O
delay O
from O
g3 O
to O
g4 O
with O
p B-MetricName
- I-MetricName
value I-MetricName
of O
0.13 B-MetricValue
. O

conditional B-MethodName
random I-MethodName
fields I-MethodName
with O
high O
- O
order O
features O
for O
sequence O
labeling O
. O

for O
example O
, O
the O
val- O
idation O
of O
the O
precursor B-MethodName
- I-MethodName
induced I-MethodName
crf I-MethodName
in O
deep O
neu- O
ral O
architecture O
for O
ner B-TaskName
, O
such O
as O
the O
lstm B-MethodName
- I-MethodName
crf I-MethodName
neural O
architecture O
( O
lample O
et O
al O
. O
, O

evidence O
from O
this O
study O
suggests O
that O
the O
utili- O
zation O
of O
outside O
labels O
as O
precedent O
ne O
infor- O
mation O
transmission O
medium O
presumably O
can O
en- O
hance O
the O
expressiveness O
of O
the O
crf B-MethodName
while O
keeping O
the O
first O
- O
order O
template O
. O

although O
the O
performance O
improvement O
is O
small O
in O
both O
the O
clinical O
and O
biomedical O
ner O
evaluations O
, O
this O
study O
has O
shown O
that O
the O
proposed O
design O
enables O
reduced O
computational O
cost O
in O
uti- O
lizing O
long O
- O
distance O
label O
dependency O
compared O
to O
the O
second B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
. O

the O
design O
of O
the O
precursor B-MethodName
- I-MethodName
induced I-MethodName
crf I-MethodName
apparently O
allows O
precedent O
named O
entity O
in- O
formation O
to O
pass O
through O
outside O
labels O
by O
induc- O
tion O
, O
even O
when O
the O
model O
maintains O
a O
first O
- O
order O
template O
. O

these O
results O
indicate O
that O
the O
precursor B-MethodName
- I-MethodName
induced I-MethodName
crf I-MethodName
, O
where O
long O
- O
distance O
dependency O
is O
intro- O
duced O
in O
crf B-MethodName
by O
label O
induction O
, O
slightly O
improves O
the O
effectiveness O
in O
clinical O
and O
biomedical O
ner B-TaskName
while O
also O
significantly O
reducing O
computational O
cost O
rather O
than O
building O
second- B-MethodName
or I-MethodName
higher I-MethodName
- I-MethodName
order I-MethodName
crfs I-MethodName
. O

the O
pre B-MethodName
- I-MethodName
induced I-MethodName
crf I-MethodName
takes O
significantly O
less O
time O
than O
the O
second B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
while O
the O
pre- B-MethodName
induced I-MethodName
crf I-MethodName
exploits O
longer O
label O
transition O
de- O
pendency O
than O
the O
second B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
. O

the O
pre B-MethodName
- I-MethodName
induced I-MethodName
crf I-MethodName
takes O
1.7 O
times O
more O
computation O
time O
than O
the O
first B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
in O
average O
. O

the O
result O
shows O
that O
the O
second B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
takes O
quite O
more O
time O
than O
the O
first B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
to O
compute O
one O
train- O
ing O
iteration O
. O

in O
order O
to O
compare O
the O
proposed O
model O
with O
the O
conventional O
crf B-MethodName
, O
both O
the O
first B-MethodName
- I-MethodName
order I-MethodName
and O
the O
sec- B-MethodName
ond I-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
are O
used O
as O
baseline O
models O
. O

the O
result O
shows O
a O
tendency O
that O
pre- B-MethodName
cursor I-MethodName
- I-MethodName
induced I-MethodName
( O
pre B-MethodName
- I-MethodName
induced I-MethodName
) O
crf B-MethodName
leads O
to O
a O
slight O
performance O
improvement O
compared O
to O
both O
the O
first B-MethodName
- I-MethodName
order I-MethodName
and O
second B-MethodName
- I-MethodName
order I-MethodName
crfs I-MethodName
in O
most O
cases O
. O

to O
perform O
ner B-TaskName
evaluation O
, O
two O
types O
of O
feature O
families O
are O
used O
: O
( O
a O
) O
token O
itself O
and O
neighbor O
to- O
kens O
in O
window O
size O
3 O
. O

the O
named O
entity O
classes O
in O
the O
biomedi- O
cal O
ner B-TaskName
evaluation O
are O
dna O
, O
rna O
, O
protein O
, O
cell O
line O
, O
and O
cell O
type O
. O

annotated O
named O
entities O
involved O
in O
the O
clini- O
cal O
ner B-TaskName
evaluation O
are O
related O
to O
mentions O
describ- O
ing O
the O
patient O
’s O
history O
. O

in O
the O
pre B-MethodName
- I-MethodName
induced I-MethodName
crf I-MethodName
, O
the O
outside O
state O
with O
a O
memory O
element O
behaves O
as O
if O
an O
information O
transmission O
medium O
is O
delivering O
information O
about O
the O
presence O
or O
absence O
of O
the O
preceding O
en- O
tity O
forward O
. O

the O
main O
purpose O
of O
the O
precursor O
- O
induced B-MethodName
crf I-MethodName
model O
, O
introduced O
in O
this O
study O
, O
is O
to O
capture O
spe- O
cific O
high O
- O
order O
named O
entity O
dependency O
that O
is O
an O
outside O
word O
sequence O
between O
two O
nes O
. O

because O
the O
first O
- O
order O
model O
assumes O
that O
state O
transition O
dependencies O
exist O
only O
between O
proximate O
two O
la- O
bels O
to O
prevent O
an O
increase O
in O
computational O
com- O
plexity O
, O
the O
first B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
learns O
bigram O
label O
transitions O
from O
the O
subsequence O
; O
{ O
( O
𝐴,𝑂),(𝑂,𝑂),(𝑂,𝐵 O
) O
} O
that O
is O
, O
label O
transition O
data O
learnt O
from O
the O
example O
sequence O
. O

as O
a O
sequence O
labeling O
model O
, O
the O
conventional O
crf B-MethodName
models O
the O
conditional O
distribu- O
tion O
𝑃(𝒚|𝒙 O
) O
in O
which O
x O
is O
the O
input O
( O
e.g. O
, O
token O
, O
word O
) O
sequence O
and O
y O
is O
the O
label O
sequence O
of O
x. O
a O
hidden O
state O
value O
set O
consists O
of O
target O
entity O
labels O
and O
a O
single O
outside O
label O
. O

2 O
precursor O
- O
induced O
crf B-MethodName
prior O
to O
introducing O
the O
new O
model O
formulation O
, O
the O
following O
information O
presents O
the O
general O
con- O
cept O
of O
crf B-MethodName
. O

10 O
kens O
, O
this O
study O
explores O
the O
method O
which O
modi- O
fies O
the O
first B-MethodName
- I-MethodName
order I-MethodName
linear I-MethodName
- I-MethodName
chain I-MethodName
crf I-MethodName
by O
using O
the O
induction O
method O
. O

previous O
studies O
have O
demonstrated O
that O
implementation O
of O
the O
higher- O
order O
crf B-MethodName
exploiting O
pre O
- O
defined O
label O
patterns O
leads O
to O
slight O
performance O
improvement O
in O
the O
conventional O
crf B-MethodName
in O
ner B-TaskName
( O
cuong O
, O
ye O
, O
lee O
, O
& O
chieu O
, O
2014 O
; O
fersini O
, O
messina O
, O
felici O
, O
& O
roth O
, O
2014 O
; O
sarawagi O
& O
cohen O
, O
2005 O
; O
ye O
et O
al O
. O
, O

only O
dependencies O
between O
neighbor O
labels O
are O
generally O
used O
in O
practice O
because O
conventional O
high O
- O
order O
crfs B-MethodName
are O
known O
to O
be O
intractable O
in O
ner B-TaskName
( O
ye O
, O
lee O
, O
chieu O
, O
& O
wu O
, O
2009 O
) O
. O

one O
major O
issue O
in O
previous O
studies O
was O
con- O
cerned O
with O
the O
way O
in O
which O
to O
explore O
long O
- O
dis- O
tance O
dependencies O
in O
ner B-TaskName
. O

in O
contrast O
, O
a O
crf B-MethodName
in O
named B-TaskName
entity I-TaskName
recognition I-TaskName
( O
ner B-TaskName
) O
can O
not O
fully O
capture O
dependencies O
between O
named O
entity O
( O
ne O
) O
labels O
. O

one O
of O
the O
primary O
advantages O
of O
applying O
the O
crf B-MethodName
to O
language O
processing O
is O
that O
it O
learns O
transi- O
tion O
factors O
between O
hidden O
variables O
correspond- O
ing O
to O
the O
label O
of O
single O
word O
. O

even O
in O
deep O
- O
learn- O
ing O
architecture O
, O
crf B-MethodName
has O
been O
used O
as O
a O
funda- O
mental O
element O
in O
named B-TaskName
entity I-TaskName
recognition I-TaskName
( O
lample O
, O
ballesteros O
, O
subramanian O
, O
kawakami O
, O
& O
dyer O
, O
2016 O
; O
liu O
, O
tang O
, O
wang O
, O
& O
chen O
, O
2017 O
) O
. O

1 O
introduction O
the O
concept O
of O
conditional B-MethodName
random I-MethodName
fields I-MethodName
( O
crfs B-MethodName
) O
( O
john O
lafferty O
, O
andrew O
mccallum O
, O
& O
fernando O
pereira O
, O
2001 O
) O
has O
been O
successfully O
adapted O
in O
many O
sequence O
labeling O
problems O
( O
andrew O
mccallum O
& O
wei O
li O
, O
2003 O
; O
fei O
sha O
& O
fernando O
pereira O
, O
2003 O
; O
john O
lafferty O
et O
al O
. O
, O

then O
, O
empirical O
results O
apparently O
demonstrate O
that O
it O
is O
possible O
to O
exploit O
long O
- O
distance O
label O
dependency O
in O
the O
orig- O
inal O
first B-MethodName
- I-MethodName
order I-MethodName
linear I-MethodName
chain I-MethodName
crf I-MethodName
structure O
upon O
ner B-TaskName
while O
reducing O
computational O
loss O
rather O
than O
in O
the O
second B-MethodName
- I-MethodName
order I-MethodName
crf I-MethodName
. O

the O
proposed O
design O
uses O
outside O
label O
in O
ner B-TaskName
as O
a O
transmission O
me- O
dium O
of O
precedent O
entity O
information O
on O
the O
crf B-MethodName
. O

com- O
pared O
with O
the O
previous O
methods O
, O
our O
leam B-MethodName
al- O
gorithm O
requires O
much O
lower O
computational O
cost O
, O
and O
achieves O
better O
if O
not O
comparable O
performance O
relative O
to O
the O
state O
- O
of O
- O
the O
- O
art O
. O

( O
a O
) O
yahoo B-DatasetName
dataset I-DatasetName
( O
b O
) O
clinical O
text O
figure O
4 O
: O
visualization O
of O
learned O
attention O
. O

cnn B-MethodName
con- O
sistently O
outperforms O
the O
basic O
bi B-MethodName
- I-MethodName
gru I-MethodName
architec- O
ture O
, O
and O
the O
logistic B-MethodName
regression I-MethodName
baseline O
performs O
worse O
than O
all O
deep O
learning O
architectures O
. O

leam B-MethodName
pro- O
vides O
the O
best O
auc B-MetricName
score O
, O
and O
better O
f1 B-MetricName
and O
p@5 B-MetricName
values O
than O
all O
methods O
except O
cnn O
. O

2018 O
) O
to O
consider O
the O
micro O
- O
averaged O
and O
macro O
- O
averaged O
f1 B-MetricName
and O
area B-MetricName
under I-MetricName
the I-MetricName
roc I-MetricName
curve I-MetricName
( O
auc B-MetricName
) O
, O
as O
well O
as O
the O
preci- B-MetricName
sion I-MetricName
atn(p@n B-MetricName
) O
. O

we O
also O
compare O
with O
three O
recent O
methods O
for O
multi B-TaskName
- I-TaskName
label I-TaskName
classiﬁcation I-TaskName
of O
clinical O
text O
, O
including O
condensed B-MethodName
memory I-MethodName
net- I-MethodName
works I-MethodName
( O
c B-MethodName
- I-MethodName
memnn I-MethodName
) O
( O
prakash O
et O
al O
. O
, O

5.3 O
applications O
to O
clinical O
text O
to O
demonstrate O
the O
practical O
value O
of O
label O
embed- O
dings O
, O
we O
apply O
leam B-MethodName
for O
a O
real O
health O
care O
sce- O
nario O
: O
medical O
code O
prediction O
on O
the O
electronic O
health O
records O
dataset O
. O

we O
visualize O
two O
examples O
in O
figure O
4(a O
) O
for O
the O
yahoo B-DatasetName
dataset I-DatasetName
. O

the O
high O
on O
- O
diagonal O
elements O
and O
low O
off O
- O
diagonal O
elements O
in O
figure O
3(a O
) O
indicate O
the O
superb O
ability O
of O
the O
label O
representations O
learned O
from O
leam B-MethodName
. O

5.2 O
representational O
ability O
label O
embeddings O
are O
highly O
meaningful O
to O
provide O
insight O
into O
the O
meaningfulness O
of O
the O
learned O
representations O
, O
in O
figure O
3 O
we O
visual- O
ize O
the O
correlation O
between O
label O
embeddings O
and O
document O
embeddings O
based O
on O
the O
yahoo B-DatasetName
date- I-DatasetName
set I-DatasetName
. O

the O
topic B-TaskName
classiﬁcation I-TaskName
tasks O
generally O
requires O
a O
larger O
r B-HyperparameterName
, O
while O
senti- B-TaskName
ment I-TaskName
classiﬁcation I-TaskName
tasks O
allows O
relatively O
smaller O
r. B-HyperparameterName
one O
may O
safely O
choose O
raround O
50if B-HyperparameterValue
not O
ﬁne- O
tuning O
. O

leam B-MethodName
uses O
much O
less O
model O
parameters O
, O
and O
converges O
signiﬁcantlymodel O
# O
parameters O
time O
cost O
( O
s O
) O
cnn O
541k O
171 O
lstm O
1.8 O
m O
598 O
swem O
61 O
k O
63 O
bi O
- O
blosan O
3.6 O
m O
292 O
leam O
65 O
k O
65 O
table O
4 O
: O
comparison O
of O
model O
size O
and O
speed O
. O

2014 O
) O
is O
employed O
on O
the O
ﬁnal O
mlp O
layer O
, O
with O
dropout B-HyperparameterName
rate I-HyperparameterName
0:5 B-HyperparameterValue
. O

we O
train O
our O
model O
’s O
parameters O
with O
the O
adam O
optimizer O
( O
kingma O
and O
ba O
, O
2014 O
) O
, O
with O
an O
ini- B-HyperparameterName
tial I-HyperparameterName
learning I-HyperparameterName
rate I-HyperparameterName
of O
0:001 B-HyperparameterValue
, O
and O
a O
minibatch B-HyperparameterName
size I-HyperparameterName
of O
100 B-HyperparameterValue
. O

for O
the O
datasets O
without O
representative O
class O
descriptions O
, O
one O
may O
initialize O
the O
label O
embed- O
dings O
as O
random O
samples O
drawn O
from O
a O
standard O
gaussian O
distribution O
. O

speciﬁcally O
, O
we O
note O
that O
the O
text O
em- O
bedding O
in O
pte O
is O
similar O
with O
a O
very O
special O
case O
of O
leam O
, O
when O
our O
window B-HyperparameterName
size I-HyperparameterName
r= O
1 B-HyperparameterValue
and O
at- O
tention O
score O
is O
uniform O
. O

we O
also O
compute O
a O
pair O
wise O
cohen B-MetricName
’s I-MetricName
value I-MetricName
of O
0.97 B-MetricValue
. O

we O
have O
achieved O
a O
pearson B-MetricName
’s I-MetricName
and O
spearman B-MetricName
’s I-MetricName
correlation I-MetricName
of O
0.94 B-MetricValue
and O
0.97 B-MetricValue
respectively O
as O
com- O
pared O
to O
that O
of O
0.91 B-MetricValue
and O
0.96 B-MetricValue
in O
( O
alikaniotis O
et O
al O
. O
, O

we O
found O
that O
that O
in O
terms O
of O
all O
these O
parameters O
our O
system O
performs O
better O
than O
the O
existing O
, O
lstm B-MethodName
, O
bi B-MethodName
- I-MethodName
lstm I-MethodName
and O
ease O
mod- O
els O
. O

on O
the O
other O
hand O
, O
we O
have O
also O
used O
evalua- O
tion O
matrices O
like O
, O
pearson B-MetricName
’s I-MetricName
correlation I-MetricName
r O
, O
spear- B-MetricName
man I-MetricName
’s I-MetricName
ranking I-MetricName
correlation I-MetricName
 O
, O
rmse B-MetricName
scores O
in O
or- O
der O
to O
compare O
our O
model O
with O
systems O
proposed O
by O
( O
alikaniotis O
et O
al O
. O
, O

it O
is O
worth O
mentioning O
here O
that O
all O
these O
mod- O
els O
are O
compared O
with O
respect O
to O
the O
qwk B-MetricName
score I-MetricName
. O

for O
ex- O
ample O
, O
in O
prompt O
3 O
, O
6 O
and O
7 O
we O
have O
achieved O
an O
qwk B-MetricName
of O
0.712 B-MetricValue
, O
0.831 B-MetricValue
and O
0.815 B-MetricValue
respectively O
as O
compared O
to O
the O
best O
reported O
average B-MetricName
qwk I-MetricName
score I-MetricName
of O
0.694 B-MetricValue
, O
0.827 B-MetricValue
and O
.0.811 B-MetricValue
respectively O
for O
the O
10 O
fold O
run O
of O
cnn O
- O
lstm O
and O
lstm O
only O
. O

for O
the O
convolution O
layer O
, O
the O
win- B-HyperparameterName
dow I-HyperparameterName
size I-HyperparameterName
( O
l O
) O
is O
set O
to O
5 B-HyperparameterValue
and O
the O
output O
dimension B-HyperparameterName
of I-HyperparameterName
this I-HyperparameterName
layer I-HyperparameterName
( O
dc)is O
set O
to O
50 B-HyperparameterValue
. O

we O
set O
the O
word B-HyperparameterName
embedding I-HyperparameterName
dimension I-HyperparameterName
( O
dlt)to O
50 B-HyperparameterValue
and O
the O
output O
dimension B-HyperparameterName
of I-HyperparameterName
the I-HyperparameterName
recurrent I-HyperparameterName
layer I-HyperparameterName
( O
dr)to O
300 B-HyperparameterValue
. O

the O
mini B-HyperparameterName
- I-HyperparameterName
batch I-HyperparameterName
size I-HyperparameterName
is O
64 B-HyperparameterValue
in O
our O
experiments O
and O
we O
train O
the O
network O
for O
400 B-HyperparameterValue
epochs B-HyperparameterName
. O

we O
use O
the O
rmsprop O
optimizer O
with O
decay B-HyperparameterName
rate I-HyperparameterName
( O
)set O
to O
0.9 B-HyperparameterValue
to O
train O
the O
net- O
work O
and O
we O
set O
the O
base O
learning B-HyperparameterName
rate I-HyperparameterName
to O
0.001 B-HyperparameterValue
. O

we O
train O
the O
model O
for O
a O
ﬁxed O
number B-HyperparameterName
of I-HyperparameterName
epochs I-HyperparameterName
( O
around O
8000 B-HyperparameterValue
) O
and O
then O
choose O
the O
best O
model O
based O
on O
the O
de- O
velopment O
set O
. O

in O
each O
fold O
, O
80 B-HyperparameterValue
% I-HyperparameterValue
of O
the O
data O
is O
used O
for O
training B-HyperparameterName
, O
10 B-HyperparameterValue
% I-HyperparameterValue
as O
the O
develop- B-HyperparameterName
ment I-HyperparameterName
set I-HyperparameterName
, O
and O
10 B-HyperparameterValue
% I-HyperparameterValue
as O
the O
test B-HyperparameterName
set I-HyperparameterName
. O

of O
ﬁlters O
100 O
bi O
- O
lstm O
hidden B-HyperparameterName
units I-HyperparameterName
100 B-HyperparameterValue
dropout O
dropout B-HyperparameterName
rate I-HyperparameterName
1.0 B-HyperparameterValue
epochs B-HyperparameterName
200 B-HyperparameterValue
batch B-HyperparameterName
size I-HyperparameterName
10 B-HyperparameterValue
initial B-HyperparameterName
learning I-HyperparameterName
rate I-HyperparameterName
0.001 B-HyperparameterValue
momentum B-HyperparameterName
0.9 B-HyperparameterValue
4 O
experiments O
4.1 O
dataset O
an O
automated O
student O
assessment O
prize O
( O
asap O
) O
contest O
was O
hosted O
at O
kaggle O
in O
2012 O
. O

where,2[0;1]is O
the O
smoothing B-HyperparameterName
parameter I-HyperparameterName
and O
is O
the O
probability O
of O
term O
qin O
the O
corpus O
c. O
in O
our O
experiments O
, O
was O
set O
to O
0:9 B-HyperparameterValue
. O

detection O
t O
ask O
runs O
precision B-MetricName
recall B-MetricName
f1 B-MetricName
run1 O
0.6736 B-MetricValue
0.8621 B-MetricValue
0.7563 B-MetricValue
run2 O
0.7266 B-MetricValue
0.7408 B-MetricValue
0.7336 B-MetricValue
identification O
t O
ask O
model O
precision B-MetricName
recall B-MetricName
f1 B-MetricName
run1 O
0.4834 B-MetricValue
0.5952 B-MetricValue
0.5335 B-MetricValue
run2 O
0.5831 B-MetricValue
0.4955 B-MetricValue
0.5357 B-MetricValue
position O
t O
ask O
model O
precision B-MetricName
recall B-MetricName
f1 B-MetricName
run1 O
0.2741 B-MetricValue
0.3177 B-MetricValue
0.2943 B-MetricValue
run2 O
0.3839 B-MetricValue
0.2966 B-MetricValue
0.3346 B-MetricValue
t O
able O
6 O
: O
results O
on O
evaluation O
dataset O
of O
dip O
t O
asks O
. O

in O
top1 O
correction O
task O
, O
the O
f1 B-MetricName
of O
run2 O
ranked O
2/9 O
according O
to O
teams O
and O
2/23 O
according O
to O
results O
, O
which O
is O
lower O
than O
the O
highest O
result O
by O
only O
0.0001 B-MetricValue
. O

and O
in O
the O
position O
task O
, O
the O
f1 B-MetricName
of O
run2 O
gained O
third O
place O
among O
32 O
results O
. O

in O
the O
identification O
task O
, O
the O
f1 B-MetricName
of O
run1 O
and O
run2 O
ranked O
the O
second O
and O
the O
third O
respectively O
. O

the O
first O
run O
of O
our O
system O
( O
run1 O
) O
achieved O
the O
highest O
f1 B-MetricName
scores I-MetricName
in O
the O
detec- O
tion O
task O
. O

specifically O
, O
we O
tag O
each O
character O
of O
the O
sentences O
and O
then O
use O
the O
lstm B-MethodName
- I-MethodName
crf I-MethodName
model O
( O
huang O
et O
al O
. O
, O

the O
pseudo O
data O
is O
used O
to O
pre O
- O
train O
the O
model O
and O
gives O
rise O
to O
improvements O
in O
both O
precision B-MetricName
and O
re- B-MetricName
call I-MetricName
. O

7 O
conclusion O
and O
f O
uture O
w O
ork O
in O
cged O
2018 O
, O
we O
employ O
the O
sequence O
to O
se- O
quence O
learning O
to O
model O
the O
task O
of O
grammar B-TaskName
error I-TaskName
correction I-TaskName
. O

t O
able O
2shows O
the O
ensembled O
system O
1 O
+ O
3 O
( O
> O
1 O
) O
achieves O
a O
f B-MetricName
alse I-MetricName
positive I-MetricName
rate I-MetricName
( O
fpr B-MetricName
) O
at O
4.48 B-MetricValue
% I-MetricValue
and O
a O
precision B-MetricName
of O
86.56 B-MetricValue
% I-MetricValue
the O
detection O
of O
erroneous O
sentences O
, O
which O
are O
better O
than O
the O
best O
fpr B-MetricName
4.99 B-MetricValue
% I-MetricValue
and O
the O
best O
precision82.76 B-MetricName
% B-MetricValue
in O
cged O
2018 O
submissions O
, O
respec- O
tively O
. O

these O
performances O
are O
much O
higher O
than O
the O
best O
in O
cged O
2018 O
submissions O
, O
where O
the O
precision B-MetricName
is O
29.32 B-MetricValue
% I-MetricValue
, O
and O
recall B-MetricName
is O
1.58 B-MetricValue
% I-MetricValue
. O

the O
ensembled O
systems O
steadily O
achieve O
a O
precision B-MetricName
greater O
than O
50 B-MetricValue
% I-MetricValue
, O
with O
a O
recall B-MetricName
greater O
than O
8 B-MetricValue
% I-MetricValue
. O

being O
aware O
of O
the O
significance O
of O
pre- B-MetricName
cision I-MetricName
in O
a O
grammar B-TaskName
error I-TaskName
correction I-TaskName
system O
in O
practice O
, O
we O
further O
use O
ensembles O
to O
boost O
precisions B-MetricName
. O

a O
teacher O
would O
always O
prefers O
a O
grammar B-TaskName
error I-TaskName
correction I-TaskName
system O
with O
high O
precision B-MetricName
, O
even O
if O
it O
has O
a O
low O
recall B-MetricName
, O
than O
a O
system O
returns O
lots O
of O
noises O
. O

in O
real O
scenarios O
of O
grammar O
error O
diag- O
noses O
, O
the O
evaluation O
metrics O
of O
precision B-MetricName
, O
re- B-MetricName
call I-MetricName
and O
f1 B-MetricName
are O
not O
of O
the O
same O
importance O
. O

the O
evaluation O
in O
t O
able O
1reveals O
that O
the O
use O
of O
pseudo O
data O
has O
improved O
both O
pre- B-MetricName
cision I-MetricName
and O
recall B-MetricName
in O
the O
correction O
task O
of O
the O
word O
selection O
errors O
and O
missing O
errors O
, O
while O
that O
of O
pos O
tags O
does O
not O
make O
a O
significant O
contribution O
. O

w O
e O
use O
the O
default O
settings O
of O
f B-MethodName
airseq I-MethodName
, O
except O
that O
we O
use O
512 B-HyperparameterValue
dimensions B-HyperparameterName
of I-HyperparameterName
character I-HyperparameterName
embeddings I-HyperparameterName
. O

the O
inputs O
to O
f B-MethodName
airseq I-MethodName
models O
are O
as O
simple O
as O
chinese O
characters O
and O
pos O
tags O
of O
charac- O
ters O
. O

in O
our O
study O
, O
we O
employ O
the O
f B-MethodName
airseq I-MethodName
model O
. O

the O
f B-MethodName
airseq I-MethodName
models O
are O
pre O
- O
trained O
with O
the O
pseudo O
labeled O
data O
, O
and O
fine O
- O
tuned O
with O
the O
manually O
labeled O
data O
delivered O
in O
cged O
. O

it O
has O
been O
the O
main- O
stream O
model O
for O
machine B-TaskName
translation I-TaskName
nowa- O
days O
( O
klein O
et O
al O
. O
, O

y O
u O
and O
chen O
( O
2012 O
) O
proposed O
to O
use O
conditional B-MethodName
random I-MethodName
field I-MethodName
( O
crf B-MethodName
) O
( O
lafferty O
et O
al O
. O
, O

when O
using O
inputs O
as O
simple O
as O
chi- O
nese O
characters O
, O
the O
ensembled O
system O
achieves O
a O
precision B-MetricName
at O
86.56 B-MetricValue
% I-MetricValue
in O
the O
detection O
of O
erroneous O
sentences O
, O
and O
a O
precision B-MetricName
at O
51.53 B-MetricValue
% I-MetricValue
in O
the O
correction O
of O
errors O
of O
selection O
and O
missing O
types O
. O

a O
robust O
riskminimization O
based O
named B-TaskName
entity I-TaskName
recognition I-TaskName
sys O
- O
tem O
. O

introduction O
to O
the O
conll-2003 O
shared O
task O
: O
language O
- O
independent O
named B-TaskName
entity I-TaskName
recognition I-TaskName
. O

design O
chal O
- O
lenges O
and O
misconceptions O
in O
named B-TaskName
entity I-TaskName
recogni I-TaskName
- I-TaskName
tion I-TaskName
. O

named B-TaskName
entity I-TaskName
recognition I-TaskName
with O
document O
- O
speciﬁc O
kb O
tag O
gazetteers O
. O

others O
, O
usedexternal O
knowledge O
by O
exploiting O
the O
associationbetween O
ner B-TaskName
and O
ned B-TaskName
( O
durrett O
and O
klein,2014;radford O
et O
al O
. O

previous O
work O
has O
already O
regarded O
ner B-TaskName
asa O
knowledge O
intensive O
task O
( O
florian O
et O
al O
. O

, O
2016 O
; O
65 O
70 O
75 O
80 O
85 O
90 O
95 O
100 O
anamekbentitygerman O
- O
testgerman O
- O
devspanish O
- O
testspanish O
- O
dev O
figure O
3 O
: O
ner B-TaskName
f1for B-MetricName
german O
on O
conll2003gdataset B-DatasetName
and O
spanish O
on O
conll2002 B-DatasetName
dataset O
. O

a O
recent O
trend O
hasachieved O
particularly O
good O
results O
modeling O
neras B-TaskName
an O
end O
- O
to O
- O
end O
task O
using O
neural O
networks O
( O
dossantos O
and O
guimar˜aes,2015;chiu O
and O
nichols,2016;lample O
et O
al O
. O

, O
2016 O
) O
in O
german O
and O
1.98 B-MetricValue
f1points B-MetricName
on O
( O
yang O
et O
al O
. O

our O
system O
lags O
only O
1.56 B-MetricValue
f1pointson B-MetricName
( O
lample O
et O
al O
. O

performance O
is O
evaluatedon O
conll2003 B-DatasetName
g O
( O
sang O
and O
meulder,2003 O
) O
forgerman O
and O
conll2002 B-DatasetName
( O
tjong O
kim O
sang,2002)for O
spanish O
. O

interestingly O
, O
lo O
- O
cations O
register O
a O
slight O
decline O
between O
kb O
andentity O
( O
0.56f1points).finally B-MetricValue
, O
fig.1bshows O
the O
performance O
overspan O
detection O
, O
which O
is O
the O
span O
where O
the O
namedentity O
occurs O
without O
taking O
type O
information O
intoaccount O
. O

the O
positive O
effect O
is O
par O
- O
ticularly O
strong O
for O
persons O
, O
improving O
more O
than15f1points B-MetricValue
( O
78.70 B-MetricValue
to O
94.28 B-MetricValue
) O
. O

75 O
80 O
85 O
90 O
95 O
100 O
anamekbentityconll2003 B-DatasetName
- O
testconll2003 B-DatasetName
- O
devmuc-7 O
- O
testmuc-7 O
- O
dev(b O
) O
span O
- O
basedf1score B-MetricName
75 O
80 O
85 O
90 O
95 O
100 O
anamekbentityfperforgflocfmiscfall O
( O
c O
) O
type O
- O
based O
nerf1score B-TaskName
on O
conll2003 B-DatasetName
- O
test O
75 O
80 O
85 O
90 O
95 O
100 O
anamekbentityfperforgflocfall O
( O
d O
) O
type O
- O
based O
nerf1score B-TaskName
on O
muc-7 O
- O
testfigure O
1 O
: O
evaluation O
results O
by O
type O
conll2003 B-DatasetName
- O
test O
and O
muc-7-test.locations O
, O
but O
the O
successive O
increment O
is O
sharper O
. O

244 O
75 O
80 O
85 O
90 O
95 O
100 O
anamekbentityconll2003 B-DatasetName
- O
testconll2003 B-DatasetName
- O
devmuc-7 O
- O
testmuc-7 O
- O
dev O
( O
a O
) O
nerf1score B-TaskName
. O

to O
perform O
our O
study O
we O
use O
a O
lin B-MethodName
- I-MethodName
ear I-MethodName
chain I-MethodName
crf(lafferty I-MethodName
et O
al O
. O

we O
evaluate O
on O
two O
standard O
nerdatasetsconll2003.(sang B-DatasetName
and O
meulder,2003),a O
collection O
of O
english O
newswires O
covering O
enti O
- O
ties O
with O
four O
types O
( O
per O
, O
org O
, O
loc O
, O
misc)andmuc-7 O
, O
a O
set O
of O
new O
york O
times O
articles(chinchor O
and O
robinson,1997 O
) O
with O
annotationson O
three O
types O
of O
entities O
( O
per O
, O
org O
, O
loc).3.2 O
incremental O
knowledgehere O
we O
analyze O
the O
impact O
of O
incrementallyadding O
external O
knowledge O
. O

as O
a O
referencepoint O
, O
one O
of O
the O
best O
systems O
to O
date O
( O
chiu O
andnichols,2016 O
) O
( O
neural O
- O
based O
) O
achievesf191.62on O
conll2013 B-DatasetName
- O
test O
, O
while O
our O
full O
- O
knowledgecrf O
reachesf191.12.fig.1cshows O
the O
performance O
for O
each O
entitytype O
on O
conll2003 B-DatasetName
. O

they O
encode O
knowl O
- O
edge O
about O
named O
entities O
themselves O
or O
their O
us O
- O
ages O
. O

our O
results O
indicate O
that O
theamount O
of O
knowledge O
is O
highly O
correlated O
withner O
performance O
. O

on O
the O
other O
hand O
, O
educational O
environment O
has O
also O
been O
improved O
to O
impact O
the O
world O
society O
, O
such O
as O
the O
emergence O
of O
moocs O
( O
massive O
open O
online O
courses O
) O
, O
and O
new O
learning O
tools O
or O
teach O
- O
ing O
paradigms O
have O
also O
change O
the O
way O
of O
class O
interactions O
, O
such O
as O
the O
use O
of O
classroom O
re O
- O
sponse O
systems O
( O
crs O
) O
( O
siau O
et O
al O
. O

