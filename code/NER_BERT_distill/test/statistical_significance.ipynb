{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMoIqv1LRGHE",
        "outputId": "9286f9c0-9f0e-4aca-d207-c92604a5c8ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_-o-_2cSJqe",
        "outputId": "01f6b254-617e-4d7a-821a-4c2ad5472f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FCw5HI70SUyV"
      },
      "outputs": [],
      "source": [
        "# for both txt, every line is (text, pred label, gold label)\n",
        "\n",
        "f = open(\"test_bert_prediction.txt\", \"r\")\n",
        "lines = f.readlines()\n",
        "\n",
        "gold = []\n",
        "bert = []\n",
        "\n",
        "for line in lines:\n",
        "    tmp = line.split()\n",
        "    if len(tmp) == 3:\n",
        "        gold.append(tmp[2])\n",
        "        bert.append(tmp[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nqdk9wV1VOFp"
      },
      "outputs": [],
      "source": [
        "f = open(\"test_bilstm_prediction.txt\", \"r\")\n",
        "lines = f.readlines()\n",
        "\n",
        "lstm = []\n",
        "\n",
        "for line in lines:\n",
        "    tmp = line.split()\n",
        "    if len(tmp) == 3:\n",
        "        lstm.append(tmp[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sRmPMEXpQ5UT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "\n",
        "def eval_with_paired_bootstrap(gold, sys1, sys2, num_samples=10000, sample_ratio=0.5):\n",
        "    \"\"\"Evaluate with paired boostrap\n",
        "    This compares two systems, performing a significance tests with\n",
        "    paired bootstrap resampling to compare the accuracy of the two systems.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gold\n",
        "      The correct labels\n",
        "    sys1\n",
        "      The output of system 1\n",
        "    sys2\n",
        "      The output of system 2\n",
        "    num_samples\n",
        "      The number of bootstrap samples to take\n",
        "    sample_ratio\n",
        "      The ratio of samples to take every time\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(gold) == len(sys1)\n",
        "    assert len(gold) == len(sys2)\n",
        "\n",
        "    gold = np.array(gold)\n",
        "    sys1 = np.array(sys1)\n",
        "    sys2 = np.array(sys2)\n",
        "\n",
        "    sys1_scores = []\n",
        "    sys2_scores = []\n",
        "    wins = [0, 0, 0]\n",
        "    n = len(gold)\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Subsample the gold and system outputs\n",
        "        subset_idxs = rng.choice(n, int(n * sample_ratio), replace=True)\n",
        "        sys1_score = (sys1[subset_idxs] == gold[subset_idxs]).mean()\n",
        "        sys2_score = (sys2[subset_idxs] == gold[subset_idxs]).mean()\n",
        "\n",
        "        if sys1_score > sys2_score:\n",
        "            wins[0] += 1\n",
        "        elif sys1_score < sys2_score:\n",
        "            wins[1] += 1\n",
        "        else:\n",
        "            wins[2] += 1\n",
        "\n",
        "        sys1_scores.append(sys1_score)\n",
        "        sys2_scores.append(sys2_score)\n",
        "\n",
        "    # Print win stats\n",
        "    wins = [x / float(num_samples) for x in wins]\n",
        "    print(\"Win ratio: sys1=%.3f, sys2=%.3f, tie=%.3f\" % (wins[0], wins[1], wins[2]))\n",
        "    if wins[0] > wins[1]:\n",
        "        print(\"(sys1 is superior with p value p=%.3f)\\n\" % (1 - wins[0]))\n",
        "    elif wins[1] > wins[0]:\n",
        "        print(\"(sys2 is superior with p value p=%.3f)\\n\" % (1 - wins[1]))\n",
        "\n",
        "    # Print system stats\n",
        "    sys1_scores.sort()\n",
        "    sys2_scores.sort()\n",
        "    print(\n",
        "        \"sys1 mean=%.3f, median=%.3f, 95%% confidence interval=[%.3f, %.3f]\"\n",
        "        % (\n",
        "            np.mean(sys1_scores),\n",
        "            np.median(sys1_scores),\n",
        "            sys1_scores[int(num_samples * 0.025)],\n",
        "            sys1_scores[int(num_samples * 0.975)],\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"sys2 mean=%.3f, median=%.3f, 95%% confidence interval=[%.3f, %.3f]\"\n",
        "        % (\n",
        "            np.mean(sys2_scores),\n",
        "            np.median(sys2_scores),\n",
        "            sys2_scores[int(num_samples * 0.025)],\n",
        "            sys2_scores[int(num_samples * 0.975)],\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRceVyHDVtxE",
        "outputId": "e0deda13-b70f-412c-bde9-df43c54fd9ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Win ratio: sys1=1.000, sys2=0.000, tie=0.000\n",
            "(sys1 is superior with p value p=0.000)\n",
            "\n",
            "sys1 mean=0.996, median=0.996, 95% confidence interval=[0.994, 0.997]\n",
            "sys2 mean=0.954, median=0.954, 95% confidence interval=[0.950, 0.959]\n"
          ]
        }
      ],
      "source": [
        "eval_with_paired_bootstrap(gold, bert, lstm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
