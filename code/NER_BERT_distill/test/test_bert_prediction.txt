leam B-MethodName B-MethodName
uses O O
much O O
less O O
model O O
parameters O O
, O O
and O O
converges O O
signiﬁcantlymodel O O
# O O
parameters O O
time O O
cost O O
( O O
s O O
) O O
cnn O O
541k O O
171 O O
lstm O O
1.8 O O
m O O
598 O O
swem O O
61 O O
k O O
63 O O
bi O O
- O O
blosan O O
3.6 O O
m O O
292 O O
leam O O
65 O O
k O O
65 O O
table O O
4 O O
: O O
comparison O O
of O O
model O O
size O O
and O O
speed O O
. O O

2014 O O
) O O
is O O
employed O O
on O O
the O O
ﬁnal O O
mlp O O
layer O O
, O O
with O O
dropout B-HyperparameterName B-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
0:5 B-HyperparameterValue B-HyperparameterValue
. O O

we O O
train O O
our O O
model O O
’s O O
parameters O O
with O O
the O O
adam O O
optimizer O O
( O O
kingma O O
and O O
ba O O
, O O
2014 O O
) O O
, O O
with O O
an O O
ini- B-HyperparameterName B-HyperparameterName
tial I-HyperparameterName I-HyperparameterName
learning I-HyperparameterName I-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
of O O
0:001 B-HyperparameterValue B-HyperparameterValue
, O O
and O O
a O O
minibatch B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
100 B-HyperparameterValue B-HyperparameterValue
. O O

for O O
the O O
datasets O O
without O O
representative O O
class O O
descriptions O O
, O O
one O O
may O O
initialize O O
the O O
label O O
embed- O O
dings O O
as O O
random O O
samples O O
drawn O O
from O O
a O O
standard O O
gaussian O O
distribution O O
. O O

speciﬁcally O O
, O O
we O O
note O O
that O O
the O O
text O O
em- O O
bedding O O
in O O
pte O O
is O O
similar O O
with O O
a O O
very O O
special O O
case O O
of O O
leam O O
, O O
when O O
our O O
window B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
r= O O
1 B-HyperparameterValue B-HyperparameterValue
and O O
at- O O
tention O O
score O O
is O O
uniform O O
. O O

we O O
have O O
achieved O O
a O O
pearson B-MetricName B-MetricName
’s I-MetricName I-MetricName
and O O
spearman B-MetricName B-MetricName
’s I-MetricName I-MetricName
correlation I-MetricName I-MetricName
of O O
0.94 B-MetricValue B-MetricValue
and O O
0.97 B-MetricValue B-MetricValue
respectively O O
as O O
com- O O
pared O O
to O O
that O O
of O O
0.91 B-MetricValue B-MetricValue
and O O
0.96 B-MetricValue B-MetricValue
in O O
( O O
alikaniotis O O
et O O
al O O
. O O
, O O

we O O
found O O
that O O
that O O
in O O
terms O O
of O O
all O O
these O O
parameters O O
our O O
system O O
performs O O
better O O
than O O
the O O
existing O O
, O O
lstm B-MethodName B-MethodName
, O O
bi B-MethodName B-MethodName
- I-MethodName I-MethodName
lstm I-MethodName I-MethodName
and O O
ease O O
mod- O O
els O O
. O O

it O O
is O O
worth O O
mentioning O O
here O O
that O O
all O O
these O O
mod- O O
els O O
are O O
compared O O
with O O
respect O O
to O O
the O O
qwk B-MetricName B-MetricName
score I-MetricName I-MetricName
. O O

for O O
ex- O O
ample O O
, O O
in O O
prompt O O
3 O O
, O O
6 O O
and O O
7 O O
we O O
have O O
achieved O O
an O O
qwk B-MetricName B-MetricName
of O O
0.712 B-MetricValue B-MetricValue
, O O
0.831 B-MetricValue B-MetricValue
and O O
0.815 B-MetricValue B-MetricValue
respectively O O
as O O
compared O O
to O O
the O O
best O O
reported O O
average B-MetricName B-MetricName
qwk I-MetricName I-MetricName
score I-MetricName I-MetricName
of O O
0.694 B-MetricValue B-MetricValue
, O O
0.827 B-MetricValue B-MetricValue
and O O
.0.811 B-MetricValue B-MetricValue
respectively O O
for O O
the O O
10 O O
fold O O
run O O
of O O
cnn O O
- O O
lstm O O
and O O
lstm O O
only O O
. O O

for O O
the O O
convolution O O
layer O O
, O O
the O O
win- B-HyperparameterName B-HyperparameterName
dow I-HyperparameterName I-HyperparameterName
size I-HyperparameterName I-HyperparameterName
( O O
l O O
) O O
is O O
set O O
to O O
5 B-HyperparameterValue B-HyperparameterValue
and O O
the O O
output O O
dimension B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
this I-HyperparameterName I-HyperparameterName
layer I-HyperparameterName I-HyperparameterName
( O O
dc)is O O
set O O
to O O
50 B-HyperparameterValue B-HyperparameterValue
. O O

we O O
set O O
the O O
word B-HyperparameterName B-HyperparameterName
embedding I-HyperparameterName I-HyperparameterName
dimension I-HyperparameterName I-HyperparameterName
( O O
dlt)to O O
50 B-HyperparameterValue B-HyperparameterValue
and O O
the O O
output O O
dimension B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
the I-HyperparameterName I-HyperparameterName
recurrent I-HyperparameterName I-HyperparameterName
layer I-HyperparameterName I-HyperparameterName
( O O
dr)to O O
300 B-HyperparameterValue B-HyperparameterValue
. O O

the O O
mini B-HyperparameterName B-HyperparameterName
- I-HyperparameterName I-HyperparameterName
batch I-HyperparameterName I-HyperparameterName
size I-HyperparameterName I-HyperparameterName
is O O
64 B-HyperparameterValue B-HyperparameterValue
in O O
our O O
experiments O O
and O O
we O O
train O O
the O O
network O O
for O O
400 B-HyperparameterValue B-HyperparameterValue
epochs B-HyperparameterName B-HyperparameterName
. O O

we O O
train O O
the O O
model O O
for O O
a O O
ﬁxed O O
number B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
epochs I-HyperparameterName I-HyperparameterName
( O O
around O O
8000 B-HyperparameterValue B-HyperparameterValue
) O O
and O O
then O O
choose O O
the O O
best O O
model O O
based O O
on O O
the O O
de- O O
velopment O O
set O O
. O O

in O O
each O O
fold O O
, O O
80 B-HyperparameterValue B-HyperparameterValue
% I-HyperparameterValue I-HyperparameterValue
of O O
the O O
data O O
is O O
used O O
for O O
training B-HyperparameterName B-HyperparameterName
, O O
10 B-HyperparameterValue B-HyperparameterValue
% I-HyperparameterValue I-HyperparameterValue
as O O
the O O
develop- B-HyperparameterName B-HyperparameterName
ment I-HyperparameterName I-HyperparameterName
set I-HyperparameterName I-HyperparameterName
, O O
and O O
10 B-HyperparameterValue B-HyperparameterValue
% I-HyperparameterValue I-HyperparameterValue
as O O
the O O
test B-HyperparameterName B-HyperparameterName
set I-HyperparameterName I-HyperparameterName
. O O

detection O O
t O O
ask O O
runs O O
precision B-MetricName B-MetricName
recall B-MetricName B-MetricName
f1 B-MetricName B-MetricName
run1 O O
0.6736 B-MetricValue B-MetricValue
0.8621 B-MetricValue B-MetricValue
0.7563 B-MetricValue B-MetricValue
run2 O O
0.7266 B-MetricValue B-MetricValue
0.7408 B-MetricValue B-MetricValue
0.7336 B-MetricValue B-MetricValue
identification O O
t O O
ask O O
model O O
precision B-MetricName B-MetricName
recall B-MetricName B-MetricName
f1 B-MetricName B-MetricName
run1 O O
0.4834 B-MetricValue B-MetricValue
0.5952 B-MetricValue B-MetricValue
0.5335 B-MetricValue B-MetricValue
run2 O O
0.5831 B-MetricValue B-MetricValue
0.4955 B-MetricValue B-MetricValue
0.5357 B-MetricValue B-MetricValue
position O O
t O O
ask O O
model O O
precision B-MetricName B-MetricName
recall B-MetricName B-MetricName
f1 B-MetricName B-MetricName
run1 O O
0.2741 B-MetricValue B-MetricValue
0.3177 B-MetricValue B-MetricValue
0.2943 B-MetricValue B-MetricValue
run2 O O
0.3839 B-MetricValue B-MetricValue
0.2966 B-MetricValue B-MetricValue
0.3346 B-MetricValue B-MetricValue
t O O
able O O
6 O O
: O O
results O O
on O O
evaluation O O
dataset O O
of O O
dip O O
t O O
asks O O
. O O

in O O
top1 O O
correction O O
task O O
, O O
the O O
f1 B-MetricName B-MetricName
of O O
run2 O O
ranked O O
2/9 O O
according O O
to O O
teams O O
and O O
2/23 O O
according O O
to O O
results O O
, O O
which O O
is O O
lower O O
than O O
the O O
highest O O
result O O
by O O
only O O
0.0001 B-MetricValue B-MetricValue
. O O

and O O
in O O
the O O
position O O
task O O
, O O
the O O
f1 B-MetricName B-MetricName
of O O
run2 O O
gained O O
third O O
place O O
among O O
32 O O
results O O
. O O

in O O
the O O
identification O O
task O O
, O O
the O O
f1 B-MetricName B-MetricName
of O O
run1 O O
and O O
run2 O O
ranked O O
the O O
second O O
and O O
the O O
third O O
respectively O O
. O O

the O O
first O O
run O O
of O O
our O O
system O O
( O O
run1 O O
) O O
achieved O O
the O O
highest O O
f1 B-MetricName B-MetricName
scores I-MetricName I-MetricName
in O O
the O O
detec- O O
tion O O
task O O
. O O

specifically O O
, O O
we O O
tag O O
each O O
character O O
of O O
the O O
sentences O O
and O O
then O O
use O O
the O O
lstm B-MethodName B-MethodName
- I-MethodName I-MethodName
crf I-MethodName I-MethodName
model O O
( O O
huang O O
et O O
al O O
. O O
, O O

the O O
pseudo O O
data O O
is O O
used O O
to O O
pre O O
- O O
train O O
the O O
model O O
and O O
gives O O
rise O O
to O O
improvements O O
in O O
both O O
precision B-MetricName B-MetricName
and O O
re- B-MetricName B-MetricName
call I-MetricName I-MetricName
. O O

7 O O
conclusion O O
and O O
f O O
uture O O
w O O
ork O O
in O O
cged O O
2018 O O
, O O
we O O
employ O O
the O O
sequence O O
to O O
se- O O
quence O O
learning O O
to O O
model O O
the O O
task O O
of O O
grammar B-TaskName B-TaskName
error I-TaskName I-TaskName
correction I-TaskName I-TaskName
. O O

t O O
able O O
2shows O O
the O O
ensembled O O
system O O
1 O O
+ O O
3 O O
( O O
> O O
1 O O
) O O
achieves O O
a O O
f B-MetricName B-MetricName
alse I-MetricName I-MetricName
positive I-MetricName I-MetricName
rate I-MetricName I-MetricName
( O O
fpr B-MetricName B-MetricName
) O O
at O O
4.48 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
and O O
a O O
precision B-MetricName B-MetricName
of O O
86.56 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
the O O
detection O O
of O O
erroneous O O
sentences O O
, O O
which O O
are O O
better O O
than O O
the O O
best O O
fpr B-MetricName B-MetricName
4.99 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
and O O
the O O
best O O
precision82.76 B-MetricName B-MetricName
% I-MetricValue B-MetricValue
in O O
cged O O
2018 O O
submissions O O
, O O
respec- O O
tively O O
. O O

these O O
performances O O
are O O
much O O
higher O O
than O O
the O O
best O O
in O O
cged O O
2018 O O
submissions O O
, O O
where O O
the O O
precision B-MetricName B-MetricName
is O O
29.32 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
, O O
and O O
recall B-MetricName B-MetricName
is O O
1.58 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
. O O

the O O
ensembled O O
systems O O
steadily O O
achieve O O
a O O
precision B-MetricName B-MetricName
greater O O
than O O
50 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
, O O
with O O
a O O
recall B-MetricName B-MetricName
greater O O
than O O
8 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
. O O

being O O
aware O O
of O O
the O O
significance O O
of O O
pre- B-MetricName B-MetricName
cision I-MetricName I-MetricName
in O O
a O O
grammar B-TaskName B-TaskName
error I-TaskName I-TaskName
correction I-TaskName I-TaskName
system O O
in O O
practice O O
, O O
we O O
further O O
use O O
ensembles O O
to O O
boost O O
precisions B-MetricName B-MetricName
. O O

a O O
teacher O O
would O O
always O O
prefers O O
a O O
grammar B-TaskName B-TaskName
error I-TaskName I-TaskName
correction I-TaskName I-TaskName
system O O
with O O
high O O
precision B-MetricName B-MetricName
, O O
even O O
if O O
it O O
has O O
a O O
low O O
recall B-MetricName B-MetricName
, O O
than O O
a O O
system O O
returns O O
lots O O
of O O
noises O O
. O O

in O O
real O O
scenarios O O
of O O
grammar O O
error O O
diag- O O
noses O O
, O O
the O O
evaluation O O
metrics O O
of O O
precision B-MetricName B-MetricName
, O O
re- B-MetricName B-MetricName
call I-MetricName I-MetricName
and O O
f1 B-MetricName B-MetricName
are O O
not O O
of O O
the O O
same O O
importance O O
. O O

the O O
evaluation O O
in O O
t O O
able O O
1reveals O O
that O O
the O O
use O O
of O O
pseudo O O
data O O
has O O
improved O O
both O O
pre- B-MetricName B-MetricName
cision I-MetricName I-MetricName
and O O
recall B-MetricName B-MetricName
in O O
the O O
correction O O
task O O
of O O
the O O
word O O
selection O O
errors O O
and O O
missing O O
errors O O
, O O
while O O
that O O
of O O
pos O O
tags O O
does O O
not O O
make O O
a O O
significant O O
contribution O O
. O O

w O O
e O O
use O O
the O O
default O O
settings O O
of O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
, O O
except O O
that O O
we O O
use O O
512 B-HyperparameterValue B-HyperparameterValue
dimensions B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
character I-HyperparameterName I-HyperparameterName
embeddings I-HyperparameterName I-HyperparameterName
. O O

the O O
inputs O O
to O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
models O O
are O O
as O O
simple O O
as O O
chinese O O
characters O O
and O O
pos O O
tags O O
of O O
charac- O O
ters O O
. O O

in O O
our O O
study O O
, O O
we O O
employ O O
the O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
model O O
. O O

the O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
models O O
are O O
pre O O
- O O
trained O O
with O O
the O O
pseudo O O
labeled O O
data O O
, O O
and O O
fine O O
- O O
tuned O O
with O O
the O O
manually O O
labeled O O
data O O
delivered O O
in O O
cged O O
. O O

it O O
has O O
been O O
the O O
main- O O
stream O O
model O O
for O O
machine B-TaskName B-TaskName
translation I-TaskName I-TaskName
nowa- O O
days O O
( O O
klein O O
et O O
al O O
. O O
, O O

y O O
u O O
and O O
chen O O
( O O
2012 O O
) O O
proposed O O
to O O
use O O
conditional B-MethodName B-MethodName
random I-MethodName I-MethodName
field I-MethodName I-MethodName
( O O
crf B-MethodName B-MethodName
) O O
( O O
lafferty O O
et O O
al O O
. O O
, O O

when O O
using O O
inputs O O
as O O
simple O O
as O O
chi- O O
nese O O
characters O O
, O O
the O O
ensembled O O
system O O
achieves O O
a O O
precision B-MetricName B-MetricName
at O O
86.56 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
the O O
detection O O
of O O
erroneous O O
sentences O O
, O O
and O O
a O O
precision B-MetricName B-MetricName
at O O
51.53 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
the O O
correction O O
of O O
errors O O
of O O
selection O O
and O O
missing O O
types O O
. O O

a O O
robust O O
riskminimization O O
based O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
sys O O
- O O
tem O O
. O O

introduction O O
to O O
the O O
conll-2003 O O
shared O O
task O O
: O O
language O O
- O O
independent O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
. O O

design O O
chal O O
- O O
lenges O O
and O O
misconceptions O O
in O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recogni I-TaskName I-TaskName
- I-TaskName I-TaskName
tion I-TaskName I-TaskName
. O O

named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
with O O
document O O
- O O
speciﬁc O O
kb O O
tag O O
gazetteers O O
. O O

others O O
, O O
usedexternal O O
knowledge O O
by O O
exploiting O O
the O O
associationbetween O O
ner B-TaskName B-TaskName
and O O
ned B-TaskName B-TaskName
( O O
durrett O O
and O O
klein,2014;radford O O
et O O
al O O
. O O

previous O O
work O O
has O O
already O O
regarded O O
ner B-TaskName B-TaskName
asa O O
knowledge O O
intensive O O
task O O
( O O
florian O O
et O O
al O O
. O O

, O O
2016 O O
; O O
65 O O
70 O O
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentitygerman O O
- O O
testgerman O O
- O O
devspanish O O
- O O
testspanish O O
- O O
dev O O
figure O O
3 O O
: O O
ner B-TaskName B-TaskName
f1for B-MetricName B-MetricName
german O O
on O O
conll2003gdataset B-DatasetName B-DatasetName
and O O
spanish O O
on O O
conll2002 B-DatasetName B-DatasetName
dataset O O
. O O

a O O
recent O O
trend O O
hasachieved O O
particularly O O
good O O
results O O
modeling O O
neras B-TaskName B-TaskName
an O O
end O O
- O O
to O O
- O O
end O O
task O O
using O O
neural O O
networks O O
( O O
dossantos O O
and O O
guimar˜aes,2015;chiu O O
and O O
nichols,2016;lample O O
et O O
al O O
. O O

, O O
2016 O O
) O O
in O O
german O O
and O O
1.98 B-MetricValue B-MetricValue
f1points B-MetricName B-MetricName
on O O
( O O
yang O O
et O O
al O O
. O O

our O O
system O O
lags O O
only O O
1.56 B-MetricValue B-MetricValue
f1pointson B-MetricName B-MetricName
( O O
lample O O
et O O
al O O
. O O

performance O O
is O O
evaluatedon O O
conll2003 B-DatasetName B-DatasetName
g O O
( O O
sang O O
and O O
meulder,2003 O O
) O O
forgerman O O
and O O
conll2002 B-DatasetName B-DatasetName
( O O
tjong O O
kim O O
sang,2002)for O O
spanish O O
. O O

interestingly O O
, O O
lo O O
- O O
cations O O
register O O
a O O
slight O O
decline O O
between O O
kb O O
andentity O O
( O O
0.56f1points).finally B-MetricValue B-MetricValue
, O O
fig.1bshows O O
the O O
performance O O
overspan O O
detection O O
, O O
which O O
is O O
the O O
span O O
where O O
the O O
namedentity O O
occurs O O
without O O
taking O O
type O O
information O O
intoaccount O O
. O O

the O O
positive O O
effect O O
is O O
par O O
- O O
ticularly O O
strong O O
for O O
persons O O
, O O
improving O O
more O O
than15f1points B-MetricValue B-MetricValue
( O O
78.70 B-MetricValue B-MetricValue
to O O
94.28 B-MetricValue B-MetricValue
) O O
. O O

75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityconll2003 B-DatasetName B-DatasetName
- O O
testconll2003 B-DatasetName B-DatasetName
- O O
devmuc-7 O O
- O O
testmuc-7 O O
- O O
dev(b O O
) O O
span O O
- O O
basedf1score B-MetricName B-MetricName
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityfperforgflocfmiscfall O O
( O O
c O O
) O O
type O O
- O O
based O O
nerf1score B-TaskName B-TaskName
on O O
conll2003 B-DatasetName B-DatasetName
- O O
test O O
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityfperforgflocfall O O
( O O
d O O
) O O
type O O
- O O
based O O
nerf1score B-TaskName B-TaskName
on O O
muc-7 O O
- O O
testfigure O O
1 O O
: O O
evaluation O O
results O O
by O O
type O O
conll2003 B-DatasetName B-DatasetName
- O O
test O O
and O O
muc-7-test.locations O O
, O O
but O O
the O O
successive O O
increment O O
is O O
sharper O O
. O O

244 O O
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityconll2003 B-DatasetName B-DatasetName
- O O
testconll2003 B-DatasetName B-DatasetName
- O O
devmuc-7 O O
- O O
testmuc-7 O O
- O O
dev O O
( O O
a O O
) O O
nerf1score B-TaskName B-TaskName
. O O

to O O
perform O O
our O O
study O O
we O O
use O O
a O O
lin B-MethodName B-MethodName
- I-MethodName I-MethodName
ear I-MethodName I-MethodName
chain I-MethodName I-MethodName
crf(lafferty I-MethodName I-MethodName
et O O
al O O
. O O

we O O
evaluate O O
on O O
two O O
standard O O
nerdatasetsconll2003.(sang B-DatasetName B-DatasetName
and O O
meulder,2003),a O O
collection O O
of O O
english O O
newswires O O
covering O O
enti O O
- O O
ties O O
with O O
four O O
types O O
( O O
per O O
, O O
org O O
, O O
loc O O
, O O
misc)andmuc-7 O O
, O O
a O O
set O O
of O O
new O O
york O O
times O O
articles(chinchor O O
and O O
robinson,1997 O O
) O O
with O O
annotationson O O
three O O
types O O
of O O
entities O O
( O O
per O O
, O O
org O O
, O O
loc).3.2 O O
incremental O O
knowledgehere O O
we O O
analyze O O
the O O
impact O O
of O O
incrementallyadding O O
external O O
knowledge O O
. O O

as O O
a O O
referencepoint O O
, O O
one O O
of O O
the O O
best O O
systems O O
to O O
date O O
( O O
chiu O O
andnichols,2016 O O
) O O
( O O
neural O O
- O O
based O O
) O O
achievesf191.62on O O
conll2013 B-DatasetName B-DatasetName
- O O
test O O
, O O
while O O
our O O
full O O
- O O
knowledgecrf O O
reachesf191.12.fig.1cshows O O
the O O
performance O O
for O O
each O O
entitytype O O
on O O
conll2003 B-DatasetName B-DatasetName
. O O

they O O
encode O O
knowl O O
- O O
edge O O
about O O
named O O
entities O O
themselves O O
or O O
their O O
us O O
- O O
ages O O
. O O

our O O
results O O
indicate O O
that O O
theamount O O
of O O
knowledge O O
is O O
highly O O
correlated O O
withner O O
performance O O
. O O

on O O
the O O
other O O
hand O O
, O O
educational O O
environment O O
has O O
also O O
been O O
improved O O
to O O
impact O O
the O O
world O O
society O O
, O O
such O O
as O O
the O O
emergence O O
of O O
moocs O O
( O O
massive O O
open O O
online O O
courses O O
) O O
, O O
and O O
new O O
learning O O
tools O O
or O O
teach O O
- O O
ing O O
paradigms O O
have O O
also O O
change O O
the O O
way O O
of O O
class O O
interactions O O
, O O
such O O
as O O
the O O
use O O
of O O
classroom O O
re O O
- O O
sponse O O
systems O O
( O O
crs O O
) O O
( O O
siau O O
et O O
al O O
. O O
, O O

top O O
3 O O
by O O
both O O
one O O
or O O
two O O
of O O
the O O
tradespeople O O
even O O
darted O O
out O O
of O O
their O O
shops O O
, O O
and O O
went O O
a O O
little O O
way O O
down O O
the O O
street O O
before O O
me O O
, O O
that O O
they O O
might O O
turn O O
, O O
as O O
if O O
they O O
had O O
forgotten O O
something O O
, O O
and O O
pass O O
me O O
face O O
to O O
face O O
– O O
on O O
which O O
occa O O
- O O
sions O O
i O O
do O O
n't O O
know O O
whether O O
they O O
or O O
i O O
made O O
the O O
worse O O
pretence O O
; O O
they O O
of O O
doing O O
it O O
, O O
or O O
i O O
of O O
not O O
seeing O O
it O O
. O O

many O O
of O O
the O O
decreases O O
are O O
statistically O O
insignificant O O
such O O
as O O
the O O
decrease O O
in O O
delay O O
from O O
g3 O O
to O O
g4 O O
with O O
p B-MetricName B-MetricName
- I-MetricName I-MetricName
value I-MetricName I-MetricName
of O O
0.13 B-MetricValue B-MetricValue
. O O

conditional B-MethodName B-MethodName
random I-MethodName I-MethodName
fields I-MethodName I-MethodName
with O O
high O O
- O O
order O O
features O O
for O O
sequence O O
labeling O O
. O O

for O O
example O O
, O O
the O O
val- O O
idation O O
of O O
the O O
precursor B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
in O O
deep O O
neu- O O
ral O O
architecture O O
for O O
ner B-TaskName B-TaskName
, O O
such O O
as O O
the O O
lstm B-MethodName B-MethodName
- I-MethodName I-MethodName
crf I-MethodName I-MethodName
neural O O
architecture O O
( O O
lample O O
et O O
al O O
. O O
, O O

evidence O O
from O O
this O O
study O O
suggests O O
that O O
the O O
utili- O O
zation O O
of O O
outside O O
labels O O
as O O
precedent O O
ne O O
infor- O O
mation O O
transmission O O
medium O O
presumably O O
can O O
en- O O
hance O O
the O O
expressiveness O O
of O O
the O O
crf B-MethodName B-MethodName
while O O
keeping O O
the O O
first O O
- O O
order O O
template O O
. O O

although O O
the O O
performance O O
improvement O O
is O O
small O O
in O O
both O O
the O O
clinical O O
and O O
biomedical O O
ner O O
evaluations O O
, O O
this O O
study O O
has O O
shown O O
that O O
the O O
proposed O O
design O O
enables O O
reduced O O
computational O O
cost O O
in O O
uti- O O
lizing O O
long O O
- O O
distance O O
label O O
dependency O O
compared O O
to O O
the O O
second B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
. O O

the O O
design O O
of O O
the O O
precursor B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
apparently O O
allows O O
precedent O O
named O O
entity O O
in- O O
formation O O
to O O
pass O O
through O O
outside O O
labels O O
by O O
induc- O O
tion O O
, O O
even O O
when O O
the O O
model O O
maintains O O
a O O
first O O
- O O
order O O
template O O
. O O

these O O
results O O
indicate O O
that O O
the O O
precursor B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
, O O
where O O
long O O
- O O
distance O O
dependency O O
is O O
intro- O O
duced O O
in O O
crf B-MethodName B-MethodName
by O O
label O O
induction O O
, O O
slightly O O
improves O O
the O O
effectiveness O O
in O O
clinical O O
and O O
biomedical O O
ner B-TaskName B-TaskName
while O O
also O O
significantly O O
reducing O O
computational O O
cost O O
rather O O
than O O
building O O
second- B-MethodName B-MethodName
or I-MethodName I-MethodName
higher I-MethodName I-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crfs I-MethodName I-MethodName
. O O

the O O
pre B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
takes O O
significantly O O
less O O
time O O
than O O
the O O
second B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
while O O
the O O
pre- B-MethodName B-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
exploits O O
longer O O
label O O
transition O O
de- O O
pendency O O
than O O
the O O
second B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
. O O

the O O
pre B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
takes O O
1.7 O O
times O O
more O O
computation O O
time O O
than O O
the O O
first B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
in O O
average O O
. O O

the O O
result O O
shows O O
that O O
the O O
second B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
takes O O
quite O O
more O O
time O O
than O O
the O O
first B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
to O O
compute O O
one O O
train- O O
ing O O
iteration O O
. O O

in O O
order O O
to O O
compare O O
the O O
proposed O O
model O O
with O O
the O O
conventional O O
crf B-MethodName B-MethodName
, O O
both O O
the O O
first B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
and O O
the O O
sec- B-MethodName B-MethodName
ond I-MethodName I-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
are O O
used O O
as O O
baseline O O
models O O
. O O

the O O
result O O
shows O O
a O O
tendency O O
that O O
pre- B-MethodName B-MethodName
cursor I-MethodName I-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
( O O
pre B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
) O O
crf B-MethodName B-MethodName
leads O O
to O O
a O O
slight O O
performance O O
improvement O O
compared O O
to O O
both O O
the O O
first B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
and O O
second B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crfs I-MethodName I-MethodName
in O O
most O O
cases O O
. O O

to O O
perform O O
ner B-TaskName B-TaskName
evaluation O O
, O O
two O O
types O O
of O O
feature O O
families O O
are O O
used O O
: O O
( O O
a O O
) O O
token O O
itself O O
and O O
neighbor O O
to- O O
kens O O
in O O
window O O
size O O
3 O O
. O O

the O O
named O O
entity O O
classes O O
in O O
the O O
biomedi- O O
cal O O
ner B-TaskName B-TaskName
evaluation O O
are O O
dna O O
, O O
rna O O
, O O
protein O O
, O O
cell O O
line O O
, O O
and O O
cell O O
type O O
. O O

annotated O O
named O O
entities O O
involved O O
in O O
the O O
clini- O O
cal O O
ner B-TaskName B-TaskName
evaluation O O
are O O
related O O
to O O
mentions O O
describ- O O
ing O O
the O O
patient O O
’s O O
history O O
. O O

in O O
the O O
pre B-MethodName B-MethodName
- I-MethodName I-MethodName
induced I-MethodName I-MethodName
crf I-MethodName I-MethodName
, O O
the O O
outside O O
state O O
with O O
a O O
memory O O
element O O
behaves O O
as O O
if O O
an O O
information O O
transmission O O
medium O O
is O O
delivering O O
information O O
about O O
the O O
presence O O
or O O
absence O O
of O O
the O O
preceding O O
en- O O
tity O O
forward O O
. O O

the O O
main O O
purpose O O
of O O
the O O
precursor O O
- O O
induced I-MethodName B-MethodName
crf I-MethodName I-MethodName
model O O
, O O
introduced O O
in O O
this O O
study O O
, O O
is O O
to O O
capture O O
spe- O O
cific O O
high O O
- O O
order O O
named O O
entity O O
dependency O O
that O O
is O O
an O O
outside O O
word O O
sequence O O
between O O
two O O
nes O O
. O O

2 O O
precursor O O
- O O
induced O O
crf B-MethodName B-MethodName
prior O O
to O O
introducing O O
the O O
new O O
model O O
formulation O O
, O O
the O O
following O O
information O O
presents O O
the O O
general O O
con- O O
cept O O
of O O
crf B-MethodName B-MethodName
. O O

10 O O
kens O O
, O O
this O O
study O O
explores O O
the O O
method O O
which O O
modi- O O
fies O O
the O O
first B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
linear I-MethodName I-MethodName
- I-MethodName I-MethodName
chain I-MethodName I-MethodName
crf I-MethodName I-MethodName
by O O
using O O
the O O
induction O O
method O O
. O O

previous O O
studies O O
have O O
demonstrated O O
that O O
implementation O O
of O O
the O O
higher- O O
order O O
crf B-MethodName B-MethodName
exploiting O O
pre O O
- O O
defined O O
label O O
patterns O O
leads O O
to O O
slight O O
performance O O
improvement O O
in O O
the O O
conventional O O
crf B-MethodName B-MethodName
in O O
ner B-TaskName B-TaskName
( O O
cuong O O
, O O
ye O O
, O O
lee O O
, O O
& O O
chieu O O
, O O
2014 O O
; O O
fersini O O
, O O
messina O O
, O O
felici O O
, O O
& O O
roth O O
, O O
2014 O O
; O O
sarawagi O O
& O O
cohen O O
, O O
2005 O O
; O O
ye O O
et O O
al O O
. O O
, O O

only O O
dependencies O O
between O O
neighbor O O
labels O O
are O O
generally O O
used O O
in O O
practice O O
because O O
conventional O O
high O O
- O O
order O O
crfs B-MethodName B-MethodName
are O O
known O O
to O O
be O O
intractable O O
in O O
ner B-TaskName B-TaskName
( O O
ye O O
, O O
lee O O
, O O
chieu O O
, O O
& O O
wu O O
, O O
2009 O O
) O O
. O O

one O O
major O O
issue O O
in O O
previous O O
studies O O
was O O
con- O O
cerned O O
with O O
the O O
way O O
in O O
which O O
to O O
explore O O
long O O
- O O
dis- O O
tance O O
dependencies O O
in O O
ner B-TaskName B-TaskName
. O O

in O O
contrast O O
, O O
a O O
crf B-MethodName B-MethodName
in O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
( O O
ner B-TaskName B-TaskName
) O O
can O O
not O O
fully O O
capture O O
dependencies O O
between O O
named O O
entity O O
( O O
ne O O
) O O
labels O O
. O O

one O O
of O O
the O O
primary O O
advantages O O
of O O
applying O O
the O O
crf B-MethodName B-MethodName
to O O
language O O
processing O O
is O O
that O O
it O O
learns O O
transi- O O
tion O O
factors O O
between O O
hidden O O
variables O O
correspond- O O
ing O O
to O O
the O O
label O O
of O O
single O O
word O O
. O O

even O O
in O O
deep O O
- O O
learn- O O
ing O O
architecture O O
, O O
crf B-MethodName B-MethodName
has O O
been O O
used O O
as O O
a O O
funda- O O
mental O O
element O O
in O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
( O O
lample O O
, O O
ballesteros O O
, O O
subramanian O O
, O O
kawakami O O
, O O
& O O
dyer O O
, O O
2016 O O
; O O
liu O O
, O O
tang O O
, O O
wang O O
, O O
& O O
chen O O
, O O
2017 O O
) O O
. O O

1 O O
introduction O O
the O O
concept O O
of O O
conditional B-MethodName B-MethodName
random I-MethodName I-MethodName
fields I-MethodName I-MethodName
( O O
crfs B-MethodName B-MethodName
) O O
( O O
john O O
lafferty O O
, O O
andrew O O
mccallum O O
, O O
& O O
fernando O O
pereira O O
, O O
2001 O O
) O O
has O O
been O O
successfully O O
adapted O O
in O O
many O O
sequence O O
labeling O O
problems O O
( O O
andrew O O
mccallum O O
& O O
wei O O
li O O
, O O
2003 O O
; O O
fei O O
sha O O
& O O
fernando O O
pereira O O
, O O
2003 O O
; O O
john O O
lafferty O O
et O O
al O O
. O O
, O O

then O O
, O O
empirical O O
results O O
apparently O O
demonstrate O O
that O O
it O O
is O O
possible O O
to O O
exploit O O
long O O
- O O
distance O O
label O O
dependency O O
in O O
the O O
orig- O O
inal O O
first B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
linear I-MethodName I-MethodName
chain I-MethodName I-MethodName
crf I-MethodName I-MethodName
structure O O
upon O O
ner B-TaskName B-TaskName
while O O
reducing O O
computational O O
loss O O
rather O O
than O O
in O O
the O O
second B-MethodName B-MethodName
- I-MethodName I-MethodName
order I-MethodName I-MethodName
crf I-MethodName I-MethodName
. O O

the O O
proposed O O
design O O
uses O O
outside O O
label O O
in O O
ner B-TaskName B-TaskName
as O O
a O O
transmission O O
me- O O
dium O O
of O O
precedent O O
entity O O
information O O
on O O
the O O
crf B-MethodName B-MethodName
. O O

com- O O
pared O O
with O O
the O O
previous O O
methods O O
, O O
our O O
leam B-MethodName B-MethodName
al- O O
gorithm O O
requires O O
much O O
lower O O
computational O O
cost O O
, O O
and O O
achieves O O
better O O
if O O
not O O
comparable O O
performance O O
relative O O
to O O
the O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
. O O

( O O
a O O
) O O
yahoo B-DatasetName B-DatasetName
dataset I-DatasetName I-DatasetName
( O O
b O O
) O O
clinical O O
text O O
figure O O
4 O O
: O O
visualization O O
of O O
learned O O
attention O O
. O O

cnn B-MethodName B-MethodName
con- O O
sistently O O
outperforms O O
the O O
basic O O
bi B-MethodName B-MethodName
- I-MethodName I-MethodName
gru I-MethodName I-MethodName
architec- O O
ture O O
, O O
and O O
the O O
logistic B-MethodName B-MethodName
regression I-MethodName I-MethodName
baseline O O
performs O O
worse O O
than O O
all O O
deep O O
learning O O
architectures O O
. O O

leam B-MethodName B-MethodName
pro- O O
vides O O
the O O
best O O
auc B-MetricName B-MetricName
score O O
, O O
and O O
better O O
f1 B-MetricName B-MetricName
and O O
p@5 B-MetricName B-MetricName
values O O
than O O
all O O
methods O O
except O O
cnn O O
. O O

2018 O O
) O O
to O O
consider O O
the O O
micro O O
- O O
averaged O O
and O O
macro O O
- O O
averaged O O
f1 B-MetricName B-MetricName
and O O
area B-MetricName B-MetricName
under I-MetricName I-MetricName
the I-MetricName I-MetricName
roc I-MetricName I-MetricName
curve I-MetricName I-MetricName
( O O
auc B-MetricName B-MetricName
) O O
, O O
as O O
well O O
as O O
the O O
preci- B-MetricName B-MetricName
sion I-MetricName I-MetricName
atn(p@n B-MetricName B-MetricName
) O O
. O O

we O O
also O O
compare O O
with O O
three O O
recent O O
methods O O
for O O
multi B-TaskName B-TaskName
- I-TaskName I-TaskName
label I-TaskName I-TaskName
classiﬁcation I-TaskName I-TaskName
of O O
clinical O O
text O O
, O O
including O O
condensed B-MethodName B-MethodName
memory I-MethodName I-MethodName
net- I-MethodName I-MethodName
works I-MethodName I-MethodName
( O O
c B-MethodName B-MethodName
- I-MethodName I-MethodName
memnn I-MethodName I-MethodName
) O O
( O O
prakash O O
et O O
al O O
. O O
, O O

5.3 O O
applications O O
to O O
clinical O O
text O O
to O O
demonstrate O O
the O O
practical O O
value O O
of O O
label O O
embed- O O
dings O O
, O O
we O O
apply O O
leam B-MethodName B-MethodName
for O O
a O O
real O O
health O O
care O O
sce- O O
nario O O
: O O
medical O O
code O O
prediction O O
on O O
the O O
electronic O O
health O O
records O O
dataset O O
. O O

we O O
visualize O O
two O O
examples O O
in O O
figure O O
4(a O O
) O O
for O O
the O O
yahoo B-DatasetName B-DatasetName
dataset I-DatasetName I-DatasetName
. O O

the O O
high O O
on O O
- O O
diagonal O O
elements O O
and O O
low O O
off O O
- O O
diagonal O O
elements O O
in O O
figure O O
3(a O O
) O O
indicate O O
the O O
superb O O
ability O O
of O O
the O O
label O O
representations O O
learned O O
from O O
leam B-MethodName B-MethodName
. O O

5.2 O O
representational O O
ability O O
label O O
embeddings O O
are O O
highly O O
meaningful O O
to O O
provide O O
insight O O
into O O
the O O
meaningfulness O O
of O O
the O O
learned O O
representations O O
, O O
in O O
figure O O
3 O O
we O O
visual- O O
ize O O
the O O
correlation O O
between O O
label O O
embeddings O O
and O O
document O O
embeddings O O
based O O
on O O
the O O
yahoo B-DatasetName B-DatasetName
date- I-DatasetName I-DatasetName
set I-DatasetName I-DatasetName
. O O

the O O
topic B-TaskName B-TaskName
classiﬁcation I-TaskName I-TaskName
tasks O O
generally O O
requires O O
a O O
larger O O
r B-HyperparameterName B-HyperparameterName
, O O
while O O
senti- B-TaskName B-TaskName
ment I-TaskName I-TaskName
classiﬁcation I-TaskName I-TaskName
tasks O O
allows O O
relatively O O
smaller O O
r. B-HyperparameterName B-HyperparameterName
one O O
may O O
safely O O
choose O O
raround O O
50if B-HyperparameterValue B-HyperparameterValue
not O O
ﬁne- O O
tuning O O
. O O

leam B-MethodName B-MethodName
uses O O
much O O
less O O
model O O
parameters O O
, O O
and O O
converges O O
signiﬁcantlymodel O O
# O O
parameters O O
time O O
cost O O
( O O
s O O
) O O
cnn O O
541k O O
171 O O
lstm O O
1.8 O O
m O O
598 O O
swem O O
61 O O
k O O
63 O O
bi O O
- O O
blosan O O
3.6 O O
m O O
292 O O
leam O O
65 O O
k O O
65 O O
table O O
4 O O
: O O
comparison O O
of O O
model O O
size O O
and O O
speed O O
. O O

2014 O O
) O O
is O O
employed O O
on O O
the O O
ﬁnal O O
mlp O O
layer O O
, O O
with O O
dropout B-HyperparameterName B-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
0:5 B-HyperparameterValue B-HyperparameterValue
. O O

we O O
train O O
our O O
model O O
’s O O
parameters O O
with O O
the O O
adam O O
optimizer O O
( O O
kingma O O
and O O
ba O O
, O O
2014 O O
) O O
, O O
with O O
an O O
ini- B-HyperparameterName B-HyperparameterName
tial I-HyperparameterName I-HyperparameterName
learning I-HyperparameterName I-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
of O O
0:001 B-HyperparameterValue B-HyperparameterValue
, O O
and O O
a O O
minibatch B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
100 B-HyperparameterValue B-HyperparameterValue
. O O

for O O
the O O
datasets O O
without O O
representative O O
class O O
descriptions O O
, O O
one O O
may O O
initialize O O
the O O
label O O
embed- O O
dings O O
as O O
random O O
samples O O
drawn O O
from O O
a O O
standard O O
gaussian O O
distribution O O
. O O

speciﬁcally O O
, O O
we O O
note O O
that O O
the O O
text O O
em- O O
bedding O O
in O O
pte O O
is O O
similar O O
with O O
a O O
very O O
special O O
case O O
of O O
leam O O
, O O
when O O
our O O
window B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
r= O O
1 B-HyperparameterValue B-HyperparameterValue
and O O
at- O O
tention O O
score O O
is O O
uniform O O
. O O

we O O
have O O
achieved O O
a O O
pearson B-MetricName B-MetricName
’s I-MetricName I-MetricName
and O O
spearman B-MetricName B-MetricName
’s I-MetricName I-MetricName
correlation I-MetricName I-MetricName
of O O
0.94 B-MetricValue B-MetricValue
and O O
0.97 B-MetricValue B-MetricValue
respectively O O
as O O
com- O O
pared O O
to O O
that O O
of O O
0.91 B-MetricValue B-MetricValue
and O O
0.96 B-MetricValue B-MetricValue
in O O
( O O
alikaniotis O O
et O O
al O O
. O O
, O O

we O O
found O O
that O O
that O O
in O O
terms O O
of O O
all O O
these O O
parameters O O
our O O
system O O
performs O O
better O O
than O O
the O O
existing O O
, O O
lstm B-MethodName B-MethodName
, O O
bi B-MethodName B-MethodName
- I-MethodName I-MethodName
lstm I-MethodName I-MethodName
and O O
ease O O
mod- O O
els O O
. O O

it O O
is O O
worth O O
mentioning O O
here O O
that O O
all O O
these O O
mod- O O
els O O
are O O
compared O O
with O O
respect O O
to O O
the O O
qwk B-MetricName B-MetricName
score I-MetricName I-MetricName
. O O

for O O
ex- O O
ample O O
, O O
in O O
prompt O O
3 O O
, O O
6 O O
and O O
7 O O
we O O
have O O
achieved O O
an O O
qwk B-MetricName B-MetricName
of O O
0.712 B-MetricValue B-MetricValue
, O O
0.831 B-MetricValue B-MetricValue
and O O
0.815 B-MetricValue B-MetricValue
respectively O O
as O O
compared O O
to O O
the O O
best O O
reported O O
average B-MetricName B-MetricName
qwk I-MetricName I-MetricName
score I-MetricName I-MetricName
of O O
0.694 B-MetricValue B-MetricValue
, O O
0.827 B-MetricValue B-MetricValue
and O O
.0.811 B-MetricValue B-MetricValue
respectively O O
for O O
the O O
10 O O
fold O O
run O O
of O O
cnn O O
- O O
lstm O O
and O O
lstm O O
only O O
. O O

for O O
the O O
convolution O O
layer O O
, O O
the O O
win- B-HyperparameterName B-HyperparameterName
dow I-HyperparameterName I-HyperparameterName
size I-HyperparameterName I-HyperparameterName
( O O
l O O
) O O
is O O
set O O
to O O
5 B-HyperparameterValue B-HyperparameterValue
and O O
the O O
output O O
dimension B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
this I-HyperparameterName I-HyperparameterName
layer I-HyperparameterName I-HyperparameterName
( O O
dc)is O O
set O O
to O O
50 B-HyperparameterValue B-HyperparameterValue
. O O

we O O
set O O
the O O
word B-HyperparameterName B-HyperparameterName
embedding I-HyperparameterName I-HyperparameterName
dimension I-HyperparameterName I-HyperparameterName
( O O
dlt)to O O
50 B-HyperparameterValue B-HyperparameterValue
and O O
the O O
output O O
dimension B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
the I-HyperparameterName I-HyperparameterName
recurrent I-HyperparameterName I-HyperparameterName
layer I-HyperparameterName I-HyperparameterName
( O O
dr)to O O
300 B-HyperparameterValue B-HyperparameterValue
. O O

the O O
mini B-HyperparameterName B-HyperparameterName
- I-HyperparameterName I-HyperparameterName
batch I-HyperparameterName I-HyperparameterName
size I-HyperparameterName I-HyperparameterName
is O O
64 B-HyperparameterValue B-HyperparameterValue
in O O
our O O
experiments O O
and O O
we O O
train O O
the O O
network O O
for O O
400 B-HyperparameterValue B-HyperparameterValue
epochs B-HyperparameterName B-HyperparameterName
. O O

we O O
train O O
the O O
model O O
for O O
a O O
ﬁxed O O
number B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
epochs I-HyperparameterName I-HyperparameterName
( O O
around O O
8000 B-HyperparameterValue B-HyperparameterValue
) O O
and O O
then O O
choose O O
the O O
best O O
model O O
based O O
on O O
the O O
de- O O
velopment O O
set O O
. O O

in O O
each O O
fold O O
, O O
80 B-HyperparameterValue B-HyperparameterValue
% I-HyperparameterValue I-HyperparameterValue
of O O
the O O
data O O
is O O
used O O
for O O
training B-HyperparameterName B-HyperparameterName
, O O
10 B-HyperparameterValue B-HyperparameterValue
% I-HyperparameterValue I-HyperparameterValue
as O O
the O O
develop- B-HyperparameterName B-HyperparameterName
ment I-HyperparameterName I-HyperparameterName
set I-HyperparameterName I-HyperparameterName
, O O
and O O
10 B-HyperparameterValue B-HyperparameterValue
% I-HyperparameterValue I-HyperparameterValue
as O O
the O O
test B-HyperparameterName B-HyperparameterName
set I-HyperparameterName I-HyperparameterName
. O O

detection O O
t O O
ask O O
runs O O
precision B-MetricName B-MetricName
recall B-MetricName B-MetricName
f1 B-MetricName B-MetricName
run1 O O
0.6736 B-MetricValue B-MetricValue
0.8621 B-MetricValue B-MetricValue
0.7563 B-MetricValue B-MetricValue
run2 O O
0.7266 B-MetricValue B-MetricValue
0.7408 B-MetricValue B-MetricValue
0.7336 B-MetricValue B-MetricValue
identification O O
t O O
ask O O
model O O
precision B-MetricName B-MetricName
recall B-MetricName B-MetricName
f1 B-MetricName B-MetricName
run1 O O
0.4834 B-MetricValue B-MetricValue
0.5952 B-MetricValue B-MetricValue
0.5335 B-MetricValue B-MetricValue
run2 O O
0.5831 B-MetricValue B-MetricValue
0.4955 B-MetricValue B-MetricValue
0.5357 B-MetricValue B-MetricValue
position O O
t O O
ask O O
model O O
precision B-MetricName B-MetricName
recall B-MetricName B-MetricName
f1 B-MetricName B-MetricName
run1 O O
0.2741 B-MetricValue B-MetricValue
0.3177 B-MetricValue B-MetricValue
0.2943 B-MetricValue B-MetricValue
run2 O O
0.3839 B-MetricValue B-MetricValue
0.2966 B-MetricValue B-MetricValue
0.3346 B-MetricValue B-MetricValue
t O O
able O O
6 O O
: O O
results O O
on O O
evaluation O O
dataset O O
of O O
dip O O
t O O
asks O O
. O O

in O O
top1 O O
correction O O
task O O
, O O
the O O
f1 B-MetricName B-MetricName
of O O
run2 O O
ranked O O
2/9 O O
according O O
to O O
teams O O
and O O
2/23 O O
according O O
to O O
results O O
, O O
which O O
is O O
lower O O
than O O
the O O
highest O O
result O O
by O O
only O O
0.0001 B-MetricValue B-MetricValue
. O O

and O O
in O O
the O O
position O O
task O O
, O O
the O O
f1 B-MetricName B-MetricName
of O O
run2 O O
gained O O
third O O
place O O
among O O
32 O O
results O O
. O O

in O O
the O O
identification O O
task O O
, O O
the O O
f1 B-MetricName B-MetricName
of O O
run1 O O
and O O
run2 O O
ranked O O
the O O
second O O
and O O
the O O
third O O
respectively O O
. O O

the O O
first O O
run O O
of O O
our O O
system O O
( O O
run1 O O
) O O
achieved O O
the O O
highest O O
f1 B-MetricName B-MetricName
scores I-MetricName I-MetricName
in O O
the O O
detec- O O
tion O O
task O O
. O O

specifically O O
, O O
we O O
tag O O
each O O
character O O
of O O
the O O
sentences O O
and O O
then O O
use O O
the O O
lstm B-MethodName B-MethodName
- I-MethodName I-MethodName
crf I-MethodName I-MethodName
model O O
( O O
huang O O
et O O
al O O
. O O
, O O

the O O
pseudo O O
data O O
is O O
used O O
to O O
pre O O
- O O
train O O
the O O
model O O
and O O
gives O O
rise O O
to O O
improvements O O
in O O
both O O
precision B-MetricName B-MetricName
and O O
re- B-MetricName B-MetricName
call I-MetricName I-MetricName
. O O

7 O O
conclusion O O
and O O
f O O
uture O O
w O O
ork O O
in O O
cged O O
2018 O O
, O O
we O O
employ O O
the O O
sequence O O
to O O
se- O O
quence O O
learning O O
to O O
model O O
the O O
task O O
of O O
grammar B-TaskName B-TaskName
error I-TaskName I-TaskName
correction I-TaskName I-TaskName
. O O

t O O
able O O
2shows O O
the O O
ensembled O O
system O O
1 O O
+ O O
3 O O
( O O
> O O
1 O O
) O O
achieves O O
a O O
f B-MetricName B-MetricName
alse I-MetricName I-MetricName
positive I-MetricName I-MetricName
rate I-MetricName I-MetricName
( O O
fpr B-MetricName B-MetricName
) O O
at O O
4.48 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
and O O
a O O
precision B-MetricName B-MetricName
of O O
86.56 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
the O O
detection O O
of O O
erroneous O O
sentences O O
, O O
which O O
are O O
better O O
than O O
the O O
best O O
fpr B-MetricName B-MetricName
4.99 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
and O O
the O O
best O O
precision82.76 B-MetricName B-MetricName
% I-MetricValue B-MetricValue
in O O
cged O O
2018 O O
submissions O O
, O O
respec- O O
tively O O
. O O

these O O
performances O O
are O O
much O O
higher O O
than O O
the O O
best O O
in O O
cged O O
2018 O O
submissions O O
, O O
where O O
the O O
precision B-MetricName B-MetricName
is O O
29.32 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
, O O
and O O
recall B-MetricName B-MetricName
is O O
1.58 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
. O O

the O O
ensembled O O
systems O O
steadily O O
achieve O O
a O O
precision B-MetricName B-MetricName
greater O O
than O O
50 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
, O O
with O O
a O O
recall B-MetricName B-MetricName
greater O O
than O O
8 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
. O O

being O O
aware O O
of O O
the O O
significance O O
of O O
pre- B-MetricName B-MetricName
cision I-MetricName I-MetricName
in O O
a O O
grammar B-TaskName B-TaskName
error I-TaskName I-TaskName
correction I-TaskName I-TaskName
system O O
in O O
practice O O
, O O
we O O
further O O
use O O
ensembles O O
to O O
boost O O
precisions B-MetricName B-MetricName
. O O

a O O
teacher O O
would O O
always O O
prefers O O
a O O
grammar B-TaskName B-TaskName
error I-TaskName I-TaskName
correction I-TaskName I-TaskName
system O O
with O O
high O O
precision B-MetricName B-MetricName
, O O
even O O
if O O
it O O
has O O
a O O
low O O
recall B-MetricName B-MetricName
, O O
than O O
a O O
system O O
returns O O
lots O O
of O O
noises O O
. O O

in O O
real O O
scenarios O O
of O O
grammar O O
error O O
diag- O O
noses O O
, O O
the O O
evaluation O O
metrics O O
of O O
precision B-MetricName B-MetricName
, O O
re- B-MetricName B-MetricName
call I-MetricName I-MetricName
and O O
f1 B-MetricName B-MetricName
are O O
not O O
of O O
the O O
same O O
importance O O
. O O

the O O
evaluation O O
in O O
t O O
able O O
1reveals O O
that O O
the O O
use O O
of O O
pseudo O O
data O O
has O O
improved O O
both O O
pre- B-MetricName B-MetricName
cision I-MetricName I-MetricName
and O O
recall B-MetricName B-MetricName
in O O
the O O
correction O O
task O O
of O O
the O O
word O O
selection O O
errors O O
and O O
missing O O
errors O O
, O O
while O O
that O O
of O O
pos O O
tags O O
does O O
not O O
make O O
a O O
significant O O
contribution O O
. O O

w O O
e O O
use O O
the O O
default O O
settings O O
of O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
, O O
except O O
that O O
we O O
use O O
512 B-HyperparameterValue B-HyperparameterValue
dimensions B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
character I-HyperparameterName I-HyperparameterName
embeddings I-HyperparameterName I-HyperparameterName
. O O

the O O
inputs O O
to O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
models O O
are O O
as O O
simple O O
as O O
chinese O O
characters O O
and O O
pos O O
tags O O
of O O
charac- O O
ters O O
. O O

in O O
our O O
study O O
, O O
we O O
employ O O
the O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
model O O
. O O

the O O
f B-MethodName B-MethodName
airseq I-MethodName I-MethodName
models O O
are O O
pre O O
- O O
trained O O
with O O
the O O
pseudo O O
labeled O O
data O O
, O O
and O O
fine O O
- O O
tuned O O
with O O
the O O
manually O O
labeled O O
data O O
delivered O O
in O O
cged O O
. O O

it O O
has O O
been O O
the O O
main- O O
stream O O
model O O
for O O
machine B-TaskName B-TaskName
translation I-TaskName I-TaskName
nowa- O O
days O O
( O O
klein O O
et O O
al O O
. O O
, O O

y O O
u O O
and O O
chen O O
( O O
2012 O O
) O O
proposed O O
to O O
use O O
conditional B-MethodName B-MethodName
random I-MethodName I-MethodName
field I-MethodName I-MethodName
( O O
crf B-MethodName B-MethodName
) O O
( O O
lafferty O O
et O O
al O O
. O O
, O O

when O O
using O O
inputs O O
as O O
simple O O
as O O
chi- O O
nese O O
characters O O
, O O
the O O
ensembled O O
system O O
achieves O O
a O O
precision B-MetricName B-MetricName
at O O
86.56 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
the O O
detection O O
of O O
erroneous O O
sentences O O
, O O
and O O
a O O
precision B-MetricName B-MetricName
at O O
51.53 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
the O O
correction O O
of O O
errors O O
of O O
selection O O
and O O
missing O O
types O O
. O O

a O O
robust O O
riskminimization O O
based O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
sys O O
- O O
tem O O
. O O

introduction O O
to O O
the O O
conll-2003 O O
shared O O
task O O
: O O
language O O
- O O
independent O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
. O O

design O O
chal O O
- O O
lenges O O
and O O
misconceptions O O
in O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recogni I-TaskName I-TaskName
- I-TaskName I-TaskName
tion I-TaskName I-TaskName
. O O

named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
with O O
document O O
- O O
speciﬁc O O
kb O O
tag O O
gazetteers O O
. O O

others O O
, O O
usedexternal O O
knowledge O O
by O O
exploiting O O
the O O
associationbetween O O
ner B-TaskName B-TaskName
and O O
ned B-TaskName B-TaskName
( O O
durrett O O
and O O
klein,2014;radford O O
et O O
al O O
. O O

previous O O
work O O
has O O
already O O
regarded O O
ner B-TaskName B-TaskName
asa O O
knowledge O O
intensive O O
task O O
( O O
florian O O
et O O
al O O
. O O

, O O
2016 O O
; O O
65 O O
70 O O
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentitygerman O O
- O O
testgerman O O
- O O
devspanish O O
- O O
testspanish O O
- O O
dev O O
figure O O
3 O O
: O O
ner B-TaskName B-TaskName
f1for B-MetricName B-MetricName
german O O
on O O
conll2003gdataset B-DatasetName B-DatasetName
and O O
spanish O O
on O O
conll2002 B-DatasetName B-DatasetName
dataset O O
. O O

a O O
recent O O
trend O O
hasachieved O O
particularly O O
good O O
results O O
modeling O O
neras B-TaskName B-TaskName
an O O
end O O
- O O
to O O
- O O
end O O
task O O
using O O
neural O O
networks O O
( O O
dossantos O O
and O O
guimar˜aes,2015;chiu O O
and O O
nichols,2016;lample O O
et O O
al O O
. O O

, O O
2016 O O
) O O
in O O
german O O
and O O
1.98 B-MetricValue B-MetricValue
f1points B-MetricName B-MetricName
on O O
( O O
yang O O
et O O
al O O
. O O

our O O
system O O
lags O O
only O O
1.56 B-MetricValue B-MetricValue
f1pointson B-MetricName B-MetricName
( O O
lample O O
et O O
al O O
. O O

performance O O
is O O
evaluatedon O O
conll2003 B-DatasetName B-DatasetName
g O O
( O O
sang O O
and O O
meulder,2003 O O
) O O
forgerman O O
and O O
conll2002 B-DatasetName B-DatasetName
( O O
tjong O O
kim O O
sang,2002)for O O
spanish O O
. O O

interestingly O O
, O O
lo O O
- O O
cations O O
register O O
a O O
slight O O
decline O O
between O O
kb O O
andentity O O
( O O
0.56f1points).finally B-MetricValue B-MetricValue
, O O
fig.1bshows O O
the O O
performance O O
overspan O O
detection O O
, O O
which O O
is O O
the O O
span O O
where O O
the O O
namedentity O O
occurs O O
without O O
taking O O
type O O
information O O
intoaccount O O
. O O

the O O
positive O O
effect O O
is O O
par O O
- O O
ticularly O O
strong O O
for O O
persons O O
, O O
improving O O
more O O
than15f1points B-MetricValue B-MetricValue
( O O
78.70 B-MetricValue B-MetricValue
to O O
94.28 B-MetricValue B-MetricValue
) O O
. O O

75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityconll2003 B-DatasetName B-DatasetName
- O O
testconll2003 B-DatasetName B-DatasetName
- O O
devmuc-7 O O
- O O
testmuc-7 O O
- O O
dev(b O O
) O O
span O O
- O O
basedf1score B-MetricName B-MetricName
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityfperforgflocfmiscfall O O
( O O
c O O
) O O
type O O
- O O
based O O
nerf1score B-TaskName B-TaskName
on O O
conll2003 B-DatasetName B-DatasetName
- O O
test O O
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityfperforgflocfall O O
( O O
d O O
) O O
type O O
- O O
based O O
nerf1score B-TaskName B-TaskName
on O O
muc-7 O O
- O O
testfigure O O
1 O O
: O O
evaluation O O
results O O
by O O
type O O
conll2003 B-DatasetName B-DatasetName
- O O
test O O
and O O
muc-7-test.locations O O
, O O
but O O
the O O
successive O O
increment O O
is O O
sharper O O
. O O

244 O O
75 O O
80 O O
85 O O
90 O O
95 O O
100 O O
anamekbentityconll2003 B-DatasetName B-DatasetName
- O O
testconll2003 B-DatasetName B-DatasetName
- O O
devmuc-7 O O
- O O
testmuc-7 O O
- O O
dev O O
( O O
a O O
) O O
nerf1score B-TaskName B-TaskName
. O O

to O O
perform O O
our O O
study O O
we O O
use O O
a O O
lin B-MethodName B-MethodName
- I-MethodName I-MethodName
ear I-MethodName I-MethodName
chain I-MethodName I-MethodName
crf(lafferty I-MethodName I-MethodName
et O O
al O O
. O O

we O O
evaluate O O
on O O
two O O
standard O O
nerdatasetsconll2003.(sang B-DatasetName B-DatasetName
and O O
meulder,2003),a O O
collection O O
of O O
english O O
newswires O O
covering O O
enti O O
- O O
ties O O
with O O
four O O
types O O
( O O
per O O
, O O
org O O
, O O
loc O O
, O O
misc)andmuc-7 O O
, O O
a O O
set O O
of O O
new O O
york O O
times O O
articles(chinchor O O
and O O
robinson,1997 O O
) O O
with O O
annotationson O O
three O O
types O O
of O O
entities O O
( O O
per O O
, O O
org O O
, O O
loc).3.2 O O
incremental O O
knowledgehere O O
we O O
analyze O O
the O O
impact O O
of O O
incrementallyadding O O
external O O
knowledge O O
. O O

as O O
a O O
referencepoint O O
, O O
one O O
of O O
the O O
best O O
systems O O
to O O
date O O
( O O
chiu O O
andnichols,2016 O O
) O O
( O O
neural O O
- O O
based O O
) O O
achievesf191.62on O O
conll2013 B-DatasetName B-DatasetName
- O O
test O O
, O O
while O O
our O O
full O O
- O O
knowledgecrf O O
reachesf191.12.fig.1cshows O O
the O O
performance O O
for O O
each O O
entitytype O O
on O O
conll2003 B-DatasetName B-DatasetName
. O O

they O O
encode O O
knowl O O
- O O
edge O O
about O O
named O O
entities O O
themselves O O
or O O
their O O
us O O
- O O
ages O O
. O O

our O O
results O O
indicate O O
that O O
theamount O O
of O O
knowledge O O
is O O
highly O O
correlated O O
withner O O
performance O O
. O O

on O O
the O O
other O O
hand O O
, O O
educational O O
environment O O
has O O
also O O
been O O
improved O O
to O O
impact O O
the O O
world O O
society O O
, O O
such O O
as O O
the O O
emergence O O
of O O
moocs O O
( O O
massive O O
open O O
online O O
courses O O
) O O
, O O
and O O
new O O
learning O O
tools O O
or O O
teach O O
- O O
ing O O
paradigms O O
have O O
also O O
change O O
the O O
way O O
of O O
class O O
interactions O O
, O O
such O O
as O O
the O O
use O O
of O O
classroom O O
re O O
- O O
sponse O O
systems O O
( O O
crs O O
) O O
( O O
siau O O
et O O
al O O
. O O
, O O

On O B-MethodName
Training B-MethodName I-MethodName
Instance I-MethodName I-MethodName
Selection I-MethodName I-MethodName
for O O
Few B-TaskName B-TaskName
- I-TaskName I-TaskName
Shot I-TaskName I-TaskName
Neural I-TaskName I-TaskName
Text I-TaskName I-TaskName
Generation I-TaskName I-TaskName
Large B-MethodName B-MethodName
- I-MethodName I-MethodName
scale I-MethodName I-MethodName
pretrained I-MethodName I-MethodName
language I-MethodName I-MethodName
models I-MethodName I-MethodName
have O O
led O O
to O O
dramatic O O
improvements O O
in O O
text B-TaskName B-TaskName
generation I-TaskName I-TaskName
. O O
Impressive O O
performance O O
can O O
be O O
achieved O O
by O O
finetuning O O
only O O
on O O
a O O
small O O
number O O
of O O
instances O O
( O O
few O O
- O O
shot O O
setting O O
) O O
. O O
Nonetheless O O
, O O
almost O O
all O O
previous O O
work O O
simply O O
applies O O
random B-MethodName B-MethodName
sampling I-MethodName I-MethodName
to O O
select O O
the O O
few O O
- O O
shot O O
training O O
instances O O
. O O
Little O O
to O O
no O O
attention O O
has O O
been O O
paid O O
to O O
the O O
selection B-MethodName B-MethodName
strategies I-MethodName I-MethodName
and O O
how O O
they O O
would O O
affect O O
model O O
performance O O
. O O
In O O
this O O
work O O
, O O
we O O
present O O
a O O
study O O
on O O
training B-MethodName B-MethodName
instance I-MethodName I-MethodName
selection I-MethodName I-MethodName
in O O
few B-TaskName B-TaskName
- I-TaskName I-TaskName
shot I-TaskName I-TaskName
neural I-TaskName I-TaskName
text I-TaskName I-TaskName
generation I-TaskName I-TaskName
. O O
The O O
selection O O
decision O O
is O O
made O O
based O O
only O O
on O O
the O O
unlabeled O O
data O O
so O O
as O O
to O O
identify O O
the O O
most O O
worthwhile O O
data O O
points O O
that O O
should O O
be O O
annotated O O
under O O
some O O
budget O O
of O O
labeling O O
cost O O
. O O
Based O O
on O O
the O O
intuition O O
that O O
the O O
few O O
- O O
shot O O
training O O
instances O O
should O O
be O O
diverse O O
and O O
representative O O
of O O
the O O
entire O O
data O O
distribution O O
, O O
we O O
propose O O
a O O
simple O O
selection I-MethodName B-MethodName
strategy O I-MethodName
with O I-MethodName
K B-MethodName I-MethodName
- I-MethodName I-MethodName
means O I-MethodName
clustering I-MethodName I-MethodName
. O O
We O O
show O O
that O O
even O O
with O O
the O O
naive O O
clustering O O
- O O
based O O
approach O O
, O O
the O O
generation O O
models O O
consistently O O
outperform O O
random B-MethodName B-MethodName
sampling I-MethodName I-MethodName
on O O
three O O
text O O
generation I-TaskName O
tasks O O
: O O
data O B-TaskName
- O I-TaskName
to O I-TaskName
- O I-TaskName
text O I-TaskName
generation I-TaskName I-TaskName
, O O
document B-TaskName B-TaskName
summarization I-TaskName I-TaskName
and O O
question B-TaskName B-TaskName
generation I-TaskName I-TaskName
. O O
The O O
code O O
and O O
training O O
data O O
are O O
made O O
available O O
at O O
https://gitlab.com/erniecyc/ O O
few B-MethodName O
- O O
selector O O
. O O
We O O
hope O O
that O O
this O O
work O O
will O O
call O O
for O O
more O O
attention O O
on O O
this O O
largely O O
unexplored O O
area O O
. O O
* O O
Equal O O
contribution O O
. O O
X.shen O O
is O O
now O O
at O O
Amazon O O
Alexa O O
AI O O
. O O

Coach B-MethodName B-MethodName
: O O
A O O
Coarse O O
- O O
to O O
- O O
Fine O O
Approach O O
for O O
Cross O O
- O O
domain O O
Slot B-TaskName B-TaskName
Filling I-TaskName I-TaskName
As O O
an O O
essential O O
task B-TaskName B-TaskName
in O O
task B-TaskName B-TaskName
- O O
oriented O O
dialog O O
systems O O
, O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
requires O O
extensive O O
training B-TaskName B-DatasetName
data I-DatasetName I-DatasetName
in O O
a O O
certain O O
domain O O
. O O

However O O
, O O
such O O
data O O
are O O
not O O
always O O
available O O
. O O

Hence O O
, O O
cross O O
- O O
domain O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
has O O
naturally O O
arisen O O
to O O
cope O O
with O O
this O O
data O O
scarcity O O
problem O O
. O O

In O O
this O O
paper O O
, O O
we O O
propose O O
a O O
Coarse O O
- O O
to O O
- O O
fine O O
approach O O
( O O
Coach B-MethodName B-MethodName
) O O
for O O
cross O O
- O O
domain O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
. O O

Our O O
model O O
first O O
learns O O
the O O
general O O
pattern O O
of O O
slot O O
entities O O
by O O
detecting O O
whether O O
the O O
tokens O O
are O O
slot O O
entities O O
or O O
not O O
. O O

It O O
then O O
predicts O O
the O O
specific O O
types O O
for O O
the O O
slot O O
entities O O
. O O

In O O
addition O O
, O O
we O O
propose O O
a O O
template B-MethodName B-MethodName
regularization I-MethodName I-MethodName
approach O O
to O O
improve O O
the O O
adaptation B-MetricName B-MetricName
robustness I-MetricName I-MetricName
by O O
regularizing B-MethodName B-MethodName
the I-MethodName I-MethodName
representation I-MethodName I-MethodName
of O O
utterances O O
based O O
on O O
utterance O O
templates O O
. O O

Experimental O O
results O O
show O O
that O O
our O O
model O O
significantly O O
outperforms O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
approaches O O
in O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
. O O

Furthermore O O
, O O
our O O
model O O
can O O
also O O
be O O
applied O O
to O O
the O O
cross O O
- O O
domain O O
named B-TaskName B-MethodName
entity I-TaskName I-MethodName
recognition I-TaskName I-MethodName
task I-MethodName I-MethodName
, O O
and O O
it O O
achieves O O
better O O
adaptation B-MetricName B-MetricName
performance I-MetricName I-MetricName
than O O
other O O
existing O O
baselines O O
. O O

Introduction O O

Slot B-MethodName B-MethodName
filling I-MethodName I-MethodName
models I-MethodName I-MethodName
identify O O
task O O
- O O
related O O
slot O O
types O O
in O O
certain O O
domains O O
for O O
user O O
utterances O O
, O O
and O O
are O O
an O O
indispensable O O
part O O
of O O
task O O
- O O
oriented O O
dialog O O
systems O O
. O O

Supervised O O
approaches O O
have O O
made O O
great O O
achievements O O
in O O
the O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
task O O
( O O
Goo O O
et O O
al O O
. O O
, O O
2018 O O
; O O
, O O
where O O
substantial O O
labeled O O
training B-DatasetName B-DatasetName
samples I-DatasetName I-DatasetName
are O O
needed O O
. O O

However O O
, O O
collecting O O
large O O
numbers O O
of O O
training B-DatasetName B-DatasetName
samples I-DatasetName I-DatasetName
is O O
not O O
only O O
expensive O O
but O O
also O O
time O O
- O O
consuming O O
. O O

To O O
cope O O
with O O
the O O
data O O
scarcity O O
issue O O
, O O
we O O
are O O
motivated O O
to O O
investigate O O
cross O O
- O O
domain O O
slot B-MethodName B-MethodName
filling I-MethodName I-MethodName
methods I-MethodName I-MethodName
, O O
which O O
leverage O O
knowledge O O
learned O O
in O O
the O O
source O O
domains O O
and O O
adapt O O
the O O
models O O
to O O
the O O
target O O
domain O O
with O O
a O O
minimum O O
number O O
of O O
target O O
domain O O
labeled O O
training B-DatasetName B-DatasetName
samples I-DatasetName I-DatasetName
. O O

A O O
challenge O O
in O O
cross O O
- O O
domain O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
is O O
to O O
handle O O
unseen O O
slot O O
types O O
, O O
which O O
prevents O O
general O O
Playlist O O
Music O O
Item O O
Step O O
1 O O
Step O O
2 O O
Step O O
2 O O
( O O
b O O
) O O
Our O O
proposed O O
framework O O
, O O
Coach B-MethodName B-MethodName
. O O

classification B-MethodName B-MethodName
models I-MethodName I-MethodName
from O O
adapting O O
to O O
the O O
target O O
domain O O
without O O
any O O
target O O
domain O O
supervision O O
signals O O
. O O

Recently O O
, O O
Bapna O O
et O O
al O O
. O O
( O O
2017 O O
) O O
proposed O O
a O O
cross O O
- O O
domain O O
slot B-MethodName B-MethodName
filling I-MethodName I-MethodName
framework I-MethodName I-MethodName
, O O
which O O
enables O O
zero B-MethodName B-MethodName
- I-MethodName I-MethodName
shot I-MethodName I-MethodName
adaptation I-MethodName I-MethodName
. O O

As O O
illustrated O O
in O O
Figure O O
1a O O
, O O
their O O
model O O
conducts O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
individually O O
for O O
each O O
slot O O
type O O
. O O

It O O
first O O
generates O O
word O O
- O O
level O O
representations O O
, O O
which O O
are O O
then O O
concatenated O O
with O O
the O O
representation O O
of O O
each O O
slot O O
type O O
description O O
, O O
and O O
the O O
predictions O O
are O O
based O O
on O O
the O O
concatenated O O
features O O
for O O
each O O
slot O O
type O O
. O O

Due O O
to O O
the O O
inherent O O
variance O O
of O O
slot O O
entities O O
across O O
different O O
domains O O
, O O
it O O
is O O
difficult O O
for O O
this O O
framework O O
to O O
capture O O
the O O
whole O O
slot O O
entity O O
( O O
e.g. O O
, O O
" O O
latin O O
dance O O
cardio O O
" O O
in O O
Figure O O
1a O O
) O O
in O O
the O O
target O O
domain O O
. O O

There O O
also O O
exists O O
a O O
multiple O O
prediction O O
problem O O
. O O

For O O
example O O
, O O
" O O
tune O O
" O O
in O O
Figure O O
1a O O
could O O
be O O
predicted O O
as O O
" O O
B O O
" O O
for O O
both O O
" O O
music O O
item O O
" O O
and O O
" O O
playlist O O
" O O
, O O
which O O
would O O
cause O O
additional O O
trouble O O
for O O
the O O
final O O
prediction O O
. O O

We O O
emphasize O O
that O O
in O O
order O O
to O O
capture O O
the O O
whole O O
slot O O
entity O O
, O O
it O O
is O O
pivotal O O
for O O
the O O
model O O
to O O
share O O
its O O
parameters O O
for O O
all O O
slot O O
types O O
in O O
the O O
source O O
domains O O
and O O
learn O O
the O O
general O O
pattern O O
of O O
slot O O
entities O O
. O O

Therefore O O
, O O
as O O
depicted O O
in O O
Figure O O
1b O O
Regularization O O
Loss O O
Step O O
One O O
Step O O
Two O O
Can O O
you O O
put O O
this O O
music O O
item O O
onto O O
playlist O O
Incorrect O O
... O O
Can O O
you O O
put O O
this O O
object O O
name O O
onto O O
city O O
Figure O O
2 O O
: O O
Illustration O O
of O O
our O O
framework O O
, O O
Coach B-MethodName B-MethodName
, O O
and O O
the O O
template B-MethodName B-MethodName
regularization I-MethodName I-MethodName
approach O O
. O O

a O O
coarse O O
- O O
to O O
- O O
fine O O
approach O O
. O O

It O O
first O O
coarsely O O
learns O O
the O O
slot O O
entity O O
pattern O O
by O O
predicting O O
whether O O
the O O
tokens O O
are O O
slot O O
entities O O
or O O
not O O
. O O

Then O O
, O O
it O O
combines O O
the O O
features O O
for O O
each O O
slot O O
entity O O
and O O
predicts O O
the O O
specific O O
( O O
fine O O
) O O
slot O O
type O O
based O O
on O O
the O O
similarity O O
with O O
the O O
representation O O
of O O
each O O
slot O O
type O O
description O O
. O O

In O O
this O O
way O O
, O O
our O O
framework O O
is O O
able O O
to O O
avoid O O
the O O
multiple O O
predictions O O
problem O O
. O O

Additionally O O
, O O
we O O
introduce O O
a O O
template B-MethodName B-MethodName
regularization I-MethodName I-MethodName
method I-MethodName I-MethodName
that O O
delexicalizes O O
slot O O
entity O O
tokens O O
in O O
utterances O O
into O O
different O B-DatasetName
slot I-DatasetName I-DatasetName
labels I-DatasetName I-DatasetName
and O O
produces O O
both O O
correct O O
and O O
incorrect O O
utterance I-DatasetName B-DatasetName
templates I-DatasetName I-DatasetName
to O O
regularize O O
the O O
utterance O O
representations O O
. O O

By O O
doing O O
so O O
, O O
the O O
model O O
learns O O
to O O
cluster O O
the O O
representations O O
of O O
semantically O O
similar O O
utterances O O
( O O
i.e. O O
, O O
in O O
the O O
same O O
or O O
similar O O
templates O O
) O O
into O O
a O O
similar O O
vector O O
space O O
, O O
which O O
further O O
improves O O
the O O
adaptation B-MetricName B-MetricName
robustness I-MetricName I-MetricName
. O O

Experimental O O
results O O
show O O
that O O
our O O
model O O
surpasses O O
the O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
methods O O
by O O
a O O
large O O
margin O O
in O O
both O O
zero O O
- O O
shot O O
and O O
few O O
- O O
shot O O
scenarios O O
. O O

In O O
addition O O
, O O
further O O
experiments O O
show O O
that O O
our O O
framework O O
can O O
be O O
applied O O
to O O
cross O O
- O O
domain O O
named B-TaskName B-TaskName
entity I-TaskName I-TaskName
recognition I-TaskName I-TaskName
, O O
and O O
achieves O O
better O O
adaptation B-MetricName B-MetricName
performance I-MetricName I-MetricName
than O O
other O O
existing O O
frameworks O O
. O O

Related O O
Work O O

Coarse O O
- O O
to O O
- O O
fine O O
methods O O
in O O
NLP O O
are O O
best O O
known O O
for O O
syntactic B-MethodName B-MethodName
parsing I-MethodName I-MethodName
( O O
Charniak O O
et O O
al O O
. O O
, O O
2006;Petrov O O
, O O
2011 O O
) O O
. O O
Zhang O O
et O O
al O O
. O O
( O O
2017 O O
) O O
reduced O O
the O O
search O O
space O O
of O O
semantic O O
parsers O O
by O O
using O O
coarse O O
macro O O
grammars O O
. O O

Different O O
from O O
the O O
previous O O
work O O
, O O
we O O
apply O O
the O O
idea O O
of O O
coarse O O
- O O
to O O
- O O
fine O O
into O O
cross O O
- O O
domain O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
to O O
handle O O
unseen O O
slot O O
types O O
by O O
separating O O
the O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
task I-TaskName I-TaskName
into O O
two O O
steps O O
( O O
Zhai O O
et O O
al O O
. O O
, O O
2017 O O
Guerini O O
et O O
al O O
. O O
, O O
2018 O O
) O O
. O O

Coping O O
with O O
low B-TaskName B-TaskName
- I-TaskName I-TaskName
resource I-TaskName I-TaskName
problems I-TaskName I-TaskName
where O O
there O O
are O O
zero O O
or O O
few O O
existing O O
training O O
samples O O
has O O
always O O
been O O
an O O
interesting O O
and O O
challenging O O
task O O
( O O
Kingma O O
et O O
al O O
. O O
, O O
2014;Lample O O
et O O
al O O
. O O
, O O
2018;Liu O O
et O O
al O O
. O O
, O O
2019a O O
, O O
b O O
; O O
. O O

Cross O O
- O O
domain O O
adaptation O O
addresses O O
the O O
data O O
scarcity O O
problem O O
in O O
low O O
- O O
resource O O
target O O
domains O O
( O O
Pan O O
et O O
al O O
. O O
, O O
2010;Jaech O O
et O O
al O O
. O O
, O O
2016;Guo O O
et O O
al O O
. O O
, O O
2018;Jia O O
et O O
al O O
. O O
, O O
2019 O O
; O O
. O O

However O O
, O O
most O O
research O O
studying O O
the O O
cross O O
- O O
domain O O
aspect O O
has O O
not O O
focused O O
on O O
predicting O O
unseen O O
label O O
types O O
in O O
the O O
target O O
domain O O
since O O
both O O
source O O
and O O
target O O
domains O O
have O O
the O O
same O O
label O O
types O O
in O O
the O O
considered O O
tasks O O
( O O
Guo O O
et O O
al O O
. O O
, O O
2018 O O
) O O
. O O

In O O
another O O
line O O
of O O
work O O
, O O
to O O
bypass O O
unseen O O
label O O
types O O
, O O
Ruder O O
and O O
Plank O O
( O O
2018 O O
) O O
and O O
Jia O O
et O O
al O O
. O O
( O O
2019 O O
) O O
utilized O O
target O O
domain O O
training B-DatasetName B-DatasetName
samples I-DatasetName I-DatasetName
, O O
so O O
that O O
there O O
was O O
no O O
unseen O O
label O O
type O O
in O O
the O O
target O O
domain O O
. O O

Recently O O
, O O
based O O
on O O
the O O
framework O O
proposed O O
by O O
Bapna O O
et O O
al O O
. O O
( O O
2017 O O
) O O
( O O
discussed O O
in O O
Section O O
1 O O
) O O
, O O
Lee O O
and O O
Jha O O
( O O
2019 O O
) O O
added O O
an O O
attention O O
layer O O
to O O
produce O O
slot O O
- O O
aware O O
representations O O
, O O
and O O
Shah O O
et O O
al O O
. O O
( O O
2019 O O
) O O
leveraged O O
slot B-TaskName B-DatasetName
examples I-DatasetName I-DatasetName
to O O
increase O O
the O O
robustness B-MetricName B-MetricName
of I-MetricName I-MetricName
cross I-MetricName I-MetricName
- I-MetricName I-MetricName
domain I-MetricName I-MetricName
slot I-MetricName I-MetricName
filling I-MetricName I-MetricName
adaptation I-MetricName I-MetricName
. O O

Methodology O O

Coach B-MethodName B-MethodName
Framework I-MethodName I-MethodName

As O O
depicted O O
in O O
Figure O O
2 O O
, O O
the O O
slot B-TaskName B-TaskName
filling I-TaskName I-TaskName
process O O
in O O
our O O
Coach B-MethodName B-MethodName
framework O O
consists O O
of O O
two O O
steps O O
. O O

In O O
the O O
first O O
step O O
, O O
we O O
utilize O O
a O O
BiLSTM B-MethodName B-MethodName
- I-MethodName I-MethodName
CRF I-MethodName I-MethodName
structure O O
( O O
Lample O O
et O O
al O O
. O O
, O O
2016 O O
) O O
to O O
learn O O
the O O
general O O
pattern O O
of O O
slot O O
entities O O
by O O
having O O
our O O
model O O
predict O O
whether O O
tokens O O
are O O
slot O O
entities O O
or O O
not O O
( O O
i.e. O O
, O O
3 O O
- O O
way O O
classification O O
for O O
each O O
token O O
) O O
. O O

In O O
the O O
second O O
step O O
, O O
our O O
model O O
further O O
predicts O O
a O O
specific O O
type O O
for O O
each O O
slot O O
entity O O
based O O
on O O
the O O
similarities O O
with O O
the O O
description O O
representations O O
of O O
all O O
possible O O
slot O O
types O O
. O O

To O O
generate O O
representations O O
of O O
slot O O
entities O O
, O O
we O O
leverage O O
another O O
encoder O O
, O O
BiLSTM B-MethodName B-MethodName
( O O
Hochreiter O O
and O O
Schmidhuber O O
, O O
1997 O O
) O O
, O O
to O O
encode O O
the O O
hidden O O
states O O
of O O
slot O O
entity O O
tokens O O
and O O
produce O O
representations O O
for O O
each O O
slot O O
entity O O
. O O

We O O
represent O O
the O O
user O O
utterance O O
with O O
n O O
tokens O O
as O O
w O O
= O O
[ O O
w O O
1 O O
, O O
w O O
2 O O
, O O
... O O
, O O
w O O
n O O
] O O
, O O
and O O
E O O
denotes O O
the O O
embedding O O
layer O O
for O O
utterances O O
. O O

The O O
whole O O
process O O
can O O
be O O
formulated O O
as O O
follows O O
: O O
[ O O
h O O
1 O O
, O O
h O O
2 O O
, O O
... O O
, O O
h O O
n O O
] O O
= O O
BiLSTM(E(w)),(1 B-MethodName B-MethodName
) O O
[ O O
p O O
1 O O
, O O
p O O
2 O O
, O O
... O O
, O O
p O O
n O O
] O O
= O O
CRF([h B-MethodName B-MethodName
1 O O
, O O
h O O
2 O O
, O O
... O O
, O O
h O O
n O O
] O O
) O O
, O O
( O O
2 O O
) O O
where O O
[ O O
p O O
1 O O
, O O
p O O
2 O O
, O O
... O O
, O O
p O O
n O O
] O O
are O O
the O O
logits O O
for O O
the O O
3 O O
- O O
way O O
classification O O
. O O

Then O O
, O O
for O O
each O O
slot O O
entity O O
, O O
we O O
take O O
its O O
hidden O O
states O O
to O O
calculate O O
its O O
representation O O
: O O
r O O
k O O
= O O
BiLSTM([h B-MethodName B-MethodName
i O O
, O O
h O O
i+1 O O
, O O
... O O
h O O
j O O
] O O
) O O
, O O
( O O
3 O O
) O O
s O O
k O O
= O O
M O O
desc O O
r  O
r O O
k O O
, O O
( O O
4 O O
) O O
where O O
r O O
k O O
denotes O O
the O O
representation O O
of O O
the O O
k O O
th O O
slot O O
entity O O
, O O
[ O O
h O O
i O O
, O O
h O O
i+1 O O
, O O
... O O
, O O
h O O
j O O
] O O
denotes O O
the O O
BiLSTM B-MethodName B-MethodName
hidden O O
states O O
for O O
the O O
k O O
th O O
slot O O
entity O O
, O O
M O O
desc O O
R  O
R O O
ns脳ds O O
is  O
the O O
representation O O
matrix O O
of O O
the O O
slot O O
description O O
( O O
n O O
s O O
is O O
the O O
number O O
of O O
possible O O
slot O O
types O O
and O O
d O O
s O O
is O O
the O O
dimension B-HyperparameterName O
of O O
slot O O
descriptions O O
) O O
, O O
and O O
s O O
k O O
is O O
the O O
specific O O
slot O O
type O O
prediction O O
for O O
this O O
k O O
th O O
slot O O
entity O O
. O O

We O O
obtain O O
the O O
slot O O
description O O
representation O O
r O O
desc O O
R  O
R O O
ds O O
by O O
summing O O
the O O
embeddings O O
of O O
the O O
N O O
slot O O
description O O
tokens O O
( O O
similar O O
to O O
Shah O O
et O O
al O O
. O O
( O O
2019 O O
) O O
): O O
r O O
desc O O
= O O
N O O
i=1 O O
E(t O O
i O O
) O O
, O O
( O O
5 O O
) O O
where O O
t O O
i O O
is O O
the O O
i O O
th O O
token O O
and O O
E O O
is O O
the O O
same O O
embedding O O
layer O O
as O O
that O O
for O O
utterances O O
. O O

Template O O
Regularization O O

In O O
many O O
cases O O
, O O
similar O O
or O O
the O O
same O O
slot O O
types O O
in O O
the O O
target O O
domain O O
can O O
also O O
be O O
found O O
in O O
the O O
source O O
domains O O
. O O

Nevertheless O O
, O O
it O O
is O O
still O O
challenging O O
for O O
the O O
model O O
to O O
recognize O O
the O O
slot O O
types O O
in O O
the O O
target O O
domain O O
owing O O
to O O
the O O
variance O O
between O O
the O O
source O O
domains O O
and O O
the O O
target O O
domain O O
. O O

To O O
improve O O
the O O
adaptation O O
ability O O
, O O
we O O
introduce O O
a O O
template B-MethodName B-MethodName
regularization I-MethodName I-MethodName
method O O
. O O

As O O
shown O O
in O O
Figure O O
2 O O
, O O
we O O
first O O
replace O O
the O O
slot O O
entity O O
tokens O O
in O O
the O O
utterance O O
with O O
different O B-DatasetName
slot I-DatasetName I-DatasetName
labels I-DatasetName I-DatasetName
to O O
generate O O
correct O O
and O O
incorrect O O
utterance O O
templates I-DatasetName O
. O O

Then O O
, O O
we O O
use O O
BiLSTM B-MethodName B-MethodName
and O O
an O O
attention O O
layer O O
( O O
Felbo O O
et O O
al O O
. O O
, O O
2017 O O
) O O
to O O
generate O O
the O O
utterance O O
and O O
template O O
representations O O
: O O
e O O
t O O
= O O
h O O
t O O
w O O
a O O
, O O
t  O
t O O
= O O
exp(e O O
t O O
) O O
n O O
j=1 O O
exp(e O O
j O O
) O O
, O O
R O O
= O O
n O O
t=1 O O
t  O
t O O
h O O
t O O
, O O
( O O
6 O O
) O O
where O O
h O O
t O O
is O O
the O O
BiLSTM B-MethodName B-MethodName
hidden O O
state O O
in O O
the O O
t O O
th O O
step O O
, O O
w O O
a O O
is O O
the O O
weight O O
vector O O
in O O
the O O
attention O O
layer O O
and O O
R O O
is O O
the O O
representation O O
for O O
the O O
input O O
utterance O O
or O O
template O O
. O O

Hence O O
, O O
in O O
the O O
training O O
phase O O
, O O
we O O
minimize O O
the O O
distance O O
between O O
R O O
u O O
and O O
R O O
r O O
and O O
maximize O O
the O O
distance O O
between O O
R O O
u O O
and O O
R O O
w O O
. O O

To O O
generate O O
a O O
wrong O O
template O O
, O O
we O O
replace O O
the O O
correct O O
slot O O
entity O O
with O O
another O O
random O O
slot O O
entity O O
, O O
and O O
we O O
generate O O
two O O
wrong O O
templates O O
for O O
each O O
utterance O O
. O O

To O O
ensure O O
the O O
representations O O
of O O
the O O
templates O O
are O O
meaningful O O
( O O
i.e. O O
, O O
similar O O
templates O O
have O O
similar O O
representations O O
) O O
for O O
training O O
R O O
u O O
, O O
in O O
the O O
first O O
several O O
epochs O O
, O O
the O O
regularization B-MetricName B-MetricName
loss I-MetricName I-MetricName
is O O
only O O
to O O
optimize O O
the O O
template O O
representations O O
, O O
and O O
in O O
the O O
following O O
epochs O O
, O O
we O O
optimize O O
both O O
template O O
representations O O
and O O
utterance O O
representations O O
. O O

By O O
doing O O
so O O
, O O
the O O
model O O
learns O O
to O O
cluster O O
the O O
representations O O
in O O
the O O
same O O
or O O
similar O O
templates O O
into O O
a O O
similar O O
vector O O
space O O
. O O

Hence O O
, O O
the O O
hidden O O
states O O
of O O
tokens O O
that O O
belong O O
to O O
the O O
same O O
slot O O
type O O
tend O O
to O O
be O O
similar O O
, O O
which O O
boosts O O
the O O
robustness B-MetricName B-MetricName
of O O
these O O
slot O O
types O O
in O O
the O O
target O O
domain O O
. O O

Experiments O O

Dataset O O

We O O
evaluate O O
our O O
framework O O
on O O
SNIPS B-DatasetName B-DatasetName
( O O
Coucke O O
et O O
al O O
. O O
, O O
2018 O O
) O O
, O O
a O O
public O O
spoken B-DatasetName B-DatasetName
language I-DatasetName I-DatasetName
understanding I-DatasetName I-DatasetName
dataset I-DatasetName I-DatasetName
which O O
contains O O
39 O O
slot O O
types O O
across O O
seven O O
domains O O
( O O
intents O O
) O O
and O O
鈭2000 O O
training B-DatasetName B-DatasetName
samples I-DatasetName O
per O O
domain O O
. O O

We O O
utilize O O
the O O
CoNLL-2003 B-DatasetName O
English O O
named B-DatasetName B-DatasetName
entity I-TaskName I-DatasetName
recognition I-TaskName I-DatasetName
( O O
NER I-DatasetName B-DatasetName
) O O
dataset O O
as O O
the O O
source O O
domain O O
( O O
Tjong O O
Kim O O
Sang O O
and O O
De O O
Meulder O O
, O O
2003 O O
) O O
, O O
and O O
the O O
CBS B-DatasetName B-DatasetName
SciTech I-DatasetName I-DatasetName
News I-DatasetName I-DatasetName
NER I-DatasetName I-DatasetName
dataset I-DatasetName I-DatasetName
from O O
Jia O O
et O O
al O O
. O O
( O O
2019 O O
) O O
as O O
the O O
target O O
domain O O
. O O

These O O
two O O
datasets O O
have O O
the O O
same O O
four O O
types O O
of O O
entities O O
, O O
namely O O
, O O
PER O O
( O O
person O O
) O O
, O O
LOC O O
( O O
location O O
) O O
, O O
ORG O O
( O O
organization O O
) O O
, O O
and O O
MISC O O
( O O
miscellaneous O O
) O O
. O O

Baselines O O

We O O
use O O
word O O
- O O
level O O
( O O
Bojanowski O O
et O O
al O O
. O O
, O O
2017 O O
) O O
and O O
character O O
- O O
level O O
( O O
Hashimoto O O
et O O
al O O
. O O
, O O
2017 O O
) O O
embeddings O O
for O O
our O O
model O O
as O O
well O O
as O O
all O O
the O O
following O O
baselines O O
. O O

Concept B-MethodName B-MethodName
Tagger I-MethodName I-MethodName
( O O
CT B-MethodName B-MethodName
) O O

Bapna O O
et O O
al O O
. O O
( O O
2017 O O
) O O
proposed O O
a O O
slot B-MethodName B-MethodName
filling I-MethodName I-MethodName
framework O O
that O O
utilizes O O
slot O O
descriptions O O
to O O
cope O O
with O O
the O O
unseen O O
slot O O
types O O
in O O
the O O
target O O
domain O O
. O O

Robust B-MethodName B-MethodName
Zero I-MethodName I-MethodName
- I-MethodName I-MethodName
shot I-MethodName I-MethodName
Tagger I-MethodName I-MethodName
( O O
RZT B-MethodName B-MethodName
) O O

Based O O
on O O
CT B-MethodName B-MethodName
, O O
Shah O O
et O O
al O O
. O O
( O O
2019 O O
) O O
leveraged O O
example O O
values O O
of O O
slots O O
to O O
improve O O
robustness B-MetricName B-MetricName
of I-MetricName I-MetricName
cross I-MetricName I-MetricName
- I-MetricName I-MetricName
domain I-MetricName I-MetricName
adaptation I-MetricName I-MetricName
. O O

BiLSTM B-MethodName B-MethodName
- O O
CRF B-MethodName B-MethodName

This O O
baseline O O
is O O
only O O
for O O
the O O
cross O O
- O O
domain O O
NER B-TaskName B-TaskName
. O O

Since O O
there O O
is O O
no O O
unseen O O
label O O
in O O
the O O
NER B-TaskName B-TaskName
target O O
domain O O
, O O
the O O
BiLSTM B-MethodName B-MethodName
- O O
CRF B-MethodName B-MethodName
( O O
Lample O O
et O O
al O O
. O O
, O O
2016 O O
) O O
uses O O
the O O
same O O
label O O
set O O
for O O
the O O
source O O
and O O
target O O
domains O O
and O O
casts O O
it O O
as O O
an O O
entity B-TaskName B-TaskName
classification I-TaskName I-TaskName
task O O
for O O
each O O
token O O
, O O
which O O
is O O
applicable O O
in O O
both O O
zero O O
- O O
shot O O
and O O
few O O
- O O
shot O O
scenarios O O
. O O

Training O O
Details O O

We O O
use O O
a O O
2 B-HyperparameterValue B-HyperparameterValue
- O O
layer B-HyperparameterName B-HyperparameterName
BiLSTM B-MethodName B-MethodName
with O O
a O O
hidden B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
200 B-HyperparameterValue B-HyperparameterValue
and O O
a O O
dropout B-HyperparameterName B-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
of O O
0.3 B-HyperparameterValue B-HyperparameterValue
for O O
both O O
the O O
template O O
encoder O O
and O O
utterance O O
encoder O O
. O O

Note O O
that O O
the O O
parameters O O
in O O
these O O
two O O
encoders O O
are O O
not O O
shared O O
. O O

The O O
BiLSTM B-MethodName B-MethodName
for O O
encoding O O
the O O
hidden B-HyperparameterName B-HyperparameterName
states I-HyperparameterName I-HyperparameterName
of O O
entity O O
tokens O O
has O O
one B-HyperparameterValue B-HyperparameterValue
layer B-HyperparameterName B-HyperparameterName
with O O
a O O
hidden B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
200 B-HyperparameterValue B-HyperparameterValue
, O O
which O O
would O O
output O O
the O O
same O O
dimension O O
as O O
the O O
concatenated O O
word O O
- O O
level O O
and O O
char O O
- O O
level O O
embeddings O O
. O O

We O O
use O O
Adam B-MethodName B-MethodName
optimizer I-MethodName I-MethodName
with O O
a O O
learning B-HyperparameterName B-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
of O O
0.0005 B-HyperparameterValue B-HyperparameterValue
. O O
Cross B-MetricName B-MetricName
- I-MetricName I-MetricName
entropy I-MetricName I-MetricName
loss I-MetricName I-MetricName
is O O
leveraged O O
to O O
train O O
the O O
3 O O
- O O
way O O
classification O O
in O O
the O O
first O O
step O O
, O O
and O O
the O O
specific O O
slot O O
type O O
predictions O O
are O O
used O O
in O O
the O O
second O O
step O O
. O O

We O O
split O O
500 B-HyperparameterValue B-HyperparameterValue
data I-DatasetName B-DatasetName
samples I-DatasetName I-DatasetName
in O O
the O O
target O O
domain O O
as O O
the O O
validation B-DatasetName B-DatasetName
set I-DatasetName I-DatasetName
for O O
choosing O O
the O O
best O O
model O O
and O O
the O O
remainder O O
are O O
used O O
for O O
the O O
test B-DatasetName B-DatasetName
set I-DatasetName I-DatasetName
. O O

We O O
implement O O
the O O
model O O
in O O
CT B-MethodName B-MethodName
and O O
RZT B-MethodName B-MethodName
and O O
follow O O
the O O
same O O
setting O O
as O O
for O O
our O O
model O O
for O O
a O O
fair O O
comparison O O
. O O

Results O O
& O O
Discussion O O

Cross O O
- O O
domain O O
Slot B-TaskName B-TaskName
Filling I-TaskName I-TaskName

Quantitative O O
Analysis O O

As O O
illustrated O O
in O O
Table O O
1 O O
, O O
we O O
can O O
clearly O O
see O O
that O O
our O O
models O O
are O O
able O O
to O O
achieve O O
significantly O O
better O O
performance O O
than O O
the O O
current O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
approach O O
( O O
RZT B-MethodName B-MethodName
) O O
. O O

The O O
CT B-MethodName B-MethodName
framework O O
suffers O O
from O O
the O O
difficulty O O
of O O
capturing O O
the O O
whole O O
slot O O
entity O O
, O O
while O O
our O O
framework O O
is O O
able O O
to O O
recognize O O
the O O
slot O O
entity O O
tokens O O
by O O
sharing O O
its O O
parameters O O
across O O
all O O
slot O O
types O O
. O O

Based O O
on O O
the O O
CT B-MethodName B-MethodName
framework O O
, O O
the O O
performance O O
of O O
RZT B-MethodName B-MethodName
is O O
still O O
limited O O
, O O
and O O
Coach B-MethodName B-MethodName
outperforms O O
RZT B-MethodName B-MethodName
by O O
a O O
3 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
F1 B-MetricName B-MetricName
- O O
score O O
in O O
the O O
zero O O
- O O
shot O O
setting O O
. O O

Additionally O O
, O O
template O O
regularization O O
further O O
improves O O
the O O
adaptation B-MetricName B-MetricName
robustness I-MetricName I-MetricName
by O O
helping O O
the O O
model O O
cluster O O
the O O
utterance O O
representations O O
into O O
a O O
similar O O
vector O O
space O O
based O O
on O O
their O O
corresponding O O
template O O
representations O O
. O O

Interestingly O O
, O O
our O O
models O O
achieve O O
impressive O O
performance O O
in O O
the O O
few O O
- O O
shot O O
scenario O O
. O O

In O O
terms O O
of O O
the O O
averaged O O
performance O O
, O O
our O O
best O O
model O O
( O O
Coach+TR B-MethodName B-MethodName
) O O
outperforms O O
RZT B-MethodName B-MethodName
by O O
8 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
and O O
9 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
F1 B-MetricName B-MetricName
- O O
scores O O
on O O
the O O
20 O O
- O O
shot O O
and O O
50 O O
- O O
shot O O
settings O O
, O O
respectively O O
. O O

This O O
enables O O
the O O
model O O
to O O
quickly O O
adapt O O
to O O
the O O
target O O
domain O O
slots O O
. O O

Analysis O O
on O O
Seen O O
and O O
Unseen O O
Slots O O

We O O
take O O
a O O
further O O
step O O
to O O
test O O
the O O
models O O
on O O
seen O O
and O O
unseen O O
slots O O
in O O
target O O
domains O O
to O O
analyze O O
the O O
effectiveness O O
of O O
our O O
approaches O O
. O O

To O O
test O O
the O O
performance O O
, O O
we O O
split O O
the O O
test B-DatasetName B-DatasetName
set I-DatasetName I-DatasetName
into O O
" O O
unseen O O
" O O
and O O
" O O
seen O O
" O O
parts O O
. O O

An O O
utterance O O
is O O
categorized O O
into O O
the O O
" O O
unseen O O
" O O
part O O
as O O
long O O
as O O
there O O
is O O
an O O
unseen O O
slot O O
( O O
i.e. O O
, O O
the O O
slot O O
does O O
not O O
exist O O
in O O
the O O
remaining O O
six O O
source O O
domains O O
) O O
in O O
it O O
. O O

Otherwise O O
we O O
categorize O O
it O O
into O O
the O O
" O O
seen O O
" O O
part O O
. O O

The O O
results O O
for O O
the O O
" O O
seen O O
" O O
and O O
" O O
unseen O O
" O O
categories O O
are O O
shown O O
in O O
Table O O
2 O O
. O O

We O O
observe O O
that O O
our O O
approaches O O
generally O O
improve O O
on O O
both O O
unseen O O
and O O
seen O O
slot O O
types O O
compared O O
to O O
the O O
baseline B-MethodName B-MethodName
models I-MethodName I-MethodName
. O O

For O O
the O O
improvements O O
in O O
the O O
unseen O O
slots O O
, O O
our O O
models O O
are O O
better O O
able O O
to O O
capture O O
the O O
unseen O O
slots O O
since O O
they O O
explicitly O O
learn O O
the O O
general O O
pattern O O
of O O
slot O O
entities O O
. O O

Interestingly O O
, O O
our O O
models O O
also O O
bring O O
large O O
improvements O O
in O O
the O O
seen O O
slot O O
types O O
. O O

We O O
conjecture O O
that O O
it O O
is O O
also O O
challenging O O
to O O
adapt O O
models O O
to O O
seen O O
slots O O
due O O
to O O
the O O
large O O
variance O O
between O O
the O O
source O O
and O O
target O O
domains O O
. O O

For O O
example O O
, O O
slot O O
entities O O
belonging O O
to O O
the O O
" O O
object O O
type O O
" O O
in O O
the O O
" O O
RateBook O O
" O O
domain O O
are O O
different O O
from O O
those O O
in O O
the O O
" O O
SearchCreativeWork O O
" O O
domain O O
. O O

Hence O O
, O O
the O O
baseline B-MethodName B-MethodName
models I-MethodName I-MethodName
might O O
fail O O
to O O
recognize O O
these O O
seen O O
slots O O
in O O
the O O
target O O
domain O O
, O O
while O O
our O O
approaches O O
can O O
adapt O O
to O O
the O O
seen O O
slot O O
types O O
more O O
quickly O O
in O O
comparison O O
. O O

In O O
addition O O
, O O
we O O
observe O O
that O O
template O O
regularization O O
improves O O
performance O O
in O O
both O O
seen O O
and O O
unseen O O
slots O O
, O O
which O O
illustrates O O
that O O
clustering O O
representations O O
based O O
on O O
templates O O
can O O
boost O O
the O O
adaptation O O
ability O O
. O O

Cross O O
- O O
domain O O
NER B-TaskName B-TaskName

From O O
Table O O
3 O O
, O O
we O O
see O O
that O O
the O O
Coach B-MethodName B-MethodName
framework O O
is O O
also O O
suitable O O
for O O
the O O
case O O
where O O
there O O
are O O
no O O
unseen O O
labels O O
in O O
the O O
target O O
domain O O
in O O
both O O
the O O
zero O O
- O O
shot O O
and O O
few O O
- O O
shot O O
scenarios O O
, O O
while O O
CT B-MethodName B-MethodName
and O O
RZT B-MethodName B-MethodName
are O O
not O O
as O O
effective O O
as O O
BiLSTM B-MethodName B-MethodName
- O O
CRF B-MethodName B-MethodName
. O O

However O O
, O O
we O O
observe O O
that O O
template O O
regularization O O
loses O O
its O O
effectiveness O O
in O O
this O O
task O O
, O O
since O O
the O O
text O O
in O O
NER B-TaskName B-TaskName
is O O
relatively O O
more O O
open O O
, O O
which O O
makes O O
it O O
hard O O
to O O
capture O O
the O O
templates O O
for O O
each O O
label O O
type O O
. O O

Ablation O O
Study O O

We O O
conduct O O
an O O
ablation O O
study O O
in O O
terms O O
of O O
the O O
methods O O
to O O
encode O O
the O O
entity O O
tokens O O
( O O
described O O
in O O
Eq O O
. O O
( O O
3 O O
) O O
) O O
to O O
investigate O O
how O O
they O O
affect O O
the O O
performance O O
. O O

Instead O O
of O O
using O O
BiLSTM B-MethodName B-MethodName
, O O
we O O
try O O
two O O
alternatives O O
. O O

One O O
is O O
to O O
use O O
the O O
encoder B-MethodName B-MethodName
of O O
Transformer B-MethodName B-MethodName
( O O
trs B-MethodName B-MethodName
) O O
( O O
Vaswani O O
et O O
al O O
. O O
, O O
2017 O O
) O O
, O O
and O O
the O O
other O O
is O O
to O O
simply O O
sum O O
the O O
hidden O O
states O O
of O O
slot O O
entity O O
tokens O O
. O O

From O O
Table O O
4 O O
, O O
we O O
can O O
see O O
that O O
there O O
is O O
no O O
significant O O
performance O O
difference O O
among O O
different O O
methods O O
, O O
and O O
we O O
observe O O
that O O
using O O
BiLSTM B-MethodName B-MethodName
to O O
encode O O
the O O
entity O O
tokens O O
generally O O
achieves O O
better O O
results O O
. O O

Conclusion O O

We O O
introduce O O
a O O
new O O
cross O O
slot B-MethodName B-MethodName
filling I-MethodName I-MethodName
framework O O
to O O
handle O O
the O O
unseen O O
slot O O
type O O
issue O O
. O O

Our O O
model O O
shares O O
its O O
parameters O O
across O O
all O O
slot O O
types O O
and O O
learns O O
to O O
predict O O
whether O O
input O O
tokens O O
are O O
slot O O
entities O O
or O O
not O O
. O O

Then O O
, O O
it O O
detects O O
concrete O O
slot O O
types O O
for O O
these O O
slot O O
entity O O
tokens O O
based O O
on O O
the O O
slot O O
type O O
descriptions O O
. O O

Moreover O O
, O O
template B-MethodName B-MethodName
regularization I-MethodName I-MethodName
is O O
proposed O O
to O O
improve O O
the O O
adaptation B-MetricName B-MetricName
robustness I-MetricName I-MetricName
further O O
. O O

Experiments O O
show O O
that O O
our O O
model O O
significantly O O
outperforms O O
existing O O
cross O O
- O O
domain O O
slot B-MethodName B-MethodName
filling I-MethodName I-MethodName
approaches O O
, O O
and O O
it O O
also O O
achieves O O
better O O
performance O O
for O O
the O O
cross O O
- O O
domain O O
NER B-TaskName B-TaskName
task O O
, O O
where O O
there O O
is O O
no O O
unseen O O
label O O
type O O
in O O
the O O
target O O
domain O O
. O O

Acknowledgments O O

This O O
work O O
is O O
partially O O
funded O O
by O O
ITF/319/16FP O O
and O O
MRP/055/18 O O
of O O
the O O
Innovation O O
Technology O O
Commission O O
, O O
the O O
Hong O O
Kong O O
SAR O O
Government O O
. O O

Have O O
my O O
arguments O O
been O O
replied O O
to O O
? O O
Argument B-TaskName B-TaskName
Pair I-TaskName I-TaskName
Extraction I-TaskName I-TaskName
as O O
Machine B-TaskName B-TaskName
Reading I-TaskName I-TaskName
Comprehension I-TaskName I-TaskName

Argument B-TaskName B-TaskName
pair I-TaskName I-TaskName
extraction I-TaskName I-TaskName
( O O
APE B-TaskName B-TaskName
) O O
aims O O
to O O
automatically O O
mine O O
argument O O
pairs O O
from O O
two B-DatasetName B-DatasetName
interrelated I-DatasetName I-DatasetName
argumentative I-DatasetName I-DatasetName
documents I-DatasetName I-DatasetName
. O O

Existing O O
studies O O
typically O O
identify O O
argument O O
pairs O O
indirectly O O
by O O
predicting O O
sentence O O
- O O
level O O
relations O O
between O O
two B-DatasetName B-DatasetName
documents I-DatasetName I-DatasetName
, O O
neglecting O O
the O O
modeling O O
of O O
the O O
holistic O O
argument O O
- O O
level O O
interactions O O
. O O

Towards O O
this O O
issue O O
, O O
we O O
propose O O
to O O
address O O
APE B-TaskName B-TaskName
via O O
a O O
machine B-TaskName B-TaskName
reading I-TaskName I-TaskName
comprehension I-TaskName I-TaskName
( O O
MRC B-TaskName B-TaskName
) O O
framework O O
with O O
two O O
phases O O
. O O

The O O
first O O
phase O O
employs O O
an O O
argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
( O O
AM B-TaskName B-TaskName
) O O
query O O
to O O
identify O O
all O O
arguments O O
in O O
two B-DatasetName B-DatasetName
documents I-DatasetName I-DatasetName
. O O

The O O
second O O
phase O O
considers O O
each O O
identified O O
argument O O
as O O
an O O
APE B-TaskName B-TaskName
query O O
to O O
extract O O
its O O
paired O O
arguments O O
from O O
another O B-DatasetName
document I-DatasetName I-DatasetName
, O O
allowing O O
to O O
better O O
capture O O
the O O
argument O O
- O O
level O O
interactions O O
. O O

Also O O
, O O
this O O
framework O O
enables O O
these O O
two O O
phases O O
to O O
be O O
jointly O O
trained O O
in O O
a O O
single O O
MRC B-TaskName B-TaskName
model I-MethodName O
, O O
thereby O O
maximizing O O
the O O
mutual O O
benefits O O
of O O
them O O
. O O

Experimental O O
results O O
demonstrate O O
that O O
our O O
approach O O
achieves O O
the O O
best O O
performance O O
, O O
outperforming O O
the O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
method O O
by O O
7.11 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
. O O

Introduction O O

As O O
a O O
salient O O
part O O
of O O
argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
( O O
AM B-TaskName B-TaskName
) O O
, O O
the O O
analysis O O
of O O
dialogical O O
argumentation O O
has O O
received O O
increasing O O
research O O
attention O O
( O O
Morio O O
and O O
Fujita O O
, O O
2018 O O
Chakrabarty O O
et O O
al O O
. O O
, O O
2019;Cheng O O
et O O
al O O
. O O
, O O
2021;Yuan O O
et O O
al O O
. O O
, O O
2021 O O
) O O
. O O

Argument B-TaskName B-TaskName
pair I-TaskName I-TaskName
extraction I-TaskName I-TaskName
( O O
APE B-TaskName B-TaskName
) O O
, O O
proposed O O
by O O
Cheng O O
et O O
al O O
. O O
( O O
2020 O O
) O O
, O O
is O O
a O O
new O O
task O O
within O O
this O O
field O O
that O O
focuses O O
on O O
extracting O O
interactive O O
argument O O
pairs O O
from O O
two B-TaskName B-TaskName
interrelated I-TaskName I-TaskName
documents I-TaskName I-TaskName
( O O
e.g. O O
, O O
peer O O
reviewer O O
and O O
rebuttal O O
) O O
. O O
Figure O O
1 O O
presents O O
an O O
example O O
of O O
APE B-TaskName B-TaskName
where O O
two B-TaskName B-DatasetName
interrelated I-DatasetName I-DatasetName
documents I-DatasetName I-DatasetName
are O O
segmented O O
into O O
arguments O O
and O O
non O O
- O O
arguments O O
at O O
sentence O O
level O O
. O O

Two O O
arguments O O
from O O
different O O
documents O O
that O O
discuss O O
the O O
same O O
issues O O
are O O
regarded O O
as O O
an O O
argument O O
pair O O
. O O

* O O
Equal O O
Contribution O O

Corresponding O O
Author O O

s O O
i O O
j O O
is O O
the O O
j O O
- O O
th O O
sentence O O
in O O
document O O
i O O
, O O
and O O
arg O O
i O O
j O O
is O O
an O O
argument O O
in O O
the O O
j O O
- O O
th O O
argument O O
pair O O
from O O
document B-DatasetName B-DatasetName
i. O O
Sentences O O
without O O
colors O O
indicate O O
non O O
- O O
arguments O O
, O O
while O O
sentences O O
covered O O
by O O
colors O O
can O O
form O O
arguments O O
. O O

Two O O
arguments O O
with O O
the O O
same O O
color O O
are O O
regarded O O
as O O
an O O
argument O O
pair O O
. O O

Previous O O
works O O
( O O
Cheng O O
et O O
al O O
. O O
, O O
2020(Cheng O O
et O O
al O O
. O O
, O O
, O O
2021 O O
commonly O O
address O O
APE B-TaskName B-TaskName
by O O
decomposing O O
it O O
into O O
two O O
sentence O O
- O O
level O O
subtasks O O
, O O
i.e. O O
, O O
a O O
sequence B-TaskName B-TaskName
labeling I-TaskName I-TaskName
task I-TaskName I-TaskName
and O O
a O O
sentence O O
relation O O
classification O O
task O O
. O O

These O O
methods O O
identify O O
arguments O O
by O O
sentencelevel O O
sequence O O
labeling O O
and O O
determine O O
whether O O
two O O
sentences O O
belong O O
to O O
the O O
same O O
argument O O
pair O O
by O O
sentence O O
relation O O
classification O O
. O O

Afterwards O O
, O O
the O O
argument O O
pairs O O
are O O
inferred O O
indirectly O O
by O O
certain O O
rules O O
combining O O
the O O
results O O
of O O
the O O
two O O
subtasks O O
. O O

However O O
, O O
such O O
a O O
paradigm O O
only O O
considers O O
sentencelevel O O
relations O O
, O O
while O O
the O O
holistic O O
argument O O
- O O
level O O
relations O O
can O O
not O O
be O O
well O O
modeled O O
. O O

In O O
this O O
paper O O
, O O
we O O
argue O O
that O O
APE B-TaskName B-TaskName
can O O
be O O
considered O O
as O O
a O O
multi O O
- O O
turn O O
machine B-TaskName B-TaskName
reading I-TaskName I-TaskName
comprehension I-TaskName I-TaskName
( O O
MRC B-TaskName B-TaskName
) O O
task O O
with O O
two O O
phases O O
, O O
i.e. O O
, O O
an O O
AM B-TaskName B-TaskName
phase O O
and O O
an O O
APE B-TaskName B-TaskName
phase O O
. O O

Specifically O O
, O O
in O O
the O O
first O O
turn O O
, O O
a O O
special O O
AM B-TaskName B-TaskName
query O O
is O O
employed O O
to O O
identify O O
all O O
the O O
arguments O O
in O O
the O O
first O O
document O O
( O O
AM B-TaskName B-TaskName
phase O O
) O O
. O O

Afterwards O O
, O O
in O O
each O O
subsequent O O
turn O O
, O O
every O O
identified O O
argument O O
is O O
treated O O
as O O
an O O
APE O O
query O O
to O O
extract O O
its O O
paired O O
arguments O O
from O O
the O O
second B-DatasetName B-DatasetName
document I-DatasetName I-DatasetName
( O O
APE B-TaskName B-TaskName
phase O O
) O O
. O O

Similarly O O
, O O
this O O
process O O
can O O
also O O
be O O
performed O O
in O O
another O O
direction O O
, O O
that O O
is O O
, O O
using O O
the O O
arguments O O
identified O O
in O O
the O O
second B-DatasetName B-DatasetName
document I-DatasetName I-DatasetName
as O O
queries O O
to O O
extract O O
the O O
paired O O
arguments O O
from O O
the O O
first B-DatasetName B-DatasetName
document I-DatasetName I-DatasetName
. O O

We O O
train O O
these O O
two O O
phases O O
jointly O O
in O O
a O O
single O O
MRC B-MethodName B-MethodName
model I-MethodName I-MethodName
, O O
allowing O O
them O O
to O O
benefit O O
each O O
other O O
. O O

By O O
considering O O
arguments O O
as O O
queries O O
, O O
our O O
proposed O O
MRC B-MethodName B-MethodName
framework I-MethodName I-MethodName
can O O
better O O
capture O O
the O O
interactions O O
between O O
each O O
query O O
argument O O
and O O
the O O
queried O O
document O O
, O O
thus O O
extracting O O
the O O
argument O O
pairs O O
at O O
the O O
argument O O
level O O
. O O

In O O
addition O O
, O O
considering O O
the O O
long O O
length O O
of O O
the O O
documents B-DatasetName B-DatasetName
, O O
we O O
utilize O O
Longformer B-MethodName B-MethodName
( O O
Beltagy O O
et O O
al O O
. O O
, O O
2020 O O
) O O
to O O
model O O
longer O O
contexts O O
. O O

We O O
evaluate O O
our O O
method O O
on O O
the O O
large O O
benchmark B-DatasetName B-DatasetName
dataset I-DatasetName I-DatasetName
( O O
Cheng O O
et O O
al O O
. O O
, O O
2020 O O
) O O
. O O

Results O O
show O O
that O O
our O O
proposed O O
method O O
significantly O O
outperforms O O
the O O
current O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
method O O
by O O
7.11 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
. O O

Related O O
Work O O

Argument B-TaskName B-TaskName
Mining I-TaskName I-TaskName

Argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
aims O O
to O O
analyze O O
the O O
structure O O
of O O
argumentation O O
, O O
and O O
it O O
contains O O
various O O
subtasks O O
, O O
such O O
as O O
argument B-TaskName B-TaskName
component I-TaskName I-TaskName
identification I-TaskName I-TaskName
( O O
Moens O O
et O O
al O O
. O O
, O O
2007;Goudas O O
et O O
al O O
. O O
, O O
2015;Ajjour O O
et O O
al O O
. O O
, O O
2017;Jo O O
et O O
al O O
. O O
, O O
2019 O O
) O O
, O O
argument B-TaskName B-TaskName
relation I-TaskName I-TaskName
prediction I-TaskName I-TaskName
( O O
Nguyen O O
and O O
Litman O O
, O O
2016;Cocarascu O O
et O O
al O O
. O O
, O O
2020;Jo O O
et O O
al O O
. O O
, O O
2021 O O
) O O
, O O
argumentation B-TaskName B-TaskName
structure I-TaskName I-TaskName
parsing I-TaskName I-TaskName
( O O
Stab O O
and O O
Gurevych O O
, O O
2017;Kuribayashi O O
et O O
al O O
. O O
, O O
2019;Morio O O
et O O
al O O
. O O
, O O
2020;Bao O O
et O O
al O O
. O O
, O O
2021 O O
) O O
, O O
argumentation B-TaskName B-TaskName
strategy I-TaskName I-TaskName
analysis I-TaskName I-TaskName
( O O
Khatib O O
et O O
al O O
. O O
, O O
2018;Morio O O
et O O
al O O
. O O
, O O
2019 O O
) O O
, O O
etc O O
. O O

Most O O
previous O O
works O O
mainly O O
focus O O
on O O
monological O O
argumentation O O
, O O
while O O
dialogical O O
argumentation O O
( O O
Morio O O
and O O
Fujita O O
, O O
2018;Chakrabarty O O
et O O
al O O
. O O
, O O
2019 O O
) O O
is O O
relatively O O
less O O
emphasized O O
. O O

Recently O O
, O O
the O O
analysis O O
of O O
dialogical O O
argumentation O O
has O O
attracted O O
increasing O O
attention O O
in O O
the O O
field O O
of O O
argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
. O O

Cheng O O
et O O
al O O
. O O
( O O
2020 O O
) O O
propose O O
the O O
APE B-TaskName B-TaskName
task I-TaskName I-TaskName
which O O
involves O O
identifying O O
arguments O O
and O O
extracting O O
argument O O
pairs O O
in O O
peer O O
review O O
and O O
rebuttal O O
. O O

Ji O O
et O O
al O O
. O O
( O O
2021 O O
) O O
identify O O
interactive O O
argument O O
pairs O O
in O O
online O O
debate O O
forums O O
based O O
on O O
the O O
discrete O O
variational O O
autoencoders O O
. O O

Cheng O O
et O O
al O O
. O O
( O O
2021 O O
) O O
address O O
the O O
APE B-TaskName B-TaskName
task I-TaskName I-TaskName
based O O
on O O
a O O
table B-MethodName B-MethodName
- I-MethodName I-MethodName
filling I-MethodName I-MethodName
approach I-MethodName I-MethodName
. O O

Yuan O O
et O O
al O O
. O O
( O O
2021 O O
) O O
construct O O
a O O
dialogical O O
argumentation O O
knowledge O O
graph O O
for O O
identifying O O
argument O O
pairs O O
. O O

Machine B-TaskName B-TaskName
Reading I-TaskName I-TaskName
Comprehension I-TaskName I-TaskName

Machine B-TaskName B-TaskName
reading I-TaskName I-TaskName
comprehension I-TaskName I-TaskName
( O O
MRC B-TaskName B-TaskName
) O O
aims O O
to O O
extract O O
answer O O
spans O O
from O O
a O O
passage O O
according O O
to O O
a O O
given O O
query O O
Devlin O O
et O O
al O O
. O O
, O O
2019 O O
; O O
Wen O O
et O O
al O O
. O O
, O O
2021 O O
) O O
. O O

Formulating O O
NLP B-TaskName B-TaskName
tasks I-TaskName I-TaskName
as O O
MRC B-TaskName B-TaskName
tasks I-TaskName I-TaskName
has O O
been O O
a O O
rising O O
trend O O
in O O
recent O O
years O O
, O O
such O O
as O O
dependency O O
parsing O O
( O O
Gan O O
et O O
al O O
. O O
, O O
2021 O O
) O O
, O O
relation O O
extraction O O
( O O
Levy O O
et O O
al O O
. O O
, O O
2017 O O
) O O
, O O
named O O
entity O O
recognition O O
( O O
Li O O
et O O
al O O
. O O
, O O
2020 O O
) O O
, O O
sentiment O O
analysis O O
( O O
Chen O O
et O O
al O O
. O O
, O O
2021 O O
; O O
Mao O O
et O O
al O O
. O O
, O O
2021 O O
) O O
. O O

Unlike O O
previous O O
studies O O
above O O
, O O
we O O
employ O O
a O O
MRC B-MethodName B-MethodName
framework I-MethodName I-MethodName
to O O
analyze O O
the O O
complex O O
argumentative O O
relations O O
between O O
two O O
documents O O
with O O
excessively O O
long O O
length O O
. O O

Methodology O O

Task O O
Formulation O O

We O O
assume O O
that O O
two O B-DatasetName
interrelated I-DatasetName I-DatasetName
documents I-DatasetName I-DatasetName
D O O
a O O
= O O
( O O
s O O
a O O
1 O O
, O O
s O O
a O O
2 O O
, O O
... O O
, O O
s O O
a O O
n O O
a O O
) O O
and O O
D O O
b O O
= O O
( O O
s O O
b O O
1 O O
, O O
s O O
b O O
2 O O
, O O
... O O
, O O
s O O
b O O
n O O
b O O
) O O
are O O
given O O
, O O
where O O
s O O
i O O
j O O
denotes O O
the O O
j O O
- O O
th O O
sentence O O
in O O
document O O
i O O
. O O

We O O
need O O
to O O
extract O O
the O O
collection O O
of O O
argument O O
pairs O O
P O O
= O O
{ O O
( O O
arg O O
a O O
i O O
, O O
arg O O
b O O
i O O
) O O
} O O
|P O O
| O O
i=1 O O
, O O
where O O
arg O O
a O O
i O O
and O O
arg O O
b O O
i O O
respectively O O
represent O O
the O O
arguments O O
in O O
document B-DatasetName B-DatasetName
D O O
a O O
and O O
D O O
b O O
, O O
and O O
they O O
compose O O
the O O
i O O
- O O
th O O
argument O O
pair O O
. O O

Note O O
that O O
each O O
argument O O
consists O O
of O O
one O O
or O O
more O O
consecutive O O
sentences O O
. O O

For O O
example O O
, O O
arg O O
a O O
i O O
= O O
( O O
s O O
a O O
, O O
i O O
start O O
, O O
s O O
a O O
, O O
i O O
start+1 O O
, O O
... O O
, O O
s O O
a O O
, O O
i O O
end O O
) O O
where O O
start O O
and O O
end O O
denote O O
the O O
start O O
and O O
end O O
sentence O O
index O O
. O O

To O O
frame O O
APE B-TaskName B-TaskName
as O O
a O O
multi O O
- O O
turn O O
MRC B-TaskName B-TaskName
task I-TaskName I-TaskName
, O O
two O O
types O O
of O O
queries O O
are O O
constructed O O
, O O
i.e. O O
, O O
the O O
argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
( O O
AM B-TaskName B-TaskName
) O O
query O O
and O O
the O O
argument B-TaskName B-TaskName
pair I-TaskName I-TaskName
extraction I-TaskName I-TaskName
( O O
APE B-TaskName B-TaskName
) O O
query O O
. O O

Intuitively O O
, O O
we O O
could O O
consider O O
the O O
process O O
of O O
extracting O O
argument O O
pairs O O
from O O
the O O
perspective O O
of O O
two O O
directions O O
, O O
i.e. O O
, O O
D O O
a O O
D  O
D O O
b O O
and O O
D O O
b O O
D O O
a O O
. O O

For O O
the O O
D O O
a O O
D  O
D O O
b O O
direction O O
, O O
we O O
first O O
construct O O
an O O
AM B-TaskName B-TaskName
query O O
using O O
a O O
special O O
token O O
whose O O
corresponding O O
answers O O
are O O
all O O
the O O
arguments O O
in O O
document B-DatasetName B-DatasetName
D O O
a O O
. O O

After O O
recognizing O O
all O O
arguments O O
through O O
the O O
AM B-TaskName B-TaskName
query O O
, O O
each O O
recognized O O
argument O O
is O O
considered O O
as O O
an O O
APE B-TaskName B-TaskName
query O O
whose O O
corresponding O O
answers O O
are O O
its O O
paired O O
arguments O O
in O O
document O O
D O O
b O O
. O O

Similarly O O
, O O
for O O
the O O
D O O
b O O
D  O
D O O
a O O
direction O O
, O O
we O O
first O O
query O O
document B-DatasetName B-DatasetName
D O O
b O O
with O O
the O O
AM B-TaskName B-TaskName
query O O
, O O
and O O
then O O
generate O O
the O O
APE B-TaskName B-TaskName
queries O O
for O O
document B-DatasetName B-DatasetName
D O O
a O O
. O O

Finally O O
, O O
the O O
argument O O
pairs O O
can O O
be O O
derived O O
by O O
fusing O O
the O O
answer O O
results O O
of O O
all O O
APE B-TaskName B-TaskName
queries O O
. O O

MRC B-MethodName B-MethodName
Framework I-MethodName I-MethodName

Encoder B-DatasetName B-TaskName

Since O O
APE B-TaskName B-TaskName
is O O
a O O
document O O
- O O
level O O
task O O
with O O
excessively O O
long O O
text O O
, O O
we O O
adopt O O
Longformer B-MethodName B-MethodName
to O O
capture O O
contextual O O
information O O
over O O
longer O O
distances O O
. O O

For O O
brevity O O
, O O
we O O
only O O
describe O O
the O O
MRC B-TaskName B-TaskName
process O O
in O O
the O O
D O O
a O O
D  O
D O O
b O O
direction O O
below O O
, O O
and O O
the O O
D O O
b O O
D  O
D O O
a O O
direction O O
can O O
be O O
performed O O
similarly O O
. O O

With O O
these O O
queries O O
, O O
we O O
first O O
concatenate O O
the O O
AM B-TaskName B-TaskName
query O O
q O O
am B-TaskName B-TaskName
and O O
the O O
document B-DatasetName B-DatasetName
D O O
a O O
as O O
an O O
input O O
sequence O O
for O O
AM B-TaskName B-TaskName
: O O
I O O
am B-TaskName B-TaskName
= O O
( O O
[ O O
s O O
] O O
, O O
q O O
am O O
, O O
[ O O
/s O O
] O O
, O O
[ O O
s O O
] O O
, O O
s O O
a O O
1 O O
, O O
s O O
a O O
2 O O
, O O
... O O
, O O
s O O
a O O
n O O
a O O
, O O
[ O O
/s])(1 O O
) O O
Also O O
, O O
we O O
concatenate O O
each O O
APE B-TaskName B-TaskName
query O O
q O O
a O O
, O O
ape B-TaskName B-TaskName
k O O
and O O
the O O
document B-DatasetName B-DatasetName
D O O
b O O
to O O
obtain O O
multiple O O
input O O
sequences O O
for O O
APE B-TaskName B-TaskName
: O O
Subsequently O O
, O O
for O O
each O O
sequence O O
above O O
, O O
we O O
feed O O
it O O
into O O
Longformer B-MethodName B-MethodName
to O O
get O O
the O O
hidden O O
representation O O
of O O
each O O
token O O
in O O
the O O
input O B-DatasetName
document I-DatasetName I-DatasetName
. O O

Specifically O O
, O O
to O O
enable O O
Longformer B-MethodName B-MethodName
to O O
better O O
learn O O
argument O O
specific O O
representations O O
, O O
we O O
add O O
global O O
attention O O
to O O
the O O
tokens O O
of O O
the O O
query O O
. O O

Afterwards O O
, O O
we O O
derive O O
the O O
hidden O O
representation O O
of O O
each O O
sentence O O
through O O
mean O O
pooling O O
on O O
token O O
representations O O
in O O
this O O
sentence O O
. O O

Further O O
, O O
to O O
better O O
model O O
the O O
longterm O O
dependency O O
among O O
sentences O O
, O O
the O O
hidden O O
representations O O
of O O
sentences O O
are O O
fed O O
into O O
LSTM B-MethodName B-MethodName
to O O
derive O O
the O O
contextual O O
sentence O O
representation O O
matrix O O
H O O
= O O
( O O
h O O
1 O O
, O O
h O O
2 O O
, O O
. O O
. O O
. O O
, O O
h O O
n O O
) O O
. O O
I O O
ape O O
k O O
= O O
( O O
[ O O
s O O
] O O
, O O
q O O
a O O
, O O
ape O O
k O O
, O O
[ O O
/s O O
] O O
, O O
[ O O
s O O
] O O
, O O
s O O
b O O
1 O O
, O O
s O O
b O O
2 O O
, O O
... O O
, O O
s O O
b O O
n O O
b O O
, O O
[ O O
/s])(2 O O

Answer O O
Span O O
Prediction O O

For O O
each O O
turn O O
, O O
one O O
or O O
more O O
answer O O
spans O O
will O O
be O O
extracted O O
as O O
arguments O O
. O O

Note O O
that O O
, O O
in O O
each O O
direction O O
, O O
the O O
first O O
turn O O
aims O O
to O O
extract O O
all O O
arguments O O
, O O
while O O
the O O
following O O
turns O O
aim O O
to O O
extract O O
arguments O O
that O O
can O O
form O O
pairs O O
with O O
the O O
query O O
argument O O
. O O

Specifically O O
, O O
inspired O O
by O O
Li O O
et O O
al O O
. O O
( O O
2020 O O
) O O
, O O
we O O
fed O O
H O O
into O O
two O O
binary O O
classifiers O O
to O O
predict O O
the O O
start O O
and O O
end O O
sentence O O
positions O O
of O O
arguments O O
. O O

After O O
obtaining O O
all O O
start O O
and O O
end O O
positions O O
, O O
we O O
further O O
employ O O
another O O
binary O O
classifier O O
to O O
determine O O
whether O O
each O O
start O O
and O O
end O O
position O O
pair O O
( O O
matched O O
by O O
Cartesian O O
product O O
) O O
forms O O
an O O
answer O O
span O O
. O O

Note O O
that O O
the O O
input O O
of O O
this O O
span O O
classifier O O
is O O
the O O
concatenation O O
of O O
the O O
start O O
and O O
end O O
sentence O O
representations O O
from O O
H. O O

Training O O

During O O
training O O
, O O
the O O
three O O
classifiers O O
described O O
in O O
Section O O
3.2.2 O O
yield O O
three O O
cross B-MetricName B-MetricName
- I-MetricName I-MetricName
entropy I-MetricName I-MetricName
losses I-MetricName I-MetricName
, O O
i.e. O O
, O O
a O O
start O O
loss O O
, O O
an O O
end O O
loss O O
, O O
and O O
a O O
span O O
loss O O
. O O

We O O
simply O O
sum O O
these O O
losses O O
up O O
as O O
the O O
training O O
objective O O
of O O
our O O
model O O
. O O

In O O
addition O O
, O O
the O O
AM B-TaskName B-TaskName
phrase O O
and O O
the O O
APE B-TaskName B-TaskName
phrase O O
are O O
trained O O
jointly O O
in O O
a O O
single O O
MRC B-MethodName B-MethodName
model I-MethodName I-MethodName
. O O

Inference O O

During O O
inference O O
, O O
the O O
D O O
a O O
D  O
D O O
b O O
direction O O
uses O O
the O O
trained O O
MRC B-MethodName B-MethodName
model I-MethodName I-MethodName
to O O
first O O
identify O O
all O O
the O O
arguments O O
in O O
D O O
a O O
by O O
the O O
AM B-TaskName B-TaskName
query O O
and O O
then O O
extract O O
all O O
the O O
argument O O
pairs O O
in O O
D O O
b O O
by O O
the O O
APE B-TaskName B-TaskName
queries O O
. O O

Similarly O O
, O O
the O O
D O O
b O O
D  O
D O O
a O O
direction O O
can O O
be O O
performed O O
in O O
the O O
same O O
manner O O
by O O
simply O O
exchanging O O
the O O
order O O
of O O
D O O
a O O
and O O
D O O
b O O
. O O

Each O O
APE B-TaskName B-TaskName
query O O
in O O
both O O
directions O O
yields O O
one O O
or O O
more O O
argument O O
pairs O O
, O O
where O O
each O O
argument O O
pair O O
contains O O
the O O
query O O
argument O O
and O O
one O O
extracted O O
argument O O
. O O

We O O
simply O O
merge O O
all O O
argument O O
pairs O O
extracted O O
by O O
all O O
APE B-TaskName B-TaskName
queries O O
into O O
a O O
union O O
set O O
to O O
obtain O O
the O O
final O O
inference O O
results O O
. O O

Experiments O O

Experimental O O
setup O O

Dataset O O

Our O O
experiments O O
are O O
conducted O O
on O O
the O O
large O O
APE B-TaskName B-TaskName
benchmark I-TaskName I-TaskName
dataset I-TaskName I-TaskName
, O O
namely O O
the O O
Review B-TaskName B-TaskName
- I-TaskName I-TaskName
Rebuttal I-TaskName I-TaskName
( O O
RR B-TaskName B-TaskName
) O O
dataset I-DatasetName O
( O O
Cheng O O
et O O
al O O
. O O
, O O
2020 O O
) O O
, O O
which O O
contains O O
4,764 O O
pairs O O
of O O
review O O
- O O
rebuttal O O
passages O O
of O O
ICLR O O
. O O

Following O O
the O O
setup O O
of O O
( O O
Cheng O O
et O O
al O O
. O O
, O O
2021 O O
) O O
, O O
we O O
also O O
evaluate O O
our O O
method O O
on O O
two O O
versions O O
of O O
the O O
train B-DatasetName B-DatasetName
/ I-DatasetName I-DatasetName
dev I-DatasetName I-DatasetName
/ I-DatasetName I-DatasetName
test I-DatasetName I-DatasetName
( O O
8:01:01 O O
) O O
split O O
, O O
i.e. O O
, O O
RR B-DatasetName B-DatasetName
- I-DatasetName I-DatasetName
Passage I-DatasetName I-DatasetName
- I-DatasetName I-DatasetName
v1 I-DatasetName I-DatasetName
and O O
RR B-DatasetName B-DatasetName
- I-DatasetName I-DatasetName
Submission I-DatasetName I-DatasetName
- I-DatasetName I-DatasetName
v2 I-DatasetName I-DatasetName
. O O

Note O O
that O O
in O O
our O O
method O O
, O O
we O O
view O O
review O O
passage O O
and O O
rebuttal O O
passage O O
as O O
document B-DatasetName B-DatasetName
D O O
a O O
and O O
document B-DatasetName B-DatasetName
D O O
b O O
, O O
respectively O O
. O O

Implementation O O
Details O O

We O O
adopt O O
Longformer B-MethodName B-MethodName
- O O
base-4096 B-DatasetName B-HyperparameterValue
1 O O
as O O
base O O
encoder O O
, O O
and O O
we O O
use O O
sliding O O
window O O
attention O O
with O O
the O O
window B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
512 B-HyperparameterValue B-HyperparameterValue
. O O

We O O
train O O
our O O
model O O
6 B-HyperparameterValue B-MetricValue
epochs B-HyperparameterName I-MetricValue
with O O
a O O
batch B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
4 B-HyperparameterValue B-HyperparameterValue
. O O

AdamW B-MethodName B-MethodName
( O O
Kingma O O
and O O
Ba O O
, O O
2015 O O
) O O
is O O
used O O
as O O
the O O
optimizer O O
, O O
and O O
the O O
learning B-HyperparameterName B-HyperparameterName
rates I-HyperparameterName I-HyperparameterName
for O O
Longformer B-MethodName B-MethodName
and O O
other O O
layers O O
are O O
1.00E-05 B-HyperparameterValue B-HyperparameterValue
and O O
1.00E-03 B-HyperparameterValue B-HyperparameterValue
. O O
2 O O

The O O
evaluation O O
metrics O O
contain O O
two O O
aspects O O
, O O
namely O O
AM B-TaskName B-TaskName
and O O
APE B-TaskName B-TaskName
. O O

Different O O
from O O
( O O
Cheng O O
et O O
al O O
. O O
, O O
2021(Cheng O O
et O O
al O O
. O O
, O O
, O O
2020 O O
, O O
sentence B-TaskName B-TaskName
pairing I-TaskName I-TaskName
is O O
not O O
included O O
as O O
a O O
metric O O
because O O
we O O
extract O O
argument O O
pairs O O
directly O O
. O O

We O O
select O O
the O O
best O O
parameters O O
based O O
on O O
the O O
performance O O
( O O
i.e. O O
, O O
average O O
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
scores O O
of O O
AM B-TaskName B-TaskName
and O O
APE B-TaskName B-TaskName
) O O
on O O
the O O
dev B-DatasetName B-DatasetName
set I-DatasetName I-DatasetName
. O O

All O O
scores O O
are O O
averaged O O
across O O
5 O O
distinct O O
trials O O
using O O
different O O
random O O
seeds O O
. O O

Baselines O O

We O O
compare O O
our O O
model O O
with O O
several O O
baselines O O
. O O

PL B-MethodName B-MethodName
- I-MethodName I-MethodName
H I-MethodName I-MethodName
- I-MethodName I-MethodName
LSTM I-MethodName I-MethodName
- I-MethodName I-MethodName
CRF I-MethodName I-MethodName
( O O
Cheng O O
et O O
al O O
. O O
, O O
2020 O O
) O O
independently O O
trains O O
an O O
argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
task I-TaskName I-TaskName
and O O
a O O
sentence B-TaskName B-TaskName
pairing I-TaskName I-TaskName
task I-TaskName I-TaskName
, O O
while O O
MT B-MethodName B-MethodName
- I-MethodName I-MethodName
H I-MethodName I-MethodName
- I-MethodName I-MethodName
LSTM I-MethodName I-MethodName
- I-MethodName I-MethodName
CRF I-MethodName I-MethodName
( O O
Cheng O O
et O O
al O O
. O O
, O O
2020 O O
) O O
trains O O
two O O
subtasks O O
in O O
a O O
multi O O
- O O
task O O
framework O O
. O O

MLMC B-MethodName B-MethodName
( O O
Cheng O O
et O O
al O O
. O O
, O O
2021 O O
) O O
is O O
an O O
attentionguided O O
model O O
based O O
on O O
a O O
table B-MethodName B-MethodName
- I-MethodName I-MethodName
filling I-MethodName I-MethodName
approach I-MethodName I-MethodName
, O O
which O O
is O O
the O O
current O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
method O O
. O O

Furthermore O O
, O O
we O O
implement O O
two O O
additional O O
baselines O O
. O O

Results O O
and O O
Analysis O O

Main O O
Results O O

As O O
shown O O
in O O
Table O O
1 O O
, O O
our O O
model O O
achieves O O
the O O
best O O
performance O O
on O O
both O O
versions O O
of O O
the O O
RR B-DatasetName B-DatasetName
dataset I-DatasetName I-DatasetName
. O O

Concretely O O
, O O
on O O
RR B-DatasetName B-DatasetName
- I-DatasetName I-DatasetName
Submission I-DatasetName I-DatasetName
- I-DatasetName I-DatasetName
v2 I-DatasetName I-DatasetName
, O O
our O O
model O O
significantly O O
outperforms O O
the O O
current O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
model O O
MLMC B-MethodName B-MethodName
by O O
at O O
least O O
7.11 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
in O O
APE B-TaskName B-TaskName
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
. O O

On O O
RR B-DatasetName B-DatasetName
- I-DatasetName I-DatasetName
Passage I-DatasetName I-DatasetName
- I-DatasetName I-DatasetName
v1 I-DatasetName I-DatasetName
, O I-DatasetName
our O O
model O O
obtains O O
at O O
least O O
a O O
6.54 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
higher O O
APE B-TaskName B-TaskName
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
than O O
the O O
MLMC B-MethodName B-MethodName
. O O

Also O O
, O O
our O O
model O O
achieves O O
the O O
best O O
performance O O
on O O
AM B-TaskName B-TaskName
. O O

Furthermore O O
, O O
without O O
applying O O
Longformer B-MethodName B-MethodName
as O O
the O O
base O O
encoder O O
, O O
MRC B-MethodName B-MethodName
- I-MethodName I-MethodName
APE I-MethodName I-MethodName
- I-MethodName I-MethodName
Bert I-MethodName I-MethodName
still O O
outperforms O O
MLMC O O
in O O
APE B-TaskName B-TaskName
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
, O O
demonstrating O O
that O O
our O O
improvement O O
is O O
not O O
only O O
brought O O
by O O
Longformer B-MethodName B-MethodName
. O O

The O O
reason O O
may O O
be O O
that O O
, O O
in O O
MLMC B-MethodName B-MethodName
, O O
the O O
predictions O O
of O O
the O O
AM B-TaskName B-TaskName
task O O
are O O
influenced O O
by O O
the O O
APE B-TaskName B-TaskName
task O O
through O O
a O O
complex O O
attention O O
interaction O O
mechanism O O
. O O

However O O
, O O
our O O
model O O
does O O
not O O
require O O
such O O
a O O
complex O O
design O O
and O O
can O O
achieve O O
much O O
better O O
results O O
on O O
the O O
APE B-TaskName B-TaskName
task O O
. O O

Besides O O
, O O
our O O
MRC B-MethodName B-MethodName
- I-MethodName I-MethodName
APE I-MethodName I-MethodName
achieves O O
better O O
results O O
than O O
MRC B-MethodName B-MethodName
- I-MethodName I-MethodName
APE I-MethodName I-MethodName
- I-MethodName I-MethodName
Sep. I-MethodName I-MethodName
on O O
both O O
AM B-TaskName B-TaskName
and O O
APE B-TaskName B-TaskName
tasks O O
, O O
indicating O O
that O O
jointly O O
training O O
two O O
phases O O
in O O
a O O
single O O
MRC B-MethodName B-MethodName
model I-MethodName I-MethodName
could O O
maximize O O
the O O
mutual O O
benefits O O
of O O
the O O
two O O
phases O O
. O O

In O O
addition O O
, O O
to O O
analyze O O
the O O
error O O
propagation O O
from O O
the O O
first O O
phase O O
to O O
the O O
second O O
phase O O
, O O
we O O
use O O
the O O
TRUE O O
label O O
of O O
AM B-TaskName B-TaskName
task O O
to O O
predict O O
APE B-TaskName B-TaskName
task O O
. O O

Under O O
this O O
setting O O
, O O
our O O
model O O
can O O
achieve O O
around O O
59.44 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
for O O
APE B-TaskName B-TaskName
task O O
, O O
showing O O
effectiveness O O
in O O
identifying O O
argument O O
pairs O O
. O O

Ablation O O
Study O O

The O O
ablation O O
study O O
results O O
are O O
shown O O
in O O
Table O O
2 O O
. O O

It O O
can O O
be O O
observed O O
that O O
using O O
two O O
directions O O
contributes O O
greatly O O
to O O
our O O
method O O
. O O

Also O O
, O O
using O O
the O O
arguments O O
recognized O O
in O O
D O O
a O O
to O O
extract O O
the O O
paired O O
arguments O O
in O O
D O O
b O O
is O O
more O O
critical O O
in O O
the O O
RR B-DatasetName B-DatasetName
dataset I-DatasetName I-DatasetName
, O O
removing O O
it O O
causes O O
a O O
6.51 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
decrease O O
in O O
APE B-TaskName B-TaskName
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
. O O

Without O O
the O O
LSTM B-MethodName B-MethodName
to O O
capture O O
the O O
long O O
- O O
term O O
dependency O O
among O O
sentences O O
, O O
the O O
APE B-TaskName B-TaskName
F B-MetricName B-MetricName
1 I-MetricName I-MetricName
score O O
decreases O O
by O O
0.86 B-MetricValue B-MetricValue
% I-MetricValue I-MetricValue
. O O

Furthermore O O
, O O
the O O
performance O O
drops O O
heavily O O
without O O
the O O
global O O
attention O O
, O O
because O O
it O O
enables O O
more O O
interactions O O
between O O
the O O
query O O
argument O O
and O O
the O O
queried O O
document O O
, O O
thus O O
better O O
argument O O
- O O
specific O O
representations O O
could O O
be O O
learned O O
. O O

Conclusion O O

In O O
this O O
paper O O
, O O
we O O
propose O O
to O O
frame O O
the O O
argument B-TaskName B-TaskName
pair I-TaskName I-TaskName
extraction I-TaskName I-TaskName
( O O
APE B-TaskName B-TaskName
task O O
as O O
a O O
machine B-TaskName B-TaskName
reading I-TaskName I-TaskName
comprehension I-TaskName I-TaskName
( O O
MRC B-TaskName B-TaskName
) O O
task O O
. O O

Our O B-MethodName
MRC B-MethodName I-MethodName
framework I-MethodName I-MethodName
addresses O O
APE B-TaskName B-TaskName
through O O
two O O
phases O O
with O O
two O O
types O O
of O O
queries O O
, O O
that O O
is O O
, O O
argument B-TaskName B-TaskName
mining I-TaskName I-TaskName
( O O
AM B-TaskName B-TaskName
) O O
query O O
and O O
argument B-TaskName B-TaskName
pair I-TaskName I-TaskName
extraction I-TaskName I-TaskName
( O O
APE B-TaskName B-TaskName
) O O
query O O
. O O

Our O O
proposed O O
method O O
can O O
better O O
model O O
the O O
argumentlevel O O
interactions O O
, O O
thus O O
facilitating O O
the O O
extraction O O
of O O
argument O O
pairs O O
. O O

Experimental O O
results O O
on O O
a O O
large O O
benchmark B-DatasetName B-DatasetName
dataset I-DatasetName I-DatasetName
demonstrate O O
that O O
our O O
proposed O O
method O O
achieves O O
state O O
- O O
of O O
- O O
the O O
- O O
art O O
performance O O
. O O

Acknowledgments O O

This O O
work O O
was O O
partially O O
supported O O
by O O
the O O
National O O
Natural O O
Science O O
Foundation O O
of O O
China O O
( O O
61876053 O O
, O O
62006062 O O
, O O
62176076 O O
) O O
, O O
the O O
Shenzhen O O
Foundational O O
Research O O
Funding O O
( O O
JCYJ20200109113441941 O O
, O O
JCYJ20210324115614039 O O
) O O
, O O
Joint O O
Lab O O
of O O
HITSZ O O
and O O
China O O
Merchants O O
Securities O O
. O O

The O O
number B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
iterations I-HyperparameterName I-HyperparameterName
for O O
DAU-AM B-MethodName B-MethodName
and O O
DAU-PTM B-MethodName B-MethodName
was O O
1,000. B-HyperparameterValue B-HyperparameterValue

Compared O O
to O O
textual O O
media, O O
which O O
allows O O
readers O O
to O O
read O O
at O O
their O O
own O O
pace, O O
dialogue-based O O
media O O
does O O
not O O
allow O O
users O O
to O O
skip O O
unnecessary O O
information O O
or O O
skim O O
necessary O O
information O O
while O O
listening. O O

When O O
β B-HyperparameterName B-HyperparameterName
= O O
2, B-HyperparameterValue B-HyperparameterValue
the O O
exclusion O O
rate O O
is O O
twice O O
as O O
important O O
as O O
the O O
coverage. O O

Figure O O
3: O O
Processing O O
time O O
for O O
each O O
number O O
of O O
sentences O O
(N O B-HyperparameterName
= O O
3, B-HyperparameterValue B-HyperparameterValue
T0 B-HyperparameterName B-HyperparameterName
= O O
270) B-HyperparameterValue B-HyperparameterValue

However, O O
in O O
terms O O
of O O
the O O
EoIT, B-MetricName B-MetricName
DAU-PTM B-MethodName B-MethodName
was O O
higher O O
than O O
DAU-AM. B-MethodName B-MethodName

We O O
used O O
EoITβ B-MetricName B-MetricName
(efficiency O B-MetricName
of I-MetricName I-MetricName
information I-MetricName I-MetricName
transmission) I-MetricName I-MetricName
(Takatsu O O
et O O
al., O O
2021) O O
as O O
the O O
evaluation O O
metric. O O

The O O
number O O
of O O
replicas O O
in O O
DAU-PTM B-MethodName B-MethodName
and O O
the O O
number O O
of O O
runs O O
of O O
annealing O O
in O O
DAU-AM B-MethodName B-MethodName
were O O
128. B-HyperparameterValue B-HyperparameterValue

It O O
can O O
handle O O
up O O
to O O
4,096 O O
binary O O
variables O O
with O O
64-bit O O
precision O O
or O O
as O O
many O O
as O O
8,192 O O
binary O O
variables O O
with O O
16-bit O O
precision. O O

A O O
soft O O
chunk O O
occurs O O
when O O
the O O
child O O
sentence O O
is O O
useful O O
to O O
prevent O O
a O O
biased O O
understanding O O
of O O
the O O
content O O
of O O
the O O
parent O O
sentence, O O
although O O
it O O
does O O
not O O
necessarily O O
contain O O
essential O O
information O O
to O O
understand O O
the O O
parent O O
sentence O O
itself. O O

We O O
defined O O
the O O
following O O
as O O
discourse O O
relations: O O
Start, O O
Result, O O
Cause, O O
Background, O O
Correspondence, O O
Contrast, O O
Topic O O
Change, O O
Example, O O
Conclusion, O O
and O O
Supplement. O O

A O O
discourse O O
relation O O
classifies O O
the O O
type O O
of O O
semantic O O
relationship O O
between O O
the O O
child O O
sentence O O
and O O
the O O
parent O O
sentence. O O

In O O
each O O
genre, O O
we O O
manually O O
selected O O
200 O O
articles O O
to O O
minimize O O
topic O O
overlap. O O

To O O
achieve O O
both O O
personalization O O
and O O
coherence O O
simultaneously, O O
we O O
propose O O
ILP B-MethodName B-MethodName
and O O
QUBO B-MethodName B-MethodName
models O O
to O O
extract O O
sentences O O
based O O
on O O
the O O
degree O O
of O O
user’s O O
interest O O
and O O
generate O O
a O O
personalized O O
summary O O
for O O
each O O
user O O
while O O
maintaining O O
coherence O O
based O O
on O O
the O O
discourse O O
structure. O O

Yang O O
and O O
Li O O
(2018) O O
proposed O O
a O O
method O O
to O O
manually O O
annotate O O
the O O
dependency O O
structure O O
and O O
discourse O O
relations O O
between O O
elementary O O
discourse O O
units O O
for O O
abstracts O O
of O O
scientific O O
papers, O O
and O O
then O O
constructed O O
SciDTB. B-DatasetName B-DatasetName

RST B-DatasetName B-DatasetName
Discourse I-DatasetName I-DatasetName
Treebank I-DatasetName I-DatasetName
is O O
a O O
dataset O O
constructed O O
based O O
on O O
rhetorical O O
structure O O
theory O O
(Mann O O
and O O
Thompson, O O
1988). O O

In O O
recent O O
years, O O
non-von O O
Neumann O O
computers O O
called O O
Ising B-MethodName B-MethodName
machines I-MethodName I-MethodName
have O O
been O O
attracting O O
attention O O
as O O
they O O
can O O
solve O O
combinatorial O O
optimization O O
problems O O
and O O
obtain O O
quasi-optimal O O
solutions O O
instantly O O
(Sao O O
et O O
al., O O
2019). O O

In O O
addition, O O
the O O
dialogue O O
scenarios O O
generated O O
based O O
on O O
the O O
extracted O O
information O O
should O O
be O O
coherent O O
to O O
aid O O
in O O
the O O
proper O O
understanding. O O

The O O
summarization O O
problem O O
is O O
formulated O O
as O O
a O O
quadratic B-MethodName B-MethodName
unconstraint I-MethodName I-MethodName
binary I-MethodName I-MethodName
optimization I-MethodName I-MethodName
(QUBO) B-MethodName B-MethodName
problem, O O
which O O
extracts O O
sentences O O
that O O
maximize O O
the O O
sum O O
of O O
the O O
degree O O
of O O
user’s O O
interest O O
in O O
the O O
sentences O O
of O O
documents O O
with O O
the O O
discourse O O
structure O O
of O O
each O O
document O O
and O O
the O O
total O O
utterance O O
time O O
as O O
constraints. O O

A O O
larger O O
total O O
effect O O
could O O
indicate O O
that O O
the O O
model O O
is O O
handling O O
negation, O O
however, O O
it O O
is O O
not O O
clear O O
why O O
that O O
would O O
be O O
the O O
case O O
if O O
the O O
original O O
sample O O
was O O
incorrectly O O
predicted. O O

Figure O O
4: O O
Natural O O
indirect O O
effect O O
of O O
the O O
top O O
5% O O
of O O
neurons O O
in O O
each O O
layer O O
per O O
negation O O
category. O O
Shaded O O
area O O
represents O O
the O O
standard O O
deviation. O O

When O O
the O O
model O O
predicts O O
the O O
original O O
example O O
correctly, O O
a O O
larger O O
total O O
effect O O
under O O
the O O
intervention O O
could O O
indicate O O
a O O
better O O
handling O O
of O O
negation, O O
as O O
it O O
suggests O O
a O O
higher O O
probability O O
of O O
the O O
correct O O
label O O
under O O
negation. O O

We O O
measure O O
the O O
natural B-MetricName B-MetricName
indirect I-MetricName I-MetricName
effect I-MetricName I-MetricName
(NIE) B-MetricName B-MetricName
of O O
a O O
change O O
in O O
the O O
input O O
X O O
on O O
the O O
response O O
variable O O
y, O O
with O O
respect O O
to O O
a O O
mediator O O
z. O O

Table O O
3: O O
Accuracy B-MetricName B-MetricName
on O O
the O O
negation O O
test O O
set O O
and O O
the O O
corresponding O O
non-negated O O
(positive) O O
examples. O O

Table O O
4: O O
Accuracy B-MetricName B-MetricName
for O O
the O O
negated O O
examples O O
for O O
whose O O
original O O
(unnegated) O O
version O O
the O O
model O O
makes O O
a O O
correct/incorrect O O
prediction O O
(“o. O O
correct”/“o. O O
incorrect”). O O

Looking O O
at O O
specific O O
categories, O O
LXMERT B-MethodName B-MethodName
seems O O
to O O
struggle O O
the O O
most O O
with O O
verbal O O
negation, O O
while O O
both O O
versions O O
of O O
UNITER B-MethodName B-MethodName
perform O O
better, O O
achieving O O
scores O O
between O O
14 B-MetricValue B-MetricValue
and O O
20 B-MetricValue B-MetricValue
points O O
higher O O
than O O
LXMERT. B-MethodName B-MethodName

It O O
should O O
also O O
be O O
noted O O
that O O
while O O
negation O O
is O O
a O O
complex O O
phenomenon, O O
here O O
we O O
only O O
consider O O
absolute O O
negators O O
(e.g., O O
no, O O
not, O O
nobody, O O
nothing), O O
and O O
we O O
do O O
not O O
consider O O
approximate O O
negators O O
(e.g., O O
few, O O
little, O O
barely) O O
or O O
affixal O O
negators O O
(e.g., O O
the O O
prefixes O O
un-, O O
in-, O O
non-, O O
see O O
Pullum O O
and O O
Huddleston O O
(2002). O O

While O O
causal O O
mediation O O
analysis O O
is O O
a O O
useful O O
analysis O O
tool, O O
it O O
is O O
not O O
straightforward O O
to O O
apply O O
it O O
to O O
all O O
models O O
and O O
to O O
the O O
analysis O O
of O O
attention O O
when O O
the O O
input O O
is O O
of O O
different O O
length O O
in O O
the O O
base O O
case O O
and O O
under O O
the O O
intervention. O O

We O O
also O O
compared O O
the O O
NIEs B-MetricName B-MetricName
of O O
examples O O
split O O
by O O
whether O O
the O O
original/negated O O
one O O
is O O
correctly O O
predicted O O
by O O
the O O
model, O O
however, O O
we O O
do O O
not O O
observe O O
notable O O
differences O O
(Appendix O O
F). O O

As O O
mentioned O O
in O O
Section O O
2.3, O O
this O O
is O O
done O O
by O O
fixing O O
the O O
input O O
to O O
its O O
value O O
without O O
the O O
intervention, O O
but O O
changing O O
the O O
value O O
of O O
the O O
mediator O O
z O O
to O O
its O O
value O O
under O O
the O O
intervention. O O

Table O O
4 O O
shows O O
accuracy B-MetricName B-MetricName
of O O
the O O
negated O O
samples, O O
split O O
by O O
whether O O
the O O
model O O
predicts O O
the O O
corresponding O O
original O O
sample O O
correctly O O
or O O
not. O O

UNITERtriplet B-MethodName B-MethodName
was O O
finetuned O O
for O O
10 B-HyperparameterValue B-HyperparameterValue
epochs B-HyperparameterName B-HyperparameterName
and O O
achieved O O
accuracies B-MetricName B-MetricName
of O O
71.53% B-MetricValue B-MetricValue
on O O
the O O
development O O
and O O
73.10% B-MetricValue B-MetricValue
on O O
the O O
test O O
set. O O

The O O
existing O O
dataset O O
also O O
cannot O O
be O O
used O O
reliably O O
to O O
make O O
performance O O
comparisons O O
between O O
negated O O
and O O
nonnegated O O
examples. O O

Vig O O
et O O
al. O O
(2020) O O
apply O O
causal O O
mediation O O
analysis O O
to O O
the O O
study O O
of O O
gender O O
bias O O
in O O
large O O
pre-trained O O
language O O
models. O O

For O O
the O O
purposes O O
of O O
this O O
analysis, O O
we O O
focus O O
on O O
a O O
particular O O
vision-and-language O O
task, O O
Natural B-MethodName B-MethodName
Language I-MethodName I-MethodName
Visual I-MethodName I-MethodName
Reasoning I-MethodName I-MethodName
for I-MethodName I-MethodName
Real I-MethodName I-MethodName
(NLVR2) B-MethodName B-MethodName
(Suhr O O
et O O
al., O O
2019). O O

Figure O O
1: O O
Examples O O
from O O
the O O
NLVR2 B-DatasetName B-DatasetName
corpus. O O

﻿Following O O
the O O
success O O
of O O
pre-trained O O
language O O
models O O
such O O
as O O
BERT B-MethodName B-MethodName
(Devlin O O
et O O
al., O O
2019) O O
on O O
a O O
range O O
of O O
language O O
tasks, O O
recent O O
advances O O
in O O
vision-and-language O O
have O O
involved O O
the O O
introduction O O
of O O
pre-trained O O
models O O
(e.g., O O
UNITER, B-MethodName B-MethodName
Chen O O
et O O
al. O O
2020, O O
VisualBERT, B-MethodName B-MethodName
Li O O
et O O
al. O O
2019, O O
ViLBERT, B-MethodName B-MethodName
Lu O O
et O O
al. O O
2019, O O
LXMERT, B-MethodName B-MethodName
Tan O O
and O O
Bansal O O
2019). O O

Given O O
that O O
unmasking O O
is O O
supposed O O
to O O
optimize O O
performance O O
on O O
downstream O O
tasks, O O
it O O
is O O
not O O
surprising O O
that O O
unmasking O O
handicapped O O
BabyBERTa B-MethodName B-MethodName
during O O
pre-training. O O

For O O
all O O
models O O
trained O O
using O O
the O O
standard O O
masking O O
strategy, O O
in O O
which O O
masked O O
words O O
are O O
left O O
unmasked O O
10% B-HyperparameterValue B-HyperparameterValue
of O O
the O O
time O O
(unmasking B-HyperparameterName B-HyperparameterName
= O O
yes), B-HyperparameterValue B-HyperparameterValue
overall O O
accuracy B-MetricName B-MetricName
was O O
between O O
8 B-MetricValue B-MetricValue
and O O
16 B-MetricValue B-MetricValue
points O O
higher O O
when O O
MLM B-MethodName B-MethodName
scoring O O
was O O
used. O O

Further, O O
we O O
adopt O O
the O O
probing O O
across O O
time O O
framework O O
used O O
by O O
Liu O O
et O O
al. O O
(2021). O O

We O O
also O O
evaluated O O
RoBERTabase B-MethodName B-MethodName
pre-trained O O
from O O
scratch O O
by O O
Warstadt O O
et O O
al. O O
(2020b) O O
on O O
a O O
similarly O O
sized O O
dataset O O
consisting O O
of O O
10M O O
words O O
of O O
English B-DatasetName B-DatasetName
Wikipedia I-DatasetName I-DatasetName
and O O
Smashwords, B-DatasetName B-DatasetName
which O O
achieved O O
an O O
average O O
accuracy B-MetricName B-MetricName
of O O
64.5, B-MetricValue B-MetricValue
well O O
below O O
81.1. B-MetricValue B-MetricValue

The O O
drop O O
in O O
average O O
accuracy B-MetricName B-MetricName
is O O
striking O O
- O O
from O O
81.1 B-MetricValue B-MetricValue
to O O
59.2. B-MetricValue B-MetricValue

The O O
preference O O
score O O
was O O
calculated O O
by O O
summing O O
the O O
cross-entropy O O
errors O O
at O O
each O O
position O O
in O O
the O O
sentence O O
(Zaczynska O O
et O O
al., O O
2020). O O

Additionally, O O
and O O
more O O
importantly, O O
during O O
training, O O
we O O
modified O O
the O O
probability B-HyperparameterName B-HyperparameterName
of I-HyperparameterName I-HyperparameterName
unmasking I-HyperparameterName I-HyperparameterName
from O O
0.1 B-HyperparameterValue B-HyperparameterValue
to B-HyperparameterValue B-HyperparameterValue
0.0 B-HyperparameterValue I-HyperparameterValue
- O O
effectively O O
removing O O
unmasking. O O

We O O
introduce O O
a O O
scaled-down O O
masked O O
language O O
model O O
based O O
on O O
RoBERTa B-MethodName B-MethodName
(Liu O O
et O O
al., O O
2019), O O
with O O
8M O O
parameters, O O
8912 O O
vocabulary O O
items, O O
and O O
trained O O
on O O
no O O
more O O
than O O
30M O O
words. O O

The O O
pre-training O O
stage O O
for O O
both O O
BART B-MethodName B-MethodName
and O O
mBART B-MethodName B-MethodName
is O O
akin O O
to O O
a O O
denoising O O
autoencoder, O O
in O O
which O O
the O O
model O O
receives O O
a O O
noisy O O
(in O O
this O O
case O O
masked) O O
sentence, O O
and O O
it O O
learns O O
to O O
reconstruct O O
it. O O

For O O
evaluating O O
on O O
sentiment B-TaskName B-TaskName
analysis I-TaskName I-TaskName
(SMILE) B-DatasetName B-DatasetName
and O O
offensive B-TaskName B-TaskName
language I-TaskName I-TaskName
identification I-TaskName I-TaskName
(OLID), B-DatasetName B-DatasetName
we O O
trained O O
a O O
simple O O
word-level O O
TF-IDF B-MethodName B-MethodName
model O O
together O O
with O O
a O O
linear O O
SVM B-MethodName B-MethodName
with O O
balanced O O
weights. O O

As O O
opposed O O
to O O
current O O
two-stage O O
methods O O
for O O
word O O
candidate O O
generation O O
and O O
ranking, O O
our O O
approach O O
is O O
more O O
straightforward. O O

For O O
example, O O
in O O
the O O
case O O
of O O
Croatian, O O
even O O
though O O
the O O
dataset O O
is O O
the O O
second O O
largest, O O
the O O
performance O O
is O O
lower O O
than O O
for O O
other O O
languages. O O

Our O O
lexical O O
normalization O O
improves O O
results O O
on O O
both O O
these O O
tasks, O O
compared O O
to O O
modelling O O
the O O
raw, O O
unprocessed O O
social O O
media O O
posts. O O

We O O
trained O O
a O O
word-level O O
TF-IDF B-MethodName B-MethodName
and O O
a O O
linear O O
SVM B-MethodName B-MethodName
with O O
balanced O O
weights O O
for O O
both O O
datasets O O
and O O
reported O O
a O O
macro B-MetricName B-MetricName
F1 I-MetricName I-MetricName
score. O O

Moreover, O O
we O O
also O O
evaluated O O
the O O
effect O O
of O O
lexical O O
normalization O O
on O O
two O O
other O O
tasks O O
- O O
sentiment B-TaskName B-TaskName
analysis I-TaskName I-TaskName
on O O
the O O
SMILE B-DatasetName B-DatasetName
dataset O O
and O O
offensive B-TaskName B-TaskName
language I-TaskName I-TaskName
identification I-TaskName I-TaskName
on O O
OLID B-DatasetName B-DatasetName
(Table O O
5). O O

Since O O
the O O
memory O O
requirements O O
of O O
an O O
mBART B-MethodName B-MethodName
model O O
are O O
quite O O
high, O O
we O O
employed O O
gradient O O
accumulation O O
to O O
increase O O
the O O
batch O O
size. O O

Moreover, O O
we O O
also O O
evaluate O O
the O O
extrinsic O O
performance O O
of O O
our O O
model O O
on O O
two O O
additional O O
tasks: O O
sentiment B-TaskName B-TaskName
analysis I-TaskName I-TaskName
on O O
the O O
SMILE B-DatasetName B-DatasetName
dataset O O
(Wang O O
et O O
al., O O
2016) O O
and O O
hate B-TaskName B-TaskName
speech I-TaskName I-TaskName
detection I-TaskName I-TaskName
on O O
OLID B-DatasetName B-DatasetName
dataset O O
(Zampieri O O
et O O
al., O O
2019a). O O

However, O O
we O O
do O O
not O O
perform O O
translation O O
between O O
languages, O O
but O O
instead, O O
we O O
use O O
mBART B-MethodName B-MethodName
as O O
a O O
denoising O O
autoencoder, O O
i.e. O O
translating O O
from O O
bad O O
English O O
to O O
good O O
English. O O

MoNoise B-MethodName B-MethodName
is O O
a O O
normalization O O
model O O
using O O
spelling O O
correction O O
and O O
word O O
embeddings O O
for O O
candidate O O
generation O O
and O O
a O O
feature-based O O
random B-MethodName B-MethodName
forest I-MethodName I-MethodName
classifier O O
for O O
candidate O O
ranking. O O

One O O
way O O
to O O
resolve O O
this O O
issue O O
is O O
through O O
lexical O O
normalization, O O
which O O
is O O
the O O
process O O
of O O
transforming O O
non-standard O O
text, O O
usually O O
from O O
social O O
media, O O
into O O
a O O
more O O
standardized O O
form. O O

As O O
we O O
can O O
see, O O
AAN B-MethodName B-MethodName
and O O
all O O
the O O
variants O O
with O O
AAN B-MethodName B-MethodName
have O O
an O O
absolutely O O
lower O O
Self-BLEU B-MetricName B-MetricName
score O O
with O O
the O O
Transformer. B-MethodName B-MethodName

The O O
Self-BLEU B-MetricName B-MetricName
scores O O
in O O
Table O O
4 O O
demonstrate O O
the O O
difference O O
between O O
two O O
models, O O
more O O
different O O
models O O
generally O O
have O O
lower O O
scores. O O

Knowledge O O
Distillation O O
and O O
more O O
BT O O
data O O
can O O
improve O O
the O O
BLEU B-MetricName B-MetricName
score O O
from O O
20.82 B-MetricValue B-MetricValue
to O O
22.11. B-MetricValue B-MetricValue

Our O O
WMT2021 B-DatasetName B-TaskName
English→Chinese O O
submission O O
achieves O O
a O O
SacreBLEU B-MetricName B-MetricName
score O O
of O O
36.9, B-MetricValue B-MetricValue
which O O
is O O
the O O
highest O O
among O O
all O O
submissions O O
and O O
chrF B-MetricName B-MetricName
score O O
of O O
0.337. B-MetricValue B-MetricValue

With O O
BSBE B-MethodName B-MethodName
strategies O O
in O O
Sec. O O
3.6, O O
a O O
better O O
model O O
combination O O
with O O
less O O
number O O
of O O
models O O
are O O
quickly O O
searched, O O
and O O
we O O
finally O O
achieve O O
50.94 B-MetricValue B-MetricValue
BLEU B-MetricName B-MetricName
score. O O

We O O
further O O
gain O O
+0.62 B-MetricValue B-MetricValue
BLEU B-MetricName B-MetricName
score O O
after O O
applying O O
knowledge O O
distillation O O
and O O
+0.24 B-MetricValue B-MetricValue
BLEU B-MetricName B-MetricName
from O O
Forward-Translation. B-MethodName B-MethodName

We O O
use O O
the O O
Adam O O
optimizer O O
with O O
β1 B-HyperparameterName B-HyperparameterName
= O O
0.9, B-HyperparameterValue B-HyperparameterValue
β2 B-HyperparameterName B-HyperparameterName
= O O
0.998. B-HyperparameterValue B-HyperparameterValue

After O O
applying O O
large-scale B-MethodName B-MethodName
Back-Translation, I-MethodName I-MethodName
we O O
obtain O O
+2.0 B-MetricValue B-MetricValue
BLEU B-MetricName B-MetricName
score O O
on O O
the O O
baseline. O O

The O O
batch B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
is O O
set O O
to O O
8192 B-HyperparameterValue B-HyperparameterValue
tokens O O
per O O
GPU O O
and O O
we O O
set O O
the O O
“update-freq” O B-HyperparameterName
parameter O O
in O O
Fairseq B-DatasetName B-DatasetName
to O O
2. B-HyperparameterValue B-HyperparameterValue

For O O
training O O
strategies, O O
we O O
mainly O O
focus O O
on O O
scheduled B-MethodName B-MethodName
sampling I-MethodName I-MethodName
based O O
on O O
decoding O O
steps O O
(Liu O O
et O O
al., O O
2021b), O O
the O O
confidence-aware B-MethodName B-MethodName
scheduled I-MethodName I-MethodName
sampling I-MethodName I-MethodName
(Mihaylova O O
and O O
Martins, O O
2019; O O
Duckworth O O
et O O
al., O O
2019; O O
Liu O O
et O O
al., O O
2021a), O O
the O O
target B-MethodName B-MethodName
denoising I-MethodName I-MethodName
(Meng O O
et O O
al., O O
2020) O O
method O O
and O O
the O O
Graduated B-MethodName B-MethodName
Label I-MethodName I-MethodName
Smoothing I-MethodName I-MethodName
(Wang O O
et O O
al., O O
2020) O O
for O O
in-domain O O
finetuning. O O

﻿In O O
our O O
experiments, O O
we O O
employ O O
data O O
filtering, O O
large-scale O O
synthetic O O
data O O
generation O O
(i.e., O O
back-translation, O O
knowledge O O
distillation, O O
forward-translation, O O
iterative O O
in-domain O O
knowledge O O
transfer), O O
advanced O O
finetuning O O
approaches, O O
and O O
boosted O O
Self-BLEU B-MetricName B-MetricName
based O O
model O O
ensemble. O O

Finally, O O
from O O
a O O
cognitive O O
plausibility O O
perspective, O O
holistic B-MethodName B-MethodName
scoring I-MethodName I-MethodName
resembles O O
much O O
more O O
closely O O
the O O
actual O O
situation O O
faced O O
by O O
humans O O
tasked O O
to O O
judge O O
grammatical O O
acceptability; O O
training O O
models O O
to O O
perform O O
well O O
with O O
holistic B-MethodName B-MethodName
scoring I-MethodName I-MethodName
should O O
be O O
considered O O
in O O
future O O
work. O O

For O O
clarity, O O
we O O
refer O O
to O O
our O O
method O O
as O O
holistic B-MethodName B-MethodName
scoring, I-MethodName I-MethodName
and O O
that O O
of O O
Salazar O O
et O O
al. O O
(2020b) O O
as O O
MLM B-MethodName B-MethodName
scoring. I-MethodName I-MethodName

The O O
direction O O
of O O
this O O
effect O O
is O O
what O O
one O O
would O O
predict O O
under O O
the O O
assumption O O
that O O
input O O
to O O
children O O
aged O O
1-6 O O
years O O
but O O
not O O
beyond O O
(6-12 O O
years) O O
scaffolds O O
grammatical O O
development. O O

Moreover, O O
because O O
the O O
total O O
number O O
of O O
occurrences O O
of O O
each O O
content O O
word O O
in O O
all O O
our O O
test O O
sentences O O
is O O
closely O O
counterbalanced O O
across O O
all O O
three O O
corpora O O
(see O O
Appendix O O
B O O
for O O
details), O O
any O O
observed O O
differences O O
can O O
be O O
attributed O O
to O O
structural O O
as O O
opposed O O
to O O
word-frequency-related O O
differences O O
between O O
corpora. O O

To O O
enable O O
fair O O
comparisons, O O
we O O
use O O
this O O
method O O
to O O
evaluate O O
all O O
models O O
considered O O
in O O
this O O
paper. O O

We O O
also O O
added O O
2 O O
phenomena O O
not O O
in O O
BLiMP B-DatasetName B-DatasetName
("case", O O
and O O
"local O O
attractor" O O
to O O
challenge O O
subject-verb O O
agreement), O O
for O O
a O O
total O O
of O O
23 O O
paradigms O O
and O O
13 O O
phenomena. O O

Toward O O
that O O
end, O O
we O O
carefully O O
counterbalanced O O
every O O
word O O
list O O
used O O
to O O
construct O O
sentences O O
(e.g. O O
nouns, O O
adjectives, O O
verbs) O O
such O O
that O O
the O O
total O O
number O O
of O O
occurrences O O
of O O
all O O
word O O
types O O
in O O
a O O
given O O
list O O
was O O
approximately O O
equal O O
(differed O O
no O O
more O O
than O O
1K) O O
across O B-DatasetName
AO-CHILDES, B-DatasetName I-DatasetName
AO-Newsela, B-DatasetName B-DatasetName
and O O
Wikipedia-1. B-DatasetName B-DatasetName

Thus, O O
in O O
order O O
to O O
further O O
isolate O O
the O O
effect O O
of O O
domain, O O
we O O
included O O
a O O
fifth O O
corpus, O O
which O O
we O O
will O O
refer O O
to O O
as O O
AO-Newsela, B-DatasetName B-DatasetName
based O O
on O O
the O O
Newsela B-DatasetName B-DatasetName
corpus I-DatasetName I-DatasetName
(Xu O O
et O O
al., O O
2015). O O

Our O O
main O O
corpus O O
of O O
interest O O
is O O
AO-CHILDES B-DatasetName B-DatasetName
(AgeOrdered-CHILDES, O B-DatasetName
Huebner O O
and O O
Willits, O O
2021). O O

Briefly, O O
BabyBERTa B-MethodName B-MethodName
uses O O
only O O
8 B-HyperparameterValue B-HyperparameterValue
layers, B-HyperparameterName B-HyperparameterName
8 B-HyperparameterValue B-HyperparameterValue
attention B-HyperparameterName B-HyperparameterName
heads, I-HyperparameterName I-HyperparameterName
256 B-HyperparameterValue B-HyperparameterValue
hidden B-HyperparameterName B-HyperparameterName
units, I-HyperparameterName I-HyperparameterName
and O O
an I-HyperparameterName B-HyperparameterName
intermediate I-HyperparameterName I-HyperparameterName
size I-HyperparameterName I-HyperparameterName
of O O
1024. B-HyperparameterValue B-HyperparameterValue

In O O
this O O
work, O O
we O O
examined O O
the O O
grammatical O O
knowledge O O
of O O
RoBERTa B-MethodName B-MethodName
(Liu O O
et O O
al., O O
2019) O O
when O O
trained O O
on O O
a O O
5M O O
word O O
corpus O O
of O O
language O O
acquisition O O
data O O
to O O
simulate O O
the O O
input O O
available O O
to O O
children O O
between O O
the O O
ages O O
1 O O
and O O
6. O O

As O O
such, O O
for O O
the O O
post-processing O O
phase, O O
we O O
aligned O O
input O O
words O O
with O O
their O O
normalized O O
counterparts O O
based O O
on O O
the O O
Levenshtein B-MetricName B-MetricName
distance I-MetricName I-MetricName
between O O
them. O O

The O O
training O O
was O O
performed O O
on O O
an O O
NVIDIA O O
RTX O O
2070 O O
graphics O O
card. O O

The O O
dataset O O
comprises O O
Twitter O O
posts O O
from O O
all O O
languages, O O
but O O
some O O
languages O O
also O O
have O O
texts O O
from O O
additional O O
sources. O O

This O O
way, O O
we O O
take O O
the O O
whole O O
sentence O O
into O O
consideration O O
when O O
correcting O O
the O O
text. O O

It O O
has O O
proven O O
to O O
be O O
effective O O
in O O
increasing O O
performance O O
on O O
tasks O O
such O O
as O O
POS B-TaskName B-TaskName
tagging I-TaskName I-TaskName
(van O O
der O O
Goot O O
and O O
Çetinoglu, O O
2021), O O
dependency B-TaskName B-TaskName
parsing I-TaskName I-TaskName
(van O O
der O O
Goot, O O
2019a) O O
and O O
sentiment B-TaskName B-TaskName
analysis I-TaskName I-TaskName
(Mandal O O
and O O
Nanmaran, O O
2018). O O

Talking-Heads B-MethodName B-MethodName
Attention I-MethodName I-MethodName
(Shazeer O O
et O O
al., O O
2020) O O
is O O
a O O
new O O
variation O O
that O O
inserts O O
two O O
additional O O
learned O O
linear O O
projection O O
weights, O O
Wl O O
and O O
Ww, O O
to O O
transform O O
the O O
attention-logits O O
and O O
the O O
attention O O
scores O O
respectively, O O
moving O O
information O O
across O O
attention O O
heads. O O

The O O
Talking-Heads B-MethodName B-MethodName
Attention I-MethodName I-MethodName
has O O
the O O
minimum O O
scores O O
among O O
all O O
the O O
variants. O O

Here O O
we O O
take O O
En→Zh O O
models O O
as O O
examples O O
to O O
conduct O O
the O O
diversity O O
and O O
ensemble O O
experiments. O O

Otherwise, O O
it O O
is O O
added O O
to O O
a O O
temporary O O
model O O
list O O
and O O
still O O
has O O
a O O
weak O O
chance O O
to O O
be O O
reused O O
in O O
the O O
future. O O

For O O
our O O
submitted O O
system, O O
we O O
search O O
from O O
over O O
500 O O
models. O O

The O O
Talking-Heads B-MethodName B-MethodName
Attention I-MethodName I-MethodName
has O O
the O O
minimum O O
scores O O
among O O
all O O
the O O
variants. O O

For O O
the O O
post-processing, O O
we O O
apply O O
de-truecaseing B-MethodName B-MethodName
and O O
de-tokenizing B-MethodName B-MethodName
on O O
the O O
English O O
and O O
German O O
translations O O
with O O
the O O
scripts O O
provided O O
in O O
Moses. B-MethodName B-DatasetName

We O O
use O O
byte B-MethodName B-MethodName
pair I-MethodName I-MethodName
encoding I-MethodName I-MethodName
BPE I-MethodName I-MethodName
(Sennrich O O
et O O
al., O O
2016b) O O
with O O
32K O O
operations O O
for O O
all O O
the O O
languages. O O

For O O
monolingual O O
data, O O
we O O
select O O
data O O
from O O
News B-DatasetName B-DatasetName
Crawl, I-DatasetName I-DatasetName
Common B-DatasetName B-DatasetName
Crawl I-DatasetName I-DatasetName
and O O
Extended B-DatasetName B-DatasetName
Common I-DatasetName I-DatasetName
Crawl, I-DatasetName I-DatasetName
it O O
is O O
then O O
divided O O
into O O
several O O
parts, O O
each O O
containing O O
50M O O
sentences. O O

We O O
use O O
warmup B-HyperparameterName B-HyperparameterName
step I-HyperparameterName I-HyperparameterName
= O O
4000. B-HyperparameterValue B-HyperparameterValue

The O O
learning B-HyperparameterName B-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
is O O
set O O
to O O
0.0005 B-HyperparameterValue B-HyperparameterValue
for O O
Fairseq B-DatasetName B-DatasetName
and O B-HyperparameterValue
2.0 B-HyperparameterValue I-HyperparameterValue
for O O
OpenNMT. B-DatasetName B-DatasetName

We O O
combine O O
the O O
Average B-MethodName B-MethodName
Attention I-MethodName I-MethodName
Transformer I-MethodName I-MethodName
(AAN) I-MethodName I-MethodName
(Zhang O O
et O O
al., O O
2018) O O
and O O
Multi-HeadAttention B-MethodName B-MethodName
(Vaswani O O
et O O
al., O O
2017) O O
to O O
derive O O
a O O
series O O
of O O
effective O O
and O O
diverse O O
model O O
variants. O O

Besides O O
the O O
Pre-Norm B-MethodName B-MethodName
Transformer, I-MethodName I-MethodName
the O O
Post-Norm B-MethodName B-MethodName
Transformer I-MethodName I-MethodName
is O O
also O O
used O O
as O O
one O O
of O O
our O O
baselines O O
this O O
year. O O

Aggregated O O
results O O
for O O
all O O
method O O
and O O
model O O
combinations, O O
averaged O O
over O O
three O O
seeds. O O
Model O O
names O O
are O O
abbreviated O O
for O O
space: O O
FastT B-MethodName B-MethodName
is O O
FastText, B-MethodName B-MethodName
DRoB B-MethodName B-MethodName
is O O
DistilRoBERTa, B-MethodName B-MethodName
and O O
DeXL B-MethodName B-MethodName
is O O
DeBERTa-XLarge. B-MethodName B-MethodName
Avg O O
is O O
the O O
average O O
across O O
models O O
for O O
that O O
method. O O
FastText B-MethodName B-MethodName
doesn’t O O
produce O O
context-dependent O O
representations, O O
and O O
so O O
is O O
not O O
usable O O
on O O
the O O
QA O O
task. O O

DistilRoBERTa B-MethodName B-MethodName
represents O O
a O O
distilled O O
version O O
of O O
RoBERTa-base B-MethodName B-MethodName
(Liu O O
et O O
al., O O
2019). O O
It O O
contains O O
82 O O
million O O
parameters, O O
compared O O
to O O
the O O
125 O O
million O O
parameters O O
found O O
in O O
RoBERTa. B-MethodName B-MethodName

DeBERTa-XLarge B-MethodName B-MethodName
is O O
our O O
large O O
model, O O
which O O
contains O O
750 O O
million O O
parameters O O
and O O
currently O O
is O O
the O O
state-of-the-art O O
on O O
many O O
natural O O
language O O
understanding O O
tasks O O
(He O O
et O O
al., O O
2021). O O

Learning B-HyperparameterName B-HyperparameterName
rates I-HyperparameterName I-HyperparameterName
were O O
chosen O O
from O O
the O O
set O O
of O O
[1e-6, B-HyperparameterValue B-HyperparameterValue
3e-6, I-HyperparameterValue I-HyperparameterValue
1e-5, I-HyperparameterValue I-HyperparameterValue
3e-5, I-HyperparameterValue I-HyperparameterValue
1e-4]. I-HyperparameterValue I-HyperparameterValue

Occasionally, O O
when O O
varying O O
dropout B-HyperparameterName B-HyperparameterName
had O O
no O O
effect, O O
we O O
consider O O
doubling O O
the O O
batch B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
instead O O
from O O
16 B-HyperparameterValue B-HyperparameterValue
to O O
32. B-HyperparameterValue B-HyperparameterValue

In O O
our O O
experiments, O O
we O O
fine-tune O O
parameters O O
during O O
initial O O
training O O
with O O
only O O
six O O
runs, O O
which O O
is O O
composed O O
of O O
three O O
learning B-HyperparameterName B-HyperparameterName
rates I-HyperparameterName I-HyperparameterName
and O O
two O O
levels O O
of O O
dropout B-HyperparameterName B-HyperparameterName
at O O
0.1 B-HyperparameterValue B-HyperparameterValue
and O O
0.05. B-HyperparameterValue B-HyperparameterValue

The O O
Social B-DatasetName B-DatasetName
Bias I-DatasetName I-DatasetName
Frames I-DatasetName I-DatasetName
dataset O O
collects O O
instances O O
of O O
biases O O
and O O
implied O O
stereotypes O O
found O O
in O O
text O O
(Sap O O
et O O
al., O O
2020). O O
We O O
extract O O
just O O
the O O
label O O
of O O
whether O O
a O O
statement O O
is O O
offensive O O
for O O
binary O O
classification. O O

We O O
adopt O O
the O O
MultiNLI B-DatasetName B-DatasetName
dataset O O
for O O
natural O O
language O O
inference O O
(Williams O O
et O O
al., O O
2018). O O

Our O O
third O O
task O O
uses O O
the O O
first O O
round O O
of O O
the O O
DynaSent B-DatasetName B-DatasetName
corpus O O
for O O
four-way B-TaskName B-TaskName
sentiment I-TaskName I-TaskName
analysis I-TaskName I-TaskName
(Potts O O
et O O
al., O O
2021). O O

Our O O
final O O
task O O
is O O
question B-TaskName B-TaskName
answering I-TaskName I-TaskName
with O O
examples O O
coming O O
from O O
the O O
NewsQA B-DatasetName B-DatasetName
dataset O O
(Trischler O O
et O O
al., O O
2017). O O

We O O
measured O O
the O O
running O O
time O O
of O O
EmojiCloud B-MethodName B-MethodName
on O O
a O O
laptop O O
with O O
an O O
AMD O O
Ryzen O O
7 O O
4800HS O O
processor O O
and O O
16 O O
GB O O
RAM. O O

Inspired O O
by O O
the O O
word B-MethodName B-MethodName
cloud I-MethodName I-MethodName
(Bielenberg O O
and O O
Zacher, O O
2005; O O
Dubinko O O
et O O
al., O O
2007), O O
which O O
has O O
be O O
adopted O O
as O O
an O O
effective O O
way O O
to O O
visualize O O
the O O
frequency O O
and O O
importance O O
of O O
words O O
in O O
text O O
mining, O O
we O O
thought O O
the O O
word O O
cloud O O
of O O
emojis O O
seemed O O
to O O
be O O
a O O
good O O
solution. O O

This O O
paper O O
proposes O O
EmojiCloud, B-MethodName B-MethodName
an O O
open-source O O
Python-based O O
emoji O O
cloud O O
visualization O O
tool, O O
to O O
generate O O
a O O
quick O O
and O O
straightforward O O
understanding O O
of O O
emojis O O
from O O
the O O
perspective O O
of O O
frequency O O
and O O
importance. O O

All O O
models O O
trained O O
on O O
more O O
than O O
60,000 O O
training O O
data O O
have O O
more O O
than O O
90 O O
points O O
in O O
the O O
recall, B-MetricName B-MetricName
precision, B-MetricName B-MetricName
and O O
f-measure B-MetricName B-MetricName
score. O O

However, O O
the O O
results O O
show O O
that O O
the O O
English O O
word O O
segmentation O O
model O O
has O O
a O O
lower O O
recall, B-MetricName B-MetricName
precision, B-MetricName B-MetricName
and O O
f-measure B-MetricName B-MetricName
scores O O
than O O
other O O
language O O
models; O O
even O O
Mongolian O O
has O O
fewest O O
training O O
data. O O

The O O
resulted O O
model O O
has O O
the O O
encoder O O
and O O
decoder O O
layer O O
with O O
128 B-HyperparameterValue B-HyperparameterValue
hidden B-HyperparameterName B-HyperparameterName
units, I-HyperparameterName I-HyperparameterName
and O O
the O O
batch B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
is O O
32. B-HyperparameterValue B-HyperparameterValue

We O O
train O O
a O O
monolingual O O
word O O
segmentation O O
model O O
for O O
each O O
given O O
language O O
with O O
identical O O
parameters, O O
50 B-HyperparameterValue B-HyperparameterValue
epochs, B-HyperparameterName B-HyperparameterName
1 B-HyperparameterValue B-HyperparameterValue
encoder B-HyperparameterName B-HyperparameterName
layer, I-HyperparameterName I-HyperparameterName
1 B-HyperparameterValue B-HyperparameterValue
decoder B-HyperparameterName B-HyperparameterName
layer, I-HyperparameterName I-HyperparameterName
0.0001 B-HyperparameterValue B-HyperparameterValue
learning B-HyperparameterName B-HyperparameterName
rate, I-HyperparameterName I-HyperparameterName
using O O
the O O
Adam O O
optimizer O O
(Kingma O O
and O O
Ba, O O
2014) O O
and O O
the O O
cross-entropy O O
loss. O O

A O O
dataset O O
for O O
this O O
task, O O
the O O
organizer O O
integrated O O
all O O
basic O O
types O O
of O O
morphological O O
databases O O
(including O O
UniMorph O O
(Kirov O O
et O O
al., O O
2018; O O
McCarthy O O
et O O
al., O O
2020; O O
Batsuren O O
et O O
al., O O
2022b) O O
– O O
inflectional O O
morphology; O O
MorphyNet B-TaskName B-DatasetName
(Batsuren O O
et O O
al., O O
2021) O O
– O O
derivational O O
morphology; O O
Universal B-DatasetName B-DatasetName
Dependencies I-DatasetName I-DatasetName
(Nivre O O
et O O
al., O O
2017) O O
and O O
ten O O
editions O O
of O O
Wiktionary O O
– O O
compound O O
morphology O O
and O O
root O O
words) O O
cover O O
9 O O
languages. O O
8 O O
of O O
these O O
languages O O
were O O
available O O
initially, O O
while O O
1 O O
surprise O O
language, O O
Mongolia, O O
was O O
released O O
one O O
week O O
before O O
the O O
submission O O
deadline. O O

The O O
first O O
is O O
based O O
on O O
decision O O
trees O O
with O O
gradient O O
boosting, O O
while O O
the O O
second O O
applies O O
Bi-LSTM B-MethodName B-MethodName
neural O O
network. O O

Recent O O
works O O
developed O O
two O O
more O O
supervised O O
machine O O
learning O O
models O O
for O O
morpheme B-TaskName B-TaskName
segmentation I-TaskName I-TaskName
with O O
classification O O
for O O
Russian O O
words O O
(Bolshakova O O
and O O
Sapin, O O
2019a), O O
(Bolshakova O O
and O O
Sapin, O O
2019b). O O

Morfessor B-MethodName B-MethodName
system O O
(Creutz O O
and O O
Lagus, O O
2007), O O
(Smit O O
et O O
al., O O
2014) O O
exploits O O
unsupervised O O
machine O O
learning O O
methods O O
to O O
be O O
trained O O
on O O
a O O
large O O
unlabelled O O
text. O O

The O O
task O O
of O O
machine B-TaskName B-TaskName
translation I-TaskName I-TaskName
has O O
seen O O
significant O O
progress O O
in O O
recent O O
times O O
with O O
the O O
advent O O
of O O
Transformer-based O O
models O O
(Vaswani O O
et O O
al., O O
2017) O O
for O O
this O O
year’s O O
SIGMORPHON O O
2022 O O
shared O O
task O O
on O O
morpheme B-TaskName B-TaskName
segemntation I-TaskName I-TaskName
(Batsuren O O
et O O
al., O O
2022a) O O
which O O
at O O
the O O
word O O
level, O O
participants O O
will O O
be O O
asked O O
to O O
segment O O
a O O
given O O
word O O
into O O
a O O
sequence O O
of O O
morphemes. O O

Morphological O O
analysis O O
is O O
the O O
heart O O
of O O
nearly O O
all O O
natural O O
language O O
processing O O
tasks, O O
such O O
as O O
sentiment B-TaskName B-TaskName
analysis, I-TaskName I-TaskName
machine B-TaskName B-TaskName
translation, I-TaskName I-TaskName
information B-TaskName B-TaskName
retrieval, I-TaskName I-TaskName
etc. O O

We O O
develop O O
monolingual O O
models O O
for O O
world-level O O
morpheme O O
segmentation O O
and O O
focus O O
on O O
improving O O
the O O
model O O
by O O
using O O
various O O
training O O
strategies O O
to O O
improve O O
accuracy O O
and O O
generalization O O
across O O
languages. O O

We O O
find O O
no O O
significant O O
difference O O
(t O O
= O O
0.442, O O
p O O
= O O
0.662) O O
in O O
BPP B-MetricName B-MetricName
scores O O
across O O
predicate O O
types. O O

As O O
can O O
be O O
seen O O
in O O
Figure O O
2, O O
this O O
model O O
is O O
BERT, B-MethodName B-MethodName
probed O O
with O O
a O O
classifier O O
trained O O
on O O
12.5% B-MetricValue B-HyperparameterValue
of O O
the O O
full O O
training B-HyperparameterName B-HyperparameterName
split. I-HyperparameterName I-HyperparameterName

Lastly, O O
LUKE’s B-MethodName B-MethodName
performance, O O
with O O
an O O
average O O
score O O
of O O
15.05, B-MetricValue B-MetricValue
is O O
significantly O O
lower O O
than O O
that O O
of O O
the O O
other O O
three O O
models O O
(t-tests O O
against O O
BERT, B-MethodName B-MethodName
StructBERT B-MethodName B-MethodName
and O O
GPT-2 B-MethodName B-MethodName
yield O O
p-values O O
approaching O O
zero), O O
suggesting O O
that O O
its O O
ability O O
to O O
track O O
entities O O
does O O
not O O
significantly O O
help O O
in O O
solving O O
logical O O
deductions. O O

GPT-2’s B-MethodName B-MethodName
high O O
standard B-MetricName B-MetricName
deviation I-MetricName I-MetricName
across O O
splits O O
(on O O
average, O O
20.82) B-MetricValue B-MetricValue
indicates O O
a O O
severe O O
instability O O
in O O
its O O
capacity O O
to O O
correctly O O
encode O O
logical O O
reasoning O O
cues. O O

BERT B-MethodName B-MethodName
and O O
StructBERT B-MethodName B-MethodName
are O O
the O O
best O O
performing O O
models O O
with O O
BPP B-MetricName B-MetricName
scores O O
ranging O O
roughly O O
between O O
15 B-MetricValue B-MetricValue
and O O
40 B-MetricValue B-MetricValue
(except O O
for O O
the O O
smallest O O
training B-HyperparameterName B-HyperparameterName
split I-HyperparameterName I-HyperparameterName
sizes). I-HyperparameterName I-HyperparameterName

We O O
therefore O O
use O O
Scrambled B-MethodName B-MethodName
to O O
compute O O
BPP B-MetricName B-MetricName
scores, O O
as O O
it O O
yields O O
the O O
strictest O O
(or O O
most O O
selective; O O
Hewitt O O
and O O
Liang, O O
2019a) O O
baseline O O
setup. O O

For O O
the O O
Random O O
baseline, O O
we O O
train O O
the O O
probing O O
classifier O O
on O O
randomly O O
initialised O O
vector O O
representations. O O

Humans O O
should O O
achieve O O
50% B-MetricValue B-MetricValue
accuracy B-MetricName B-MetricName
on O O
this O O
version O O
of O O
the O O
dataset O O
because O O
random O O
word O O
order O O
impedes O O
logical O O
reasoning. O O

We O O
split O O
AnaLog B-TaskName B-DatasetName
into O O
a O O
main O O
training O O
and O O
testing O O
set O O
using O O
an O O
80-20 B-HyperparameterValue B-HyperparameterValue
split. O O

Diagnostic O O
probes O O
are O O
known O O
for O O
achieving O O
high O O
accuracy B-MetricName B-MetricName
on O O
linguistic O O
tasks O O
despite O O
representations O O
not O O
necessarily O O
encoding O O
relevant O O
linguistic O O
information O O
(Hewitt O O
and O O
Liang, O O
2019b; O O
Belinkov, O O
2021). O O
To O O
address O O
this O O
issue, O O
following O O
the O O
approach O O
taken O O
by O O
Zhang O O
and O O
Bowman O O
(2018), O O
we O O
measure O O
probing O O
performance O O
as O O
the O O
difference O O
between O O
the O O
classification O O
accuracy O O
of O O
the O O
probing O O
classifier O O
trained O O
on O O
the O O
original O O
dataset, O O
and O O
the O O
accuracy B-MetricName B-MetricName
of O O
a O O
baseline. O O
We O O
call O O
this O O
baselined O O
probing O O
performance O O
(BPP), O O
adopting O O
the O O
terminology O O
proposed O O
by O O
Hewitt O O
et O O
al. O O
(2021). O O

We O O
fit O O
a O O
binary O O
logistic O O
regression O O
classifier6—as O O
more O O
powerful O O
classifiers O O
have O O
been O O
shown O O
to O O
produce O O
unreliable O O
results O O
(Hewitt O O
and O O
Liang, O O
2019a)—to O O
the O O
training O O
set, O O
obtain O O
predictions O O
for O O
the O O
test O O
set, O O
and O O
compute O O
accuracy O O
and O O
baselined O O
probing O O
scores, O O
as O O
described O O
in O O
the O O
next O O
section. O O

GPT-2 B-MethodName B-MethodName
(Radford O O
et O O
al., O O
2019) O O
An O O
autoregressive O O
Transformer-based O O
LM O O
which O O
is O O
known O O
for O O
its O O
high O O
performance O O
across O O
text-generation O O
tasks, O O
yet O O
has O O
not O O
been O O
frequently O O
tested O O
on O O
NLI O O
datasets. O O

We O O
expect O O
StructBERT B-MethodName B-MethodName
to O O
provide O O
insight O O
on O O
whether O O
structural O O
cues O O
are O O
useful O O
in O O
solving O O
logic-based O O
NLI. O O

This O O
enables O O
LMs O O
to O O
output O O
representations O O
that O O
are O O
as O O
stable O O
as O O
possible. O O

For O O
the O O
restrictor O O
noun O O
in O O
universal O O
quantification O O
premises O O
(e.g., O O
director O O
in O O
the O O
UNI O O
premise O O
in O O
Table O O
1), O O
we O O
use O O
the O O
four O O
most O O
common O O
nouns O O
in O O
COCA B-DatasetName B-DatasetName
(Davies, O O
2010) O O
which O O
correspond O O
to O O
the O O
category O O
NOUN.PERSON O O
in O O
Wordnet B-DatasetName B-DatasetName
(Fellbaum, O O
1998), O O
do O O
not O O
begin O O
with O O
a O O
vowel, O O
and O O
are O O
semantically O O
compatible O O
with O O
our O O
predicates. O O

This O O
is O O
in O O
contrast O O
to O O
both O O
SuperGLUE O O
(Wang O O
et O O
al., O O
2020) O O
where O O
the O O
logical O O
connectives O O
vary O O
between O O
being O O
positioned O O
in O O
the O O
premise O O
or O O
hypothesis, O O
and O O
LogicNLI B-MethodName B-MethodName
(Tian O O
et O O
al., O O
2021), O O
where O O
premises O O
consist O O
of O O
multiple O O
facts O O
and O O
rules O O
and O O
do O O
not O O
isolate O O
logical O O
connectives. O O

We O O
extend O O
the O O
LAKNLI B-DatasetName B-DatasetName
dataset O O
(Ryb O O
and O O
Van O O
Schijndel, O O
2021) O O
and O O
present O O
AnaLog, B-TaskName B-TaskName
an O O
NLI O O
dataset O O
that O O
explicitly O O
targets O O
different O O
types O O
of O O
logical B-TaskName B-TaskName
reasoning. I-TaskName I-TaskName

Yet, O O
Kim O O
et O O
al. O O
(2019b) O O
showed O O
that O O
BERT’s B-MethodName B-MethodName
performance O O
is O O
only O O
11% B-MetricValue B-MetricValue
less O O
than O O
human B-MethodName B-MethodName
performance I-MethodName I-MethodName
on O O
comparative B-TaskName B-TaskName
reasoning I-TaskName I-TaskName
tasks, O O
and O O
10% B-MetricValue B-MetricValue
less O O
than O O
human B-MethodName B-MethodName
performance I-MethodName I-MethodName
on O O
spatial B-TaskName B-TaskName
reasoning I-TaskName I-TaskName
tasks. O O

Kim O O
et O O
al. O O
(2019b) O O
showed O O
that O O
BERT B-MethodName B-MethodName
(Devlin O O
et O O
al., O O
2019) O O
achieves O O
10% O O
higher O O
accuracy B-MetricName B-MetricName
than O O
humans O O
on O O
tasks O O
that O O
involve O O
conjunctions. O O

We O O
analyse O O
the O O
behaviour O O
of O O
the O O
best O O
performing O O
model, O O
BERT B-MethodName B-MethodName
(Devlin O O
et O O
al., O O
2019), O O
across O O
the O O
various O O
inference O O
categories O O
present O O
in O O
AnaLog, B-TaskName B-TaskName
finding O O
that O O
its O O
reasoning O O
abilities O O
go O O
beyond O O
shallow O O
heuristics O O
and O O
yield O O
relatively O O
consistent O O
performance O O
on O O
deductive O O
and O O
analytical O O
reasoning, O O
as O O
well O O
as O O
across O O
reasoning O O
domains O O
(spatial O O
and O O
comparative) O O
and O O
logical O O
connectives. O O

To O O
do O O
so, O O
we O O
develop O O
a O O
new O O
NLI O O
task, O O
AnaLog, B-TaskName B-TaskName
1 O O
that O O
requires O O
LMs O O
to O O
encode O O
different O O
logical O O
reasoning O O
patterns O O
and O O
we O O
probe O O
the O O
behaviour O O
of O O
four O O
masked O O
and O O
autoregressive O O
LMs O O
on O O
this O O
new O O
dataset. O O

Yet, O O
LMs O O
typically O O
learn O O
to O O
solve O O
NLI O O
by O O
using O O
invalid O O
heuristics, O O
for O O
example O O
by O O
extracting O O
overlapping O O
patterns O O
between O O
premises O O
and O O
hypotheses O O
(McCoy O O
et O O
al., O O
2019), O O
or O O
by O O
using O O
specific O O
lexical O O
items O O
and O O
sentence O O
grammaticality O O
as O O
simplistic O O
predictors O O
of O O
entailment O O
(Poliak O O
et O O
al., O O
2018). O O

One O O
way O O
of O O
verifying O O
LMs’ O O
reasoning O O
abilities O O
is O O
using O O
a O O
natural O O
language O O
inference O O
(NLI) O O
task O O
(Dagan O O
et O O
al., O O
2005; O O
Giampiccolo O O
et O O
al., O O
2007; O O
Bowman O O
et O O
al., O O
2015; O O
Bhagavatula O O
et O O
al., O O
2020; O O
Rudinger O O
et O O
al., O O
2020). O O

Because O O
most O O
of O O
the O O
current O O
approaches O O
to O O
these O O
tasks O O
rely O O
on O O
pre-trained O O
language O O
models O O
(LMs), O O
it O O
is O O
essential O O
to O O
understand O O
whether O O
LMs O O
can O O
perform O O
logical B-TaskName B-TaskName
reasoning. I-TaskName I-TaskName

Logical B-TaskName B-TaskName
reasoning I-TaskName I-TaskName
(Lakoff, O O
1970; O O
MacCartney O O
and O O
Manning, O O
2007; O O
Smith, O O
2020) O O
is O O
at O O
the O O
core O O
of O O
many O O
downstream O O
NLP O O
tasks, O O
such O O
as O O
dialogue B-TaskName B-TaskName
and I-TaskName I-TaskName
story I-TaskName I-TaskName
generation I-TaskName I-TaskName
(Fan O O
et O O
al., O O
2018; O O
Welleck O O
et O O
al., O O
2019); O O
narrative B-TaskName B-TaskName
understanding I-TaskName I-TaskName
and I-TaskName I-TaskName
summarisation I-TaskName I-TaskName
(Mostafazadeh O O
et O O
al., O O
2016; O O
Vashishtha O O
et O O
al., O O
2020); O O
question B-TaskName B-TaskName
answering I-TaskName I-TaskName
(Weber O O
et O O
al., O O
2019; O O
Shi O O
et O O
al., O O
2021); O O
relation B-TaskName B-TaskName
extraction I-TaskName I-TaskName
(Massey O O
et O O
al., O O
2015; O O
Kassner O O
et O O
al., O O
2020; O O
Yanaka O O
et O O
al., O O
2021); O O
and O O
visual B-TaskName B-TaskName
comprehension I-TaskName I-TaskName
(Suhr O O
et O O
al., O O
2017, O O
2019; O O
Sethuraman O O
et O O
al., O O
2021). O O

We O O
present O O
AnaLog, B-TaskName B-TaskName
a O O
natural O O
language O O
inference O O
task O O
designed O O
to O O
probe O O
models O O
for O O
these O O
capabilities, O O
controlling O O
for O O
different O O
invalid O O
heuristics O O
the O O
models O O
may O O
adopt O O
instead O O
of O O
learning O O
the O O
desired O O
generalisations. O O

From O O
Table O O
3, O O
we O O
can O O
see O O
that O O
Radical-added B-MethodName B-MethodName
CGE I-MethodName I-MethodName
obtains O O
the O O
best O O
performance O O
on O O
Wordsim-240 B-DatasetName B-DatasetName
dataset, O O
outperforming O O
the O O
best O O
baseline O O
Word2vec B-MethodName B-MethodName
by O O
0.0111. O O

We O O
compute O O
the O O
Spearman B-MetricName B-MetricName
correlation I-MetricName I-MetricName
(Myers O O
et O O
al., O O
2010) O O
between O O
the O O
human-labeled O O
scores O O
and O O
similarity O O
scores O O
computed O O
by O O
embeddings. O O

The O O
similarity O O
embedding O O
score O O
for O O
a O O
word O O
pair O O
is O O
computed O O
as O O
the O O
cosine O O
similarity O O
of O O
their O O
embeddings. O O

However, O O
we O O
confirm O O
that O O
no O O
stereotype O O
examples O O
exist O O
in O O
Chinese B-DatasetName B-DatasetName
Wordsim-240 I-DatasetName I-DatasetName
and O O
wordsim-295. B-DatasetName B-DatasetName

We O O
select O O
two O O
different O O
Chinese O O
word O O
similarity O O
datasets, O O
i.e., O O
Wordsim-240 B-DatasetName B-DatasetName
and O O
Wordsim-295 B-DatasetName B-DatasetName
provided O O
by O O
Chen O O
et O O
al. O O
(2015). O O

We O O
use O O
the O O
Clopper-Pearson B-MetricName B-MetricName
confidence I-MetricName I-MetricName
intervals O O
following O O
Kaneko O O
and O O
Bollegala O O
(2019) O O
to O O
do O O
the O O
significance O O
test. O O

We O O
select O O
the O O
word-pair O O
with O O
the O O
highest O O
cosine O O
similarity O O
with O O
# O O
»he O O
− O O
# O O
» O O
she O O
as O O
the O O
predicted O O
answer. O O

We O O
name O O
the O O
outof-domain O O
test O O
dataset O O
as O O
CSemBias-subset. B-DatasetName B-DatasetName

CSemBias B-DatasetName B-DatasetName
contains O O
20 O O
gender-stereotype O O
word O O
pairs O O
and O O
22 O O
gender-definitional O O
word O O
pairs, O O
and O O
we O O
use O O
their O O
Cartesian O O
product O O
to O O
generate O O
440 O O
instances. O O

Concretely, O O
we O O
hire O O
three O O
native O O
Chinese O O
speakers O O
to O O
translate O O
the O O
original O O
English B-DatasetName B-DatasetName
SemBias I-DatasetName I-DatasetName
(Zhao O O
et O O
al., O O
2018b) O O
dataset O O
to O O
the O O
Chinese O O
version. O O

To O O
evaluate O O
debiasing O O
performance O O
of O O
our O O
model, O O
we O O
come O O
up O O
with O O
a O O
new O O
dataset O O
named O O
CSemBias B-DatasetName B-DatasetName
(Chinese B-DatasetName B-DatasetName
SemBias). I-DatasetName I-DatasetName

Words O O
with O O
a O O
frequency B-HyperparameterName B-HyperparameterName
of O O
less O O
than O O
5 B-HyperparameterValue B-HyperparameterValue
were O O
ignored O O
during O O
training. O O

For O O
all O O
models, O O
we O O
use O O
the O O
same O O
parameter O O
settings. O O
Following O O
Yu O O
et O O
al. O O
(2017), O O
we O O
set O O
the O O
word B-HyperparameterName B-HyperparameterName
vector I-HyperparameterName I-HyperparameterName
dimension I-HyperparameterName I-HyperparameterName
to O O
200, B-HyperparameterValue B-HyperparameterValue
the O O
window B-HyperparameterName B-HyperparameterName
size I-HyperparameterName I-HyperparameterName
to O O
5, B-HyperparameterValue B-HyperparameterValue
the O O
training B-HyperparameterName B-HyperparameterName
iteration I-HyperparameterName I-HyperparameterName
to O O
100, B-HyperparameterValue B-HyperparameterValue
the O O
initial O O
learning B-HyperparameterName B-HyperparameterName
rate I-HyperparameterName I-HyperparameterName
to O O
0.025, B-HyperparameterValue B-HyperparameterValue
and O O
the O O
subsampling B-HyperparameterName B-HyperparameterName
parameter I-HyperparameterName I-HyperparameterName
to O O
10−4 B-HyperparameterValue B-HyperparameterValue
. O O

